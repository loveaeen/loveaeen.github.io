---
title: Fault-Tolerant Virtual Machines
date: 2022-03-30 20:32:33
categories: Paper
tags: 
typora-root-url: ../../
---

The Design of a Practical System for Fault-Tolerant Virtual Machines - 基于容错虚拟机的实用系统设计

<!-- more -->

[原文翻译地址在这里](https://riverferry.site/2021-02-12-The-Design-of-a-Practical-System-for-Fault-Tolerant-Virtual-Machines/)

[原始论文地址 2010](https://pdos.csail.mit.edu/6.824/papers/vm-ft.pdf)

## ABSTRACT

通过提供故障容错性的虚拟机，我们已经实现了一个商业化的企业级系统，它建立在复制一个主虚拟机的执行过程到另一个服务器上的备份虚拟机的基础上。我们已经在VMware vSphere4.0上设计了一个完整的系统，它运行在商业用的服务器上，很容易使用，同时保证了应用的性能仅有少于10%的降低。另外，为了让主VM和次级VM的执行活动保持一致，对于几个实际的应用而言，需要的数据带宽少于20Mbit/s，这也允许实现更长距离的故障容错的可能性。一种容易使用，在故障后自动恢复备份的商业化系统，在复制VM执行之前需要额外的组件。我们已经设计并且实现了这些额外的组件，并且解决了在支持VM运行企业级应用的时候，遇到的许多实际问题。在这篇文章中，我们描述了我们基础的设计，讨论了可替代的设计选择和很多实现的细节，并且针对微基准和真实应用，提供了性能结果。

## 1. INTRODUCTION

一个实现容错服务器的常见方法是主备机制，如果主服务器失败，一个备份服务器总是可以进行接管。在任何时间，备份服务器的状态必须和主服务器几乎保持一致，因此当主服务器失败的时候，备份服务器可以立刻接管，此时对于外部客户端而言，故障就相当于被隐藏了起来，并且不会造成数据丢失。在备份服务器上复制状态的一种方法是将主服务器的所有状态，包括CPU、memory、IO设备，连续地送给备份服务器。然而，这种发送状态的方法，尤其是涉及到内存中的变更，其需要的带宽非常大。

> 将 primary所有的状态，包括处理器、内存、IO 全部发送给backup；这种策略的困难在于，需要的带宽资源非常多，因为需要完全复制内存，内存上的数据都要发到 backup 上。

另一种可以用更少带宽复制服务器的方法类似于状态机。这种思路是将服务器建模为确定性的状态机，他们从相同的初始状态开始，并且确保以相同的顺序接收相同的输入请求，这样就能保持同步。因为大多数服务器或服务有一些不确定性的操作，因此必须使用额外的协调机制来确保主备同步。然而，需要保持主备一致性的额外信息数目，远远少于正在变更的主服务器上状态（主要是内存更新）的数目。

> 将主机视为确定性状态机，对于一个状态机，只有输入才能改变状态，没有输入状态是不会改变的。因此这种策略主要同步两台主机的输入，primary 和 backup 在同一个初始状态开始，让 primary 和 backup 获得相同的输入，这样两台主机就可以保持状态一致；这种策略的困难在于，处理同一个输入需要进行的操作具有不确定性，比如获取时钟，在 primary 上执行是一个结果，在 backup 上执行是另一个结果，这会导致两个主机的状态不一致。

实现协调机制来确保物理服务器的确定性操作是困难的，尤其随着处理器频率增长。反之，一个运行在管理程序上的VM，是一个实现状态机方法的很好的平台。一个VM可以被当作一个定义好的状态机，它的操作是机器被虚拟化的操作（包括它所有的设备）。和物理服务器一样，VM有相同的非确定性操作（例如读取时钟或发送中断），因此为了保持同步，额外的信息必须被发送给备份服务器。管理程序有VM的全权控制权利，包括处理所有输入，因此它能够获得所有与主VM上的非确定性操作有关的必要信息，并且能正确地重放这些操作。

因此，这个状态机方法可以通过商业化软件上的VM来实现，它不需要硬件更改，允许在最新的微处理器上立刻实现故障容错。另外，状态机方法需要的低带宽允许了主备服务器能更好地进行物理分隔。例如，被复制的VM可以运行在横跨一个学校的物理机器上，相比于运行在同一建筑内的VM而言，可以提供更多的可靠性。

我们在VMware vSphere 4.0平台上使用主备机制实现了故障容忍的VMs，这个平台以一种高度有效的方式，运行着完全虚拟化的x86虚拟机。因为VMware vSphere实现了一个完整的x86虚拟机，所以我们自动地能够为任何x86操作系统和应用提供故障容忍。这种允许我们记录一个主服务器执行，并确保备份服务器一致执行的基础技术是**确定性重放**[^1]。VMware vSphere Fault Tolerance(FT)是基于确定性重放的，但是为了建立一个完整的故障容忍系统，还增加了必要的额外协议和功能。除了提供硬件故障容忍，我们的系统在一次失败后，通过在局部集群中任何可接受的服务器上开始一个新的备份虚拟机，进行自动地存储备份。目前确定性重放和VMare FT的产品版本只支持单处理器的VMs。多处理器VM的操作记录和重放还在开发中，因为每个共享内存的操作都是一个非确定性的操作，因此还有重要的性能问题待解决。

Bressoud和Schneider描述了一个针对HP PA-RISC平台的故障容忍VMs的原型实现。我们的方法是相似的，但是出于性能原因，以及在调查了许多可替代设计后，我们已经做了一些基础性的改变。另外，为了建立一个完整的系统，而这个系统是有效的并且能够被正在运行企业级应用的客户使用，我们已经设计并实现了系统中许多额外的组件，可以处理许多实际问题。与大多数其他实际系统讨论的类似，我们只尝试应付fail-stop的故障，这是一种服务器故障，可以在故障服务器造成一次不正确的外部可见行为之前被检测。

文章的剩余部分如下组织。首先，我们描述了我们基础的设计，并且详细说明了我们的基本协议，它能确保在主VM失败后，备份VM能够接替，且不会造成数据丢失。然后，我们描述了许多实际问题的细节，这些问题是为了建立一个强大的、完整的和自动化系统过程中必须被处理的。我们也描述了几个可用于实现故障容忍VMs的设计选择，并且讨论了这些选择的得失。接着，我们给出在一些基准以及实际企业级应用上的性能结果。最后，我们描述相关的工作和结论。

## 2. BASIC FT DESIGN

<img src="/image/Fault-Tolerant%20Virtual%20Machines/image-20220330204725217.png" style="zoom:50%;" />

图1展示了我们系统在故障容忍VMs的基本步骤。对于一个给定的VM，我们希望提供故障容忍（主VM），我们在一个完全不同的物理机器上运行一个备份VM，保持和主VM同步并且执行一致，虽然存在短时间的滞后。我们说这两个VM是同步的。 VM的虚拟磁盘位于共享存储上(例如Fibre Channel或iSCSI磁盘阵列)，因此主VM和备份VM可以共同访问它们的输入和输出。 (我们将在第4.1节中讨论主VM和备份VM具有独立的非共享虚拟磁盘的设计。) 只有主VM通知它在网络上的存在，因此所有网络输入都进入主VM。 类似地，所有其他输入(如键盘和鼠标)都只进入主VM。

主VM接收的所有输入都通过一个称为日志通道的网络连接发送到备份VM。 对于服务器工作负载，主要的输入流量是网络和磁盘。 为了确保备份VM以与主VM相同的方式执行非确定性操作，需要传输额外的信息(如下面的2.1节所述)。 结果是备份VM总是与主VM执行相同。 但是，备份VM的输出会被系统管理程序删除，因此只有主VM产生返回给客户机的实际输出。 如第2.2节所述，主VM和备份VM遵循特定的协议，包括备份VM的显式确认，以确保在主VM失败时不会丢失任何数据。

为了检测主VM或备份VM是否失败，我们的系统使用相关服务器之间的心跳和日志通道上的流量监控的组合。 此外，我们必须确保主VM或备份VM中只有一个接管执行，即使出现主服务器和备份服务器彼此失去通信的脑裂情况。

在下面的小节中，我们将提供几个重要领域的更多细节。 在第2.1节中，我们详细介绍了确定性重放技术，它确保主vm和备份vm通过日志通道发送的信息保持同步。 在第2.2节中，我们描述了我们的FT协议的一个基本规则，它确保在主节点失败时不会丢失数据。 在第2.3节中，我们描述了以正确的方式检测和响应故障的方法。

### 2.1 Deterministic 确定性 Replay Implementation

如前所述，复制服务器(或VM)的执行可以建模为确定性状态机的复制。 如果两个确定性状态机以相同的初始状态启动，并以相同的顺序提供完全相同的输入，那么它们将经历相同的状态序列并产生相同的输出。 虚拟机有一组广泛的输入，包括传入的网络数据包、磁盘读取以及键盘和鼠标输入。 非确定性事件(如虚拟中断)和非确定性操作(如读取处理器的时钟周期计数器)也会影响VM的状态。 这给复制执行任何操作系统和虚拟机运行工作负载提出了三个挑战:(1)正确捕获所有必要的输入和非确定性,确保确定性执行备份虚拟机,(2)正确应用备份虚拟机的输入和非确定性,(3)这样的方式不会降低性能。 此外，x86微处理器中的许多复杂操作都有不确定的副作用。 捕获这些未定义的副作用并将其重新播放以产生相同的状态是一个额外的挑战。

VMware replay正是为VMware vSphere平台上的x86虚拟机提供了这一功能。 确定性重放来记录VM的输入和与VM执行相关的所有可能的不确定性，记录在日志文件的日志项流中。 稍后，通过从文件中读取日志项，可以准确地重放VM执行。 对于不确定的操作，将记录足够的信息，以允许使用相同的状态更改和输出复制操作。 对于不确定的事件，如定时器或IO完成中断，事件发生的确切指令也会被记录下来。 在重放期间，事件在指令流中的同一点被交付。 VMware确定性回放实现了一种高效的事件记录和事件传递机制，该机制采用了多种技术，包括使用与AMD和Intel联合开发的硬件性能计数器。

Bressoud和Schneider提到将VM的执行划分为epoch，在其中，诸如中断之类的非确定性事件只在epoch结束时交付。 epoch的概念似乎被用作一种批处理机制，因为它太昂贵了，不能在每个中断发生的确切位置上分别交付它们。 但是，我们的事件交付机制非常有效，VMware的确定性重放不需要使用epoch。 每次中断发生时都会被记录下来，并在回放时有效地按适当的指令进行传送。

### 2.2 FT Protocol 协议

对于VMware FT，我们使用确定性重放来生成必要的日志项来记录主VM的执行，但是我们不将日志项写入磁盘，而是通过日志通道将它们发送到备份VM。 备份VM实时回放这些条目，因此与主VM执行相同。 但是，我们必须在日志通道上使用严格的FT协议来增加日志项，以确保实现容错。 我们的基本要求是:

> 输出要求:如果备份 VM 在主要机器出现故障后接管，备份 VM 将继续执行，其执行方式将与主要 VM 发送到外部世界的所有输出完全一致。

请注意，在发生故障转移之后(即，备份VM在主VM发生故障后接管)，备份VM的启动方式可能与主VM继续执行的方式非常不同，因为在执行期间会发生许多不确定的事件。 但是，只要备份VM满足输出要求，在故障转移到备份VM期间就不会丢失外部可见的状态或数据，客户机也不会注意到它们的服务中没有中断或不一致。

输出要求可以通过延迟所有外部输出(通常是网络包)直到备机已经接受了所有信息(允许备机重放到至少输出操作的时刻)的时候。一个必要的条件是备机必须已经接收了所有的输出操作事先生成的日志项。这些日志项能够让备机执行到最后的日志项的时刻。然而，如果一个故障在主机执行输出操作的时候立刻发生。备机必须知道它必须一直重放到输出操作的时刻然后在那个时刻仅仅上线(停止重放并接管主机，像2.3节描述的那样)。如果备机在输出操作之前的最后的日志项的时刻上线，一些不确定性事件(比如传递给虚拟机的时钟中断)可能改变执行路径，在执行输出操作之前。

鉴于上面的约束，执行输出要求的最简单方式是对每一个输出操作创建一个特殊的日志项。然后，输出要求可以通过这些特殊的规则被执行：

> 输出规则：主机直到备机接收被确认了和产生输出相关联的日志项的时候，才发送输出给外部世界。

如果备机已经接收了所有的日志项，包括输出产生操作的日志项，那么备机将能够准确的重现在该输出点上的主机的状态，即使主机宕了，备机仍能够正确的达到和该输出一致的状态。相反，如果备机在没有接收到所有必要的日志项的时候就接管了主机，则备机的状态可能很快偏离到和主机输出不一致的状态。输出规则在某些方面和提到的方法是类似的，其中外部同步IO可以被缓冲，只要在下一次外部通信前写入磁盘。

注意输出规则没有说任何要通知主机执行的事情。我们只需要延迟发送输出，但是虚拟机可以继续执行。因为操作系统通过异步中断来非阻塞的表示网络和磁盘输出的完成，所以虚拟机只需要继续执行，并且不一定会立即受到输出延迟的影响。相反，先前的工作[3,9]通常表明在完成输出之前主机必须完全停止，直到备机已经确认了所有来自主机的必要信息。

![Figure 2: FT Protocol](/image/Fault-Tolerant%20Virtual%20Machines/image-20220331142544231.png)

作为例子，我们在图2中展示了一个图表说明容错协议的要求。该图展示了主机和备机上事件的时间线。主机线到备机线的箭头表示日志项的传输，备机线到主机线的箭头表示确认。异步事件的信息，输入，和输出操作都必须被发送给备机，以日志项的方式，然后由备机确认。如图中说明的那样，对于外部世界的输出会被延迟到主机已经接收到来自备机的确认信息，在备机收到和输出操作相关联的日志项的时候会进行确认。如果输出规则得以遵守，备机将能够以和主机最后输出一致性的状态进行接管。

如[3,9]所表示的，我们不能保证所有的输出都只被生成一次在故障转移的情况下。在主机尝试发送输出的时候不适用两阶段提交事务的话，就没有办法让备机判断主机是在崩溃之前还是之后发送了最后的输出。幸运的是，网络基础设施(包括常用的tcp)被设计为能够处理丢包和重包。

注意，传给主机的数据包在主机故障的时候也可能丢失因而不能被传递给备机。然而，传入的数据包可能出于一系列和服务器故障不相关的原因被丢弃，所以网络基础设施，操作系统和应用都被写入(意思应该是都要适配这个情况？ )来确保可以对丢失的包进行补偿。

### 2.3 Detecting and Responding to Failure

如前面提到的那样，主机和备机必须在另一方故障的时候快速响应。如果备机故障，主机将会上线-指的是离开记录模式(因此停止在日志通道上发送日志项)并开始正常运行。如果主机故障，备机也会上线，但是处理会更加复杂一点。因为备机是延迟执行的，备机可能有一系列它已经接受和确认的的日志项，但是还没被消费完因为备机还没达到运行的合适时间点。备机必须继续重放来自日志项的运行直到消费完最后的日志项。然后备机将会停止重放模式然后开始正常运行，像普通虚拟机那样。本质上，备机已经被晋升为了主机(现在没有备机了)。因为已经不是备机了，新的主机将在guest os(运行在虚拟机上的操作系统)有输出操作的时候产生输出给外部世界。在过渡为正常模式的期间，可能会需要一些特定设备的操作来让输出正确发生。特别的，出于联网的目的，VMware容错会自动将新的主机的mac地址在网络进行通告，所以物理网络交换机将能够得知新的主机服务器的位置。另外，新的晋升的主机可能需要重发一些磁盘IO(像3.4节描述的那样)。

对于尝试检测主机和备机故障有许多可能的方式。VMware容错使用运行在容错虚拟机上的服务器间的udp心跳包来检测哪台服务器已经宕掉了。另外，VMware容错监控从主机发给备机的日志和从备机发送给主机的确认信息的流量。因为经常的时钟中断，日志流量应该是规律的并且永远不会在guest os上停止。因此，日志项和确认信息流的暂停可能表明虚拟机或者网络问题引起的故障。如果心跳包或者日志通道流量停止了超过指定的超时时间(大约几秒钟)则表明这是故障。

然而，任何这类故障检测方法都容易收到脑裂问题的影响。如果备机停止从主机接收心跳包，可能意味着主机故障了，也可能只是因为仍在运行的服务器间的所有网络连接都丢失了。如果备机接着在主机仍旧运行的情况下上线，这可能引起数据损坏或者客户端与虚拟机通信的问题。因此，我们必须确保只有一台主机或备机上线，在故障被检测到的时候。为了避免脑裂的问题，我们使用用来存储虚拟机虚拟磁盘的共享存储。在主机或备机想上线的时候，在共享存储上执行一个原子的test-and-set锁指令。如果操作指令成功，则虚拟机可以上线。如果指令失败，则另外的虚拟机肯定仍在运行，所以当前的虚拟机实际上会结束运行(提交suicide).如果虚拟机无法访问共享存储，在尝试做原子操作指令的时候，只需要一直等到可以访问的时候。记住如果共享存储因为一些存储网络故障导致不能访问，那么虚拟机可能无论如何都不能正常工作，因为虚拟机磁盘也在共享存储上面。因此，使用共享存储来解决脑裂问题不会带来任何额外的不可用。

该设计的最后一个方面是一旦故障已经发生了并且其中一个虚拟机已经上线了，VMware容错会自动通过在另外主机上启动新的备机来恢复冗余。即使前面大部分没有提及这个过程，但是这一点对于实现有用的容错系统是基础的，并且需要仔细设计。更多的细节见3.1节。

### 2.4 Go-live Points

为了容错使用的确定性重放驱使我们在重放实现中增加了一种有趣的机制。因为会有网络问题以及主机故障可能发生在任何时刻，由备机正在读取或者重放的日志项流也可能在任何时刻终止。日志项在任何时刻终止的可能性会扩散到确定性重放的实现，因为每一个日志项(比如一个虚拟的设备实现)的潜在消费者都需要检查和处理所需日志不可用的问题。比如，给定一个之前的日志项和它现在的状态，虚拟设备实现可能需要一系列有关IO实现的额外的日志项。需要编写重放部分的代码来检查日志流的结束，退出一些可能复杂的重放代码，回复设备到合理的状态，使之可以在虚拟机上go live.

为了减轻系统上多数组件的负担，我们已经实现了go-live points.任何单个日志项都可以被标记为go-live points.这个思想是一个被标记为go-live point的日志项可以用来表示对于重放一个指令或者特别的设备操作必要的一系列日志项中的最后一个日志项。如果一个特别的操作或者指令需要一部分被记录的日志项，那么仅最后的日志项会被标记为go-live point.实际上，虚拟机管理程序会自动标记最后的一个新的日志项为go-live point,在它完成给定指令的所有事件和设备处理的时候。

go-live points在重放期间的使用如下。当所有从日志通道读取的日志项都被虚拟机管理程序缓存在正在重放的虚拟机上。只有最后的go-live point之前的日志项可以被重放的备机消费。也就是说，正在重放的虚拟机在消费最后一个被标记为go-live point的日志项之后会停止运行直到一系列包含go-live point的日志项已经被虚拟机管理程序拉取。结果是如果有一系列和设备操作关联的日志项，如果虚拟设备实现遇到了第一个日志项，就可以假定所有需要的日志项都是可用的。因此，虚拟设备实现不需要做所有额外的检查和恢复代码，如果日志项可以在任何时刻终止。类似的，任何代表虚拟机执行的单个指令生成多个日志项的时候，重放虚拟机的虚拟机管理程序仅在所有的对于完成指令仿真有必要的日志项都是可用的时候，才开始指令的模拟。标记方案不会对正在重放的虚拟机带来任何明显的延迟，因此记录(primary)虚拟机的虚拟机管理程序保证每一个模拟指令或者设备操作的最后的日志项被标记为go-live point.因此备机不会有明显的延迟，主机也不会受到go-live point的影响。

## 3. PRACTICAL IMPLEMENTATION OF FT

第2节描述了容错的基础设计和协议。但是为了创建一个可用的，健壮的自动化系统，还需要设计实现许多其他组件。

### 3.1 Starting and Restarting FT VMs

必须设计的最大的额外组件之一是以和主机相同的状态启动备机的机制。这个机制在故障发生重启备机的时候也会用到。因此，该机制对于运行任意状态(不仅仅是启动)的主机必须是可用的。另外，我们更希望该机制不会明显的打断主机的运行，因此这会影响到所有连接虚拟机的客户端。

对于VMware容错系统，我们适配了VMware vSphere的现有Vmotion功能。VMware VMotion可以在最小化中断的代价下将运行的虚拟机从一台服务器迁移到另一台服务器-虚拟机的暂停时间通常小于1秒。我们创建了一个修改版的Vmotion，通过在远端服务器上创建一个精确的虚拟机的运行拷贝，而不需要摧毁本地服务器上的虚拟机。也就是说，修改版的容错Vmotion克隆一个虚拟机到远端服务器而不是迁移虚拟机。容错Vmotion也会建立一个日志通道，源虚拟机会作为主机进入日志模式，目的虚拟机作为新的备机进入重放模式。和普通版本的Vmotion一样，容错Vmotion通常打断主机的时间少于1秒。因此，在运行中虚拟机启用容错是简单，无中断的操作

启动备机的另一个方面是选择哪台服务器来运行。容错虚拟机运行在访问共享存储的服务器集群上，因而所有的虚拟机是运行在集群中任意的服务器的。这种灵活性让VMware vSphere能够恢复容错冗余在一台或者多台服务器故障的时候。VMware vSphere实现了一个集聚服务来维护管理和资源信息。当故障发生而主机需要一个新的备机重建冗余的时候，主机会通知集聚服务它需要一个新的备机。集聚服务基于资源申请，使用和其他约束来选择运行备机的最佳服务器。然后集聚服务自动调用容错Vmotion来创建新的备机。当然，也有许多额外的复杂性，比如在第一次创建备机失败后的重试，和自动检测集群中服务器什么时候变为新的可用状态。最后的结果是VMware容错可以重建虚拟机冗余在服务器故障后几分钟，而不会对容错虚拟机执行有明显的打断。

### 3.2 Managing the Logging Channel

管理日志通道的流量有一系列有趣的实现细节。在我们实现中，虚拟机管理程序维护了一个大的缓冲，保存了主机和备机的日志项。当主机运行的时候，会产生日志项到日志缓冲，类似的，备机从日志缓冲消费日志项。主机日志缓冲的内容会尽快刷到日志通道中，日志项写到日志缓冲后也会尽快读取到备机的日志缓冲中。备机发送确认信息给主机，在每一次通过网络读取一些日志项到日志缓冲的时候。这些确认信息让VMvare容错能够决定什么时候被输出规则延迟的输出可以被发送。图3说明了这个过程。

![Figure 3: FT Logging Buffers and Channel](/image/Fault-Tolerant%20Virtual%20Machines/Snipaste_2021-02-17_23-19-37_water.jpg)

如果备机在读取新的日志项的时候遇到了空的日志缓冲，则会停止运行直到日志项变为可用。因为备机不是在外部通信，这种暂停不会对虚拟机的客户端有影响。相似的，如果主机在需要写入日志项的时候发现复制缓冲满了，也会停止运行直到日志项被清除了。主机的停止是自然的流控机制，可以在生成的日志项速率过快的时候降低速度。然而，这种暂停会影响虚拟机的客户端，因为主机会完全停止变为不响应知道可以写入日志继续运行的时候。因此，我们的实现必须设计为最小化主机日志缓冲满的可能性。

主机日志缓冲满的一个原因是日志通道的带宽太小以至于无法承载正在生成的日志项的容量。因为日志通道的带宽通常不太高(见第5节)，我们强烈建议对于日志通道使用1Gbit/s的网络来避免网络瓶颈。

主机缓冲满的另一个可能原因是备机执行过慢以至于消费日志项太慢。通常，备机必须能以和主机记录执行大致相同的速度重放执行。幸运的是，VMware确定性重放中记录和重放的负载是大致相同的。然而，如果承载备机的服务器也加载了其他的虚拟机(因此使用资源过渡)，备机可能无法获得足够的cpu和内存资源以和主机相同的速度执行，即使备机虚拟机管理程序的虚拟机调度器尽最大的努力。

除了避免在日志缓冲满时不希望的暂停，还有另外原因是我们不希望执行的滞后变得太大。如果主机故障了，备机必须通过重放它在之前已经确认的所有日志项来“追赶”主机，再成为主机上线。结束重放的时间基本上是故障点的执行滞后时间。因此，备机上线的时间大致等于故障检测时间加上当前执行滞后时间。所以，我们不希望执行滞后时间太大(超过1秒)，因为这将明显的增加故障转移的时间(备机上线的时间)。

因此，我们有一个额外的机制来减慢主机的速度，避免备机落后太多。在发送和确认日志项的协议中，会发送额外的信息来决定实时的运行延迟，在主机和备机之间。通常执行延迟少于100毫秒。如果备机开始有了明显的执行延迟(比如超过1秒)，VMware容错会开始减慢主机的速度，通过通知调度器给主机更少的cpu份额(初始时只有百分之几)。我们使用一个慢反馈环，会逐渐的精确化对于主机的cpu份额来让备机追上主机的运行。如果备机仍旧落后，我们会继续降低主机的cpu份额。相反的，如果备机追上了主机，我们会逐渐的增加主机的cpu份额直到备机返回微小的延迟。

注意对于主机的减速是很罕见的，通常只在系统处于极端压力的情况下发生。第5节的所有性能数字包含了这些减速的成本。

### 3.3 Operation on FT VMs

另一个实际的问题是处理多种可能被应用于主机的控制操作。比如，当主机显式关机的时候，备机也应该关机，而不是尝试上线。另一个例子，主机上任何的资源管理改变(比如增加了cpu份额)也应该应用到备机。对于这些操作，特殊的控制项会通过日志通道从主机发送给备机，为了在备机上也应用适当的操作。

通常，虚拟机的多数操作仅在主机上初始化。VMware容错会发送所有必要的控制项在备机上应用适当的变更。唯一可以在主机和备机上独立执行的操作是VMotion.也就是说，主机和备机可以分别独立的Vmotiond到其他主机。注意，VMware容错确保主机和备机都不会被VMotioned到对方所在的服务器上，因为这种情况下不再提供容错。

主机的Vmotion相对于普通Vmotion增加了一些复杂性，因为备机必须和源主机断开连接然后在合适的时间重新连接到目的主机。备机的VMtion有相同的问题，但是增加了额外的复杂性。对于普通的Vmotion,我们要求所有未完成的磁盘IO都暂停(即完成)就像VMotion上发生的最终切换。对于主机，这种暂停容易处理，可以一直等待直到物理IO完成并发送完成信息给虚拟机。然而，对于备机，没有简单的方法在任何需要的时间点让所有IO完成，因为备机必须重放主机的执行并且在相同的执行点完成IO.主机可以运行在总是有磁盘IO的工作负载上，在正常运行期间。VMware容错有独特的方法解决这个问题。当备机在VMotion的最终切换点的时候，它通过日志通道要求主机临时停止所有的IO.备机的IO也会在单独的执行点上自然的暂停，因为备机会重放主机暂停操作的执行命令

### 3.4 Implementation Issues for Disk IOs

有一些和磁盘IO相关的细微的实现问题。首先，非阻塞的磁盘操作可以并行执行，因此对同一磁盘位置的同时访问可能导致不确定性。我们对磁盘IO的实现使用DMA直接读写虚拟机内存，所有对于相同内存页的同时访问也可能导致不确定性。我们的解决方案通常是检测所有这类IO竞争(是很罕见的)，然后强制这些竞争的磁盘操作以相同的方式在主机和备机上顺序执行。有趣的是，单个磁盘读取操作也可能造成竞争，因为散聚的阵列可能引用相同的内存块多次，而导致内存页的内容变得不确定性。我们的解决方案还是检测这些竞争，保证在这种情况下最后的内存内容会在日志通道上发送，这样备机可以以相同的内存内存结束。

第二，虚拟机上的应用程序(或操作系统)的有关内存访问的磁盘操作也可能产生竞争，因为磁盘操作直接通过DMA访问内存。比如，如果虚拟机中的应用程序/操作系统在读取内存块的同时读取该块的磁盘，则可能会导致不确定性。这种情况也是类似的，但是我们必须检测并在它发生的时候解决它。我们的解决方案是设置临时的页保护在由磁盘操作的页上。如果虚拟机碰巧对未完成磁盘操作的标记页进行访问则页保护最终会进入陷阱，虚拟机会被暂停直到磁盘操作完成。因为修改页上的MMU保护是昂贵的操作，所以我们使用了bounce buffers. bounce buffer是磁盘操作正在访问的内存大小一致的临时缓冲。磁盘读操作被修改为在bounce buffer中读取特定数据，并且数据仅在IO操作完成并被传递的时候拷贝到虚拟机内存。类似的，对于磁盘写操作，将要被发送的数据会先拷贝到bounce buffer,磁盘写操作被修改为写数据到bounce buffer. bounce buffer的使用能够减慢磁盘操作，但是我们还没有看到任何明显的性能差异。

第三，当主机故障的时候在主机上可能会有一些未完成的和磁盘IO相关的问题，而备机进行了接管。对新提升的主机就没有办法确定磁盘IO被发布到磁盘还是已经成功完成。另外，因为磁盘IO没有在外部的备机进行发布，当新提升的主机继续运行的时候，不会有明确的IO完成，最终可能导致虚拟机的虚拟机操作系统开始终止或者重置程序。因此，我们希望确保对于每一个挂起的IO，将完成信息发送给虚拟机。我们可以发送错误完成信息来表明IO失败，因为即使IO成功完成，返回错误也是可接受的。然而，虚拟机操作系统可能不会从本地磁盘很好的响应错误。相反，我们在虚拟机go-live的过程重新发布IO，因为我们已经消除了所有的竞争并且所有的IO直接指定了要访问的内存和磁盘块，这些磁盘操作可以重新发布即使已经成功完成了（即是幂等的)。

### 3.5 Implementation Issues for Network IO

VMware vSphere对于虚拟机网络提供了许多性能优化。多数这些优化是基于虚拟机管理程序异步更新虚拟机网络设备的状态。比如，在虚拟机运行的时候接收缓冲区可以被虚拟机管理程序直接更新。不幸的是，这种对于虚拟机状态的异步更新增加了不确定性。除非我们能够保证所有的更新在主机和备机的指令流同时发生，否则备机的执行可能和主机不同。

对于容错的网络仿真代码的最大改变是消除了异步网络优化。所有对于虚拟机网络状态的更新必须在虚拟机不执行指令的时候完成，以便我们可以记录更新日志并在备机上指令流的同一点重放。异步更新虚拟机ring buffer的代码被修改为强制guest陷入到虚拟机管理程序，在虚拟机管理程序里可以更新然后应用更新日志带虚拟机。类似的，之前异步拉取传输队列的包的代码被容错禁用了，取而代之的我们要求通过陷入到虚拟机管理程序来完成传输(如下所示)。

网络设备异步更新的消除和2.2节描述的发送包的延迟，为网络的性能带来了挑战。我们已经使用两种方法来提高运行容错的虚拟机的网络性能。首先，我们实现了集群优化以减少虚拟机的陷阱和中断。当我们以足够的比特率传输数据，我们可以对于每一组包进行一次传输陷阱，最好的情况下是0陷阱，因为我们将包作为新接收的包的一部分进行传输。同样的，我们通过对每一组包发送一次中断，来降低对于传入包的虚拟机的中断次数。

我们对于网络的第二个性能优化涉及降低传输包的延迟。如前面提到的，我们必须延迟所有的传输包直到获取了备机的确认信息，在备机接受到合适的日志项。降低传输延迟的关键是减少向备份发送日志消息并获得确认所需的时间。我们在这个方面的主要优化设计确保发送接受日志项和确认信息都在不发生线程上下文切换的情况下完成。VMware vSphere虚拟机管理程序允许函数被注册为TCP栈，任何接收到tcp数据的时候，将在推迟执行上下文中调用(类似linux的软中断)。这允许我们在备机上快速处理所有的输入日志项和由主机收到的确认信息，而不会发生任何的线程上下文切换。另外，当主机将需要被传输的包入队，我们通过调度延迟执行上下文来将需要立即刷新的和输出日志项关联的日志进行刷新。

## 4 DESIGN ALTERNATIVES 替代方案



## RELATED READ

[[1] 楷哥的论文笔记](https://www.cnblogs.com/zzk0/p/13504580.html)

[[2] BrianLeeLXT的论文研读](https://www.cnblogs.com/brianleelxt/p/13245754.html)

[^1]:对于一系列输入，对主机的执行进行记录并确保备机以相同方式执行的基本技术称为确定性重放