<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>百度Ueditor迁移过程</title>
    <link href="/2022/04/02/Work/%E7%99%BE%E5%BA%A6Ueditor%E8%BF%81%E7%A7%BB%E8%BF%87%E7%A8%8B/"/>
    <url>/2022/04/02/Work/%E7%99%BE%E5%BA%A6Ueditor%E8%BF%81%E7%A7%BB%E8%BF%87%E7%A8%8B/</url>
    
    <content type="html"><![CDATA[<h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>UEditor是由百度web前端研发部开发所见即所得富文本web编辑器，具有轻量，可定制，注重用户体验等特点，开源基于MIT协议，允许自由使用和修改代码。但是Github中的源代码已经很多年不维护了，所以遇到问题只能靠自己本事来解决了。</p><p>本篇文章并不是对Ueditor编辑器本身的迁移做记录，而是针对已在项目中实际使用很久，并包含了前后端交互的表单自定义功能做迁移操作。表单自定义功能允许研发人员根据客户需求，使用编辑器绘制页面样式后，自定义查询条件与展示数据列表，并维护一个相对简单的CRUD功能，实现「低代码」开发，并且无需项目重启即可生成新的模块功能。</p><h2 id="组件结构"><a href="#组件结构" class="headerlink" title="组件结构"></a>组件结构</h2><table><thead><tr><th>名称</th><th>描述</th></tr></thead><tbody><tr><td><strong>editor_config.js</strong> (ueditor.config.js)</td><td>可以在这里配置整个编辑器的特性，包含「定制工具栏图标」</td></tr><tr><td>dialogs文件夹</td><td>工具栏弹出的对话框所对应的网页资源和JS文件</td></tr><tr><td>FormAction</td><td>表单管理的功能类，用于表单设计后的存储，修改，生成数据库表等操作</td></tr><tr><td>FormUtil</td><td>表单管理的工具类，如获取或解析存储的HTML文本，为页面element额外补充属性等。</td></tr><tr><td>YYFormAction</td><td>表单与业务结合的管理类，用于将表单生成用户需要的增删改查页面与列表查询功能。</td></tr><tr><td>YYFormUtil</td><td>将表单的HTML填充业务实际需要的各种组件，如「用户选择器」「机构选择器」等，并在修改查看页面根据组件来回显数据。</td></tr></tbody></table><!-- flag of hidden posts -->]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>TCP网络编程实践</title>
    <link href="/2022/04/01/NetWork/TCP%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%AE%9E%E8%B7%B5/"/>
    <url>/2022/04/01/NetWork/TCP%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%AE%9E%E8%B7%B5/</url>
    
    <content type="html"><![CDATA[<p>本文不会涉及TCP的各个基础知识点，主要是总结一些TCP网络编程实践中可能碰到的一些问题，以及相应的经过实践验证的解决方案等。虽然本文档很多细节主要是针对于Linux系统，不过，大部分建议适合于所有系统。</p><h2 id="1-服务端监听设置SO-REUSEADDR选项"><a href="#1-服务端监听设置SO-REUSEADDR选项" class="headerlink" title="1. 服务端监听设置SO_REUSEADDR选项"></a>1. 服务端监听设置SO_REUSEADDR选项</h2><p>当我们重启服务端程序的时候可能会碰到 “address already in use” 这样的报错信息，即地址已被使用，导致程序无法快速成功重启。老的进程关闭退出了，为什么还会报地址已被使用呢？</p><p>我们先来理解如下两点：</p><ul><li>TCP连接主动关闭方存在持续2MSL的<code>TIME_WAIT</code>状态；</li><li>TCP连接由是由四元组&lt;本地地址，本地端口，远程地址，远程端口&gt;来确定的。</li></ul><p>我们先简单回顾一下TCP连接关闭过程中的<code>TIME_WAIT</code>状态，如下所示：</p><img src="/image/TCP%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%AE%9E%E8%B7%B5/tcp_close.png" style="zoom:50%;" /><p>TIME_WAIT存在的意义主要有两点：</p><ol><li>维护连接状态，使TCP连接能够可靠地关闭。如果连接主动关闭端发送的最后一条ACK丢失，连接被动关闭端会重传FIN报文。因此，主动关闭方必须维持连接状态，以支持收到重传的FIN后再次发送ACK。如果没有<code>TIME_WAIT</code>，并且最后一个ACK丢失，那么此时被动关闭端还会处于<code>LAST_ACK</code>一段时间，并等待重传；如果此时主动关闭方又立即创建新TCP连接且恰好使用了相同的四元组，连接会创建失败，会被对端重置。</li><li>等待网络中所有此连接老的重复的、走失的报文消亡，避免此类报文对新的相同四元组的TCP连接造成干扰，因为这些报文的序号可能恰好落在新连接的接收窗口内。</li></ol><p>因为每个TCP报文最大存活时间为MSL，一个往返最大是2*MSL，所以<code>TIME_WAIT</code>需要等待2MSL。</p><p>当进程关闭时，进程会发起连接的主动关闭，连接最后会进入<code>TIME_WAIT</code>状态。当新进程bind监听端口时，就会报错，因为有对应本地端口的连接还处于<code>TIME_WAIT</code>状态。</p><p>实际上，只有当新的TCP连接和老的TCP连接四元组完全一致，且老的迷走的报文序号落在新连接的接收窗口内时，才会造成干扰。为了使用<code>TIME_WAIT</code>状态的端口，现在大部分系统的实现都做了相关改进与扩展：</p><ul><li>新连接SYN告知的初始序列号，要求一定要比<code>TIME_WAIT</code>状态老连接的序列号大，可以一定程度保证不会与老连接的报文序列号重叠。</li><li>开启TCP <a href="https://datatracker.ietf.org/doc/html/rfc6191">timestamps扩展选项</a>后，新连接的时间戳要求一定要比<code>TIME_WAIT</code>状态老连接的时间戳大，可以保证老连接的报文不会影响新连接。</li></ul><p>因此，在开启了TCP timestamps扩展选项的情况下（<code>net.ipv4.tcp_timestamps = 1</code>），可以放心的设置<code>SO_REUSEADDR</code>选项，支持程序快速重启。</p><p>注意不要与<code>net.ipv4.tcp_tw_reuse</code>系统参数混淆，该参数仅在客户端调用connect创建连接时才生效，可以使用<code>TIME_WAIT</code>状态超过1秒的端口（防止最后一个ACK丢失）；而<code>SO_REUSEADDR</code>是在bind端口时生效，一般用于服务端监听时，可以使用本地非<code>LISTEN</code>状态的端口（另一个端口也必须设置<code>SO_REUSEADDR</code>），不仅仅是<code>TIME_WAIT</code>状态端口。</p><h2 id="2-服务端需要限制最大连接数"><a href="#2-服务端需要限制最大连接数" class="headerlink" title="2. 服务端需要限制最大连接数"></a>2. 服务端需要限制最大连接数</h2><p>一个服务端口，理论上能接收的最大TCP连接数是多少呢？TCP四元组中的服务端IP、服务端端口已经固定了，理论上的上限就是客户端可用IP数量*客户端可用端口数量。去除一些IP分类、端口保留等细节，理论上限就是2^32 * 2 ^16 &#x3D; 2^48。</p><p>当然，目前现实中肯定达不到理论上限的瓶颈。一个TCP socket所关联的主要资源有内存缓冲区、文件描述符等，因此，实际限制主要取决于系统内存大小与文件描述符数量限制。</p><p>服务端限制最大连接数，主要有两个目的：</p><ul><li>避免服务过载导致CPU、内存耗尽；</li><li>避免文件描述符耗尽。</li></ul><p>每个TCP连接的socket都占用一个FD，每个进程以及整个系统的FD数量都是有限制的。Linux系统下，通过<code>ulimit -n</code>可以查看单个用户的进程运行打开的FD最大数量，通过<code>cat /proc/sys/fs/file-max</code>可以查看所有进程运行打开的最大FD数量，如果不符合应用的需求，那就需要进行相应的调整。</p><p>达到FD上限会有什么影响呢？首先，肯定是无法接收新TCP连接了；其次，除了TCP连接占用的FD外，你的应用肯定还有内部场景占用或需要分配新的FD，比如日志文件发生轮转创建新日志文件时，如果日志文件创建失败，对于依赖本地存储的应用（如KV、MQ等存储型应用），就导致服务不可用了。所以，要在系统限制的基础上，根据应用的特性预留一定数量的FD，而不能把所有的FD都给客户端TCP连接使用。</p><p>有赞在线上压测时，一个应用就碰到过类似的一个问题。压测期间，压力比较高，导致磁盘IO压力增高，请求处理延迟增高，导致客户端超时。客户端发现超时关闭连接，创建新连接重试，但此时服务端由于IO阻塞带来的延迟并未能够及时回收连接关闭（CLOSE_WAIT）的socket以及FD，导致FD消耗越来越多，最终导致FD耗尽，新日志文件创建失败，而该应用又是存储类型应用，强依赖于日志落盘，最终导致服务不可用。</p><p>除了服务端限制最大连接数外，如果应用有对应的客户端SDK，最好也在客户端SDK也做一层保护。</p><h2 id="3-降低网络读写系统调用次数"><a href="#3-降低网络读写系统调用次数" class="headerlink" title="3. 降低网络读写系统调用次数"></a>3. 降低网络读写系统调用次数</h2><p>当我们调用read&#x2F;write系统函数从socket读写数据时，每次调用都至少进行两次用户态与内核态的上下文切换，成本比较高。针对该问题，一般有两种优化思路：</p><ul><li>使用读写缓冲区；读数据时，先一次性从socket读入缓冲区，然后再按需要分次从缓冲区读取；写数据时，先分次写入缓冲区，缓冲区满时或所有写操作完成时，一次性写入socket。</li><li>当不方便将数据合并到连续内存时，使用readv&#x2F;writev一次性读取&#x2F;写入多段内存数据。</li></ul><p>对于批量写操作还有一个优点，就是可以避免<a href="https://en.wikipedia.org/wiki/Nagle's_algorithm">Nagle算法</a>带来的延迟（一般也不建议开启Nagle算法）。假如当前写缓冲区中没有数据，我们先通过write写4个字节，这时TCP协议栈将其发送出去，然后再通过write写96个字节，这时，由于前面发送了一个报文，还没有收到ACK，并且当前可发送数据未达到MSS，Nagle算法不允许继续发送报文，必须等到前一个报文的ACK回来才能继续发送数据，大大降低了吞吐量并且提高了延迟。如果接收端开启了<a href="https://en.wikipedia.org/wiki/TCP_delayed_acknowledgment">延迟ACK</a>，影响更大。</p><p>因此，应该尽量批量读写网络数据，以提升性能。</p><h2 id="4-TIME-WAIT解析"><a href="#4-TIME-WAIT解析" class="headerlink" title="4. TIME_WAIT解析"></a>4. TIME_WAIT解析</h2><p><img src="/image/TCP%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%AE%9E%E8%B7%B5/tcp_state.png" alt="img"></p><h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><p>我们从上面的图中可以看出来，当 TCP 连接主动关闭时，都会经过 TIME_WAIT 状态。而且我们在机器上 curl 一个 url 创建一个 TCP 连接后，使用 ss 等工具可以在一定时长内持续观察到这个连接处于 TIME_WAIT 状态。</p><p>所以TIME_WAIT 是这么一种状态：TCP 四次握手结束后，连接双方都不再交换消息，但主动关闭的一方保持这个连接在一段时间内不可用。</p><h3 id="原因"><a href="#原因" class="headerlink" title="原因"></a>原因</h3><p>上文中提到过，对于复杂的网络状态，TCP 的实现提出了多种应对措施，TIME_WAIT 状态的提出就是为了应对其中一种异常状况。</p><p>为了理解 TIME_WAIT 状态的必要性，我们先来假设没有这么一种状态会导致的问题。暂以 A、B 来代指 TCP 连接的两端，A 为主动关闭的一端。</p><ol><li><p>在四次挥手中，A 发 FIN， B 响应 ACK，B 再发 FIN，A 响应 ACK 实现连接的关闭。而如果 A 响应的 ACK 包丢失，B 会以为 A 没有收到自己的关闭请求，然后会重试向 A 再发 FIN 包。如果没有 TIME_WAIT 状态，A 不再保存这个连接的信息，收到一个不存在的连接的包，A 会响应 RST 包，导致 B 端异常响应。此时， TIME_WAIT 是为了保证全双工的 TCP 连接正常终止。</p></li><li><p>我们还知道，TCP 下的 IP 层协议是无法保证包传输的先后顺序的。如果双方挥手之后，一个网络四元组（src&#x2F;dst ip&#x2F;port）被回收，而此时网络中还有一个迟到的数据包没有被 B 接收，A 应用程序又立刻使用了同样的四元组再创建了一个新的连接后，这个迟到的数据包才到达 B，那么这个数据包就会让 B 以为是 A 刚发过来的。此时， TIME_WAIT 的存在是为了保证网络中迷失的数据包正常过期。</p></li></ol><p>由以上两个原因，TIME_WAIT 状态的存在是非常有意义的。</p><h3 id="时长的确定"><a href="#时长的确定" class="headerlink" title="时长的确定"></a>时长的确定</h3><p>由原因来推实现，TIME_WAIT 状态的保持时长也就可以理解了。确定 TIME_WAIT 的时长主要考虑上文的第二种情况，保证关闭连接后这个连接在网络中的所有数据包都过期。</p><p>说到过期时间，不得不提另一个概念: <strong>最大分段寿命</strong>（MSL, Maximum Segment Lifetime），它表示一个 TCP 分段可以存在于互联网系统中的最大时间，由 TCP 实现，超出这个寿命的分片都会被丢弃。</p><p><code>TIME_WAIT</code> 状态由主动关闭的 A 来保持，那么我们来考虑对于 A 来说，可能接到上一个连接的数据包的最大时长：A 刚发出的数据包，能保持 MSL 时长的寿命，它到了 B 端后，B 端由于关闭连接了，会响应 RST 包，这个 RST 包最长也会在 MSL 时长后到达 A，那么 A 端只要保持 TIME_WAIT 到达 2MS 就能保证网络中这个连接的包都会消失。</p><p>MSL 的时长被 RFC 定义为 2分钟，但在不同的 unix 实现上，这个值不并确定，我们常用的 centOS 上，它被定义为 30s，我们可以通过 <code>/proc/sys/net/ipv4/tcp_fin_timeout</code> 这个文件查看和修改这个值。</p><h2 id="RELATED-READ"><a href="#RELATED-READ" class="headerlink" title="RELATED READ"></a>RELATED READ</h2><p><a href="https://tech.youzan.com/you-zan-tcpwang-luo-bian-cheng-zui-jia-shi-jian/">有赞TCP网络编程最佳实践</a></p>]]></content>
    
    
    <categories>
      
      <category>NetWork</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Fault-Tolerant Virtual Machines</title>
    <link href="/2022/03/30/Paper/Fault-Tolerant%20Virtual%20Machines/"/>
    <url>/2022/03/30/Paper/Fault-Tolerant%20Virtual%20Machines/</url>
    
    <content type="html"><![CDATA[<p>The Design of a Practical System for Fault-Tolerant Virtual Machines - 基于容错虚拟机的实用系统设计</p><span id="more"></span><p><a href="https://riverferry.site/2021-02-12-The-Design-of-a-Practical-System-for-Fault-Tolerant-Virtual-Machines/">原文翻译地址在这里</a></p><p><a href="https://pdos.csail.mit.edu/6.824/papers/vm-ft.pdf">原始论文地址 2010</a></p><h2 id="ABSTRACT"><a href="#ABSTRACT" class="headerlink" title="ABSTRACT"></a>ABSTRACT</h2><p>通过提供故障容错性的虚拟机，我们已经实现了一个商业化的企业级系统，它建立在复制一个主虚拟机的执行过程到另一个服务器上的备份虚拟机的基础上。我们已经在VMware vSphere4.0上设计了一个完整的系统，它运行在商业用的服务器上，很容易使用，同时保证了应用的性能仅有少于10%的降低。另外，为了让主VM和次级VM的执行活动保持一致，对于几个实际的应用而言，需要的数据带宽少于20Mbit&#x2F;s，这也允许实现更长距离的故障容错的可能性。一种容易使用，在故障后自动恢复备份的商业化系统，在复制VM执行之前需要额外的组件。我们已经设计并且实现了这些额外的组件，并且解决了在支持VM运行企业级应用的时候，遇到的许多实际问题。在这篇文章中，我们描述了我们基础的设计，讨论了可替代的设计选择和很多实现的细节，并且针对微基准和真实应用，提供了性能结果。</p><h2 id="1-INTRODUCTION"><a href="#1-INTRODUCTION" class="headerlink" title="1. INTRODUCTION"></a>1. INTRODUCTION</h2><p>一个实现容错服务器的常见方法是主备机制，如果主服务器失败，一个备份服务器总是可以进行接管。在任何时间，备份服务器的状态必须和主服务器几乎保持一致，因此当主服务器失败的时候，备份服务器可以立刻接管，此时对于外部客户端而言，故障就相当于被隐藏了起来，并且不会造成数据丢失。在备份服务器上复制状态的一种方法是将主服务器的所有状态，包括CPU、memory、IO设备，连续地送给备份服务器。然而，这种发送状态的方法，尤其是涉及到内存中的变更，其需要的带宽非常大。</p><blockquote><p>将 primary所有的状态，包括处理器、内存、IO 全部发送给backup；这种策略的困难在于，需要的带宽资源非常多，因为需要完全复制内存，内存上的数据都要发到 backup 上。</p></blockquote><p>另一种可以用更少带宽复制服务器的方法类似于状态机。这种思路是将服务器建模为确定性的状态机，他们从相同的初始状态开始，并且确保以相同的顺序接收相同的输入请求，这样就能保持同步。因为大多数服务器或服务有一些不确定性的操作，因此必须使用额外的协调机制来确保主备同步。然而，需要保持主备一致性的额外信息数目，远远少于正在变更的主服务器上状态（主要是内存更新）的数目。</p><blockquote><p>将主机视为确定性状态机，对于一个状态机，只有输入才能改变状态，没有输入状态是不会改变的。因此这种策略主要同步两台主机的输入，primary 和 backup 在同一个初始状态开始，让 primary 和 backup 获得相同的输入，这样两台主机就可以保持状态一致；这种策略的困难在于，处理同一个输入需要进行的操作具有不确定性，比如获取时钟，在 primary 上执行是一个结果，在 backup 上执行是另一个结果，这会导致两个主机的状态不一致。</p></blockquote><p>实现协调机制来确保物理服务器的确定性操作是困难的，尤其随着处理器频率增长。反之，一个运行在管理程序上的VM，是一个实现状态机方法的很好的平台。一个VM可以被当作一个定义好的状态机，它的操作是机器被虚拟化的操作（包括它所有的设备）。和物理服务器一样，VM有相同的非确定性操作（例如读取时钟或发送中断），因此为了保持同步，额外的信息必须被发送给备份服务器。管理程序有VM的全权控制权利，包括处理所有输入，因此它能够获得所有与主VM上的非确定性操作有关的必要信息，并且能正确地重放这些操作。</p><p>因此，这个状态机方法可以通过商业化软件上的VM来实现，它不需要硬件更改，允许在最新的微处理器上立刻实现故障容错。另外，状态机方法需要的低带宽允许了主备服务器能更好地进行物理分隔。例如，被复制的VM可以运行在横跨一个学校的物理机器上，相比于运行在同一建筑内的VM而言，可以提供更多的可靠性。</p><p>我们在VMware vSphere 4.0平台上使用主备机制实现了故障容忍的VMs，这个平台以一种高度有效的方式，运行着完全虚拟化的x86虚拟机。因为VMware vSphere实现了一个完整的x86虚拟机，所以我们自动地能够为任何x86操作系统和应用提供故障容忍。这种允许我们记录一个主服务器执行，并确保备份服务器一致执行的基础技术是<strong>确定性重放</strong><sup id="fnref:1" class="footnote-ref"><a href="#fn:1" rel="footnote"><span class="hint--top hint--rounded" aria-label="对于一系列输入，对主机的执行进行记录并确保备机以相同方式执行的基本技术称为确定性重放">[1]</span></a></sup>。VMware vSphere Fault Tolerance(FT)是基于确定性重放的，但是为了建立一个完整的故障容忍系统，还增加了必要的额外协议和功能。除了提供硬件故障容忍，我们的系统在一次失败后，通过在局部集群中任何可接受的服务器上开始一个新的备份虚拟机，进行自动地存储备份。目前确定性重放和VMare FT的产品版本只支持单处理器的VMs。多处理器VM的操作记录和重放还在开发中，因为每个共享内存的操作都是一个非确定性的操作，因此还有重要的性能问题待解决。</p><p>Bressoud和Schneider描述了一个针对HP PA-RISC平台的故障容忍VMs的原型实现。我们的方法是相似的，但是出于性能原因，以及在调查了许多可替代设计后，我们已经做了一些基础性的改变。另外，为了建立一个完整的系统，而这个系统是有效的并且能够被正在运行企业级应用的客户使用，我们已经设计并实现了系统中许多额外的组件，可以处理许多实际问题。与大多数其他实际系统讨论的类似，我们只尝试应付fail-stop的故障，这是一种服务器故障，可以在故障服务器造成一次不正确的外部可见行为之前被检测。</p><p>文章的剩余部分如下组织。首先，我们描述了我们基础的设计，并且详细说明了我们的基本协议，它能确保在主VM失败后，备份VM能够接替，且不会造成数据丢失。然后，我们描述了许多实际问题的细节，这些问题是为了建立一个强大的、完整的和自动化系统过程中必须被处理的。我们也描述了几个可用于实现故障容忍VMs的设计选择，并且讨论了这些选择的得失。接着，我们给出在一些基准以及实际企业级应用上的性能结果。最后，我们描述相关的工作和结论。</p><h2 id="2-BASIC-FT-DESIGN"><a href="#2-BASIC-FT-DESIGN" class="headerlink" title="2. BASIC FT DESIGN"></a>2. BASIC FT DESIGN</h2><img src="/image/Fault-Tolerant%20Virtual%20Machines/image-20220330204725217.png" style="zoom:50%;" /><p>图1展示了我们系统在故障容忍VMs的基本步骤。对于一个给定的VM，我们希望提供故障容忍（主VM），我们在一个完全不同的物理机器上运行一个备份VM，保持和主VM同步并且执行一致，虽然存在短时间的滞后。我们说这两个VM是同步的。 VM的虚拟磁盘位于共享存储上(例如Fibre Channel或iSCSI磁盘阵列)，因此主VM和备份VM可以共同访问它们的输入和输出。 (我们将在第4.1节中讨论主VM和备份VM具有独立的非共享虚拟磁盘的设计。) 只有主VM通知它在网络上的存在，因此所有网络输入都进入主VM。 类似地，所有其他输入(如键盘和鼠标)都只进入主VM。</p><p>主VM接收的所有输入都通过一个称为日志通道的网络连接发送到备份VM。 对于服务器工作负载，主要的输入流量是网络和磁盘。 为了确保备份VM以与主VM相同的方式执行非确定性操作，需要传输额外的信息(如下面的2.1节所述)。 结果是备份VM总是与主VM执行相同。 但是，备份VM的输出会被系统管理程序删除，因此只有主VM产生返回给客户机的实际输出。 如第2.2节所述，主VM和备份VM遵循特定的协议，包括备份VM的显式确认，以确保在主VM失败时不会丢失任何数据。</p><p>为了检测主VM或备份VM是否失败，我们的系统使用相关服务器之间的心跳和日志通道上的流量监控的组合。 此外，我们必须确保主VM或备份VM中只有一个接管执行，即使出现主服务器和备份服务器彼此失去通信的脑裂情况。</p><p>在下面的小节中，我们将提供几个重要领域的更多细节。 在第2.1节中，我们详细介绍了确定性重放技术，它确保主vm和备份vm通过日志通道发送的信息保持同步。 在第2.2节中，我们描述了我们的FT协议的一个基本规则，它确保在主节点失败时不会丢失数据。 在第2.3节中，我们描述了以正确的方式检测和响应故障的方法。</p><h3 id="2-1-Deterministic-确定性-Replay-Implementation"><a href="#2-1-Deterministic-确定性-Replay-Implementation" class="headerlink" title="2.1 Deterministic 确定性 Replay Implementation"></a>2.1 Deterministic 确定性 Replay Implementation</h3><p>如前所述，复制服务器(或VM)的执行可以建模为确定性状态机的复制。 如果两个确定性状态机以相同的初始状态启动，并以相同的顺序提供完全相同的输入，那么它们将经历相同的状态序列并产生相同的输出。 虚拟机有一组广泛的输入，包括传入的网络数据包、磁盘读取以及键盘和鼠标输入。 非确定性事件(如虚拟中断)和非确定性操作(如读取处理器的时钟周期计数器)也会影响VM的状态。 这给复制执行任何操作系统和虚拟机运行工作负载提出了三个挑战:(1)正确捕获所有必要的输入和非确定性,确保确定性执行备份虚拟机,(2)正确应用备份虚拟机的输入和非确定性,(3)这样的方式不会降低性能。 此外，x86微处理器中的许多复杂操作都有不确定的副作用。 捕获这些未定义的副作用并将其重新播放以产生相同的状态是一个额外的挑战。</p><p>VMware replay正是为VMware vSphere平台上的x86虚拟机提供了这一功能。 确定性重放来记录VM的输入和与VM执行相关的所有可能的不确定性，记录在日志文件的日志项流中。 稍后，通过从文件中读取日志项，可以准确地重放VM执行。 对于不确定的操作，将记录足够的信息，以允许使用相同的状态更改和输出复制操作。 对于不确定的事件，如定时器或IO完成中断，事件发生的确切指令也会被记录下来。 在重放期间，事件在指令流中的同一点被交付。 VMware确定性回放实现了一种高效的事件记录和事件传递机制，该机制采用了多种技术，包括使用与AMD和Intel联合开发的硬件性能计数器。</p><p>Bressoud和Schneider提到将VM的执行划分为epoch，在其中，诸如中断之类的非确定性事件只在epoch结束时交付。 epoch的概念似乎被用作一种批处理机制，因为它太昂贵了，不能在每个中断发生的确切位置上分别交付它们。 但是，我们的事件交付机制非常有效，VMware的确定性重放不需要使用epoch。 每次中断发生时都会被记录下来，并在回放时有效地按适当的指令进行传送。</p><h3 id="2-2-FT-Protocol-协议"><a href="#2-2-FT-Protocol-协议" class="headerlink" title="2.2 FT Protocol 协议"></a>2.2 FT Protocol 协议</h3><p>对于VMware FT，我们使用确定性重放来生成必要的日志项来记录主VM的执行，但是我们不将日志项写入磁盘，而是通过日志通道将它们发送到备份VM。 备份VM实时回放这些条目，因此与主VM执行相同。 但是，我们必须在日志通道上使用严格的FT协议来增加日志项，以确保实现容错。 我们的基本要求是:</p><blockquote><p>输出要求:如果备份 VM 在主要机器出现故障后接管，备份 VM 将继续执行，其执行方式将与主要 VM 发送到外部世界的所有输出完全一致。</p></blockquote><p>请注意，在发生故障转移之后(即，备份VM在主VM发生故障后接管)，备份VM的启动方式可能与主VM继续执行的方式非常不同，因为在执行期间会发生许多不确定的事件。 但是，只要备份VM满足输出要求，在故障转移到备份VM期间就不会丢失外部可见的状态或数据，客户机也不会注意到它们的服务中没有中断或不一致。</p><p>输出要求可以通过延迟所有外部输出(通常是网络包)直到备机已经接受了所有信息(允许备机重放到至少输出操作的时刻)的时候。一个必要的条件是备机必须已经接收了所有的输出操作事先生成的日志项。这些日志项能够让备机执行到最后的日志项的时刻。然而，如果一个故障在主机执行输出操作的时候立刻发生。备机必须知道它必须一直重放到输出操作的时刻然后在那个时刻仅仅上线(停止重放并接管主机，像2.3节描述的那样)。如果备机在输出操作之前的最后的日志项的时刻上线，一些不确定性事件(比如传递给虚拟机的时钟中断)可能改变执行路径，在执行输出操作之前。</p><p>鉴于上面的约束，执行输出要求的最简单方式是对每一个输出操作创建一个特殊的日志项。然后，输出要求可以通过这些特殊的规则被执行：</p><blockquote><p>输出规则：主机直到备机接收被确认了和产生输出相关联的日志项的时候，才发送输出给外部世界。</p></blockquote><p>如果备机已经接收了所有的日志项，包括输出产生操作的日志项，那么备机将能够准确的重现在该输出点上的主机的状态，即使主机宕了，备机仍能够正确的达到和该输出一致的状态。相反，如果备机在没有接收到所有必要的日志项的时候就接管了主机，则备机的状态可能很快偏离到和主机输出不一致的状态。输出规则在某些方面和提到的方法是类似的，其中外部同步IO可以被缓冲，只要在下一次外部通信前写入磁盘。</p><p>注意输出规则没有说任何要通知主机执行的事情。我们只需要延迟发送输出，但是虚拟机可以继续执行。因为操作系统通过异步中断来非阻塞的表示网络和磁盘输出的完成，所以虚拟机只需要继续执行，并且不一定会立即受到输出延迟的影响。相反，先前的工作[3,9]通常表明在完成输出之前主机必须完全停止，直到备机已经确认了所有来自主机的必要信息。</p><p><img src="/image/Fault-Tolerant%20Virtual%20Machines/image-20220331142544231.png" alt="Figure 2: FT Protocol"></p><p>作为例子，我们在图2中展示了一个图表说明容错协议的要求。该图展示了主机和备机上事件的时间线。主机线到备机线的箭头表示日志项的传输，备机线到主机线的箭头表示确认。异步事件的信息，输入，和输出操作都必须被发送给备机，以日志项的方式，然后由备机确认。如图中说明的那样，对于外部世界的输出会被延迟到主机已经接收到来自备机的确认信息，在备机收到和输出操作相关联的日志项的时候会进行确认。如果输出规则得以遵守，备机将能够以和主机最后输出一致性的状态进行接管。</p><p>如[3,9]所表示的，我们不能保证所有的输出都只被生成一次在故障转移的情况下。在主机尝试发送输出的时候不适用两阶段提交事务的话，就没有办法让备机判断主机是在崩溃之前还是之后发送了最后的输出。幸运的是，网络基础设施(包括常用的tcp)被设计为能够处理丢包和重包。</p><p>注意，传给主机的数据包在主机故障的时候也可能丢失因而不能被传递给备机。然而，传入的数据包可能出于一系列和服务器故障不相关的原因被丢弃，所以网络基础设施，操作系统和应用都被写入(意思应该是都要适配这个情况？ )来确保可以对丢失的包进行补偿。</p><h3 id="2-3-Detecting-and-Responding-to-Failure"><a href="#2-3-Detecting-and-Responding-to-Failure" class="headerlink" title="2.3 Detecting and Responding to Failure"></a>2.3 Detecting and Responding to Failure</h3><p>如前面提到的那样，主机和备机必须在另一方故障的时候快速响应。如果备机故障，主机将会上线-指的是离开记录模式(因此停止在日志通道上发送日志项)并开始正常运行。如果主机故障，备机也会上线，但是处理会更加复杂一点。因为备机是延迟执行的，备机可能有一系列它已经接受和确认的的日志项，但是还没被消费完因为备机还没达到运行的合适时间点。备机必须继续重放来自日志项的运行直到消费完最后的日志项。然后备机将会停止重放模式然后开始正常运行，像普通虚拟机那样。本质上，备机已经被晋升为了主机(现在没有备机了)。因为已经不是备机了，新的主机将在guest os(运行在虚拟机上的操作系统)有输出操作的时候产生输出给外部世界。在过渡为正常模式的期间，可能会需要一些特定设备的操作来让输出正确发生。特别的，出于联网的目的，VMware容错会自动将新的主机的mac地址在网络进行通告，所以物理网络交换机将能够得知新的主机服务器的位置。另外，新的晋升的主机可能需要重发一些磁盘IO(像3.4节描述的那样)。</p><p>对于尝试检测主机和备机故障有许多可能的方式。VMware容错使用运行在容错虚拟机上的服务器间的udp心跳包来检测哪台服务器已经宕掉了。另外，VMware容错监控从主机发给备机的日志和从备机发送给主机的确认信息的流量。因为经常的时钟中断，日志流量应该是规律的并且永远不会在guest os上停止。因此，日志项和确认信息流的暂停可能表明虚拟机或者网络问题引起的故障。如果心跳包或者日志通道流量停止了超过指定的超时时间(大约几秒钟)则表明这是故障。</p><p>然而，任何这类故障检测方法都容易收到脑裂问题的影响。如果备机停止从主机接收心跳包，可能意味着主机故障了，也可能只是因为仍在运行的服务器间的所有网络连接都丢失了。如果备机接着在主机仍旧运行的情况下上线，这可能引起数据损坏或者客户端与虚拟机通信的问题。因此，我们必须确保只有一台主机或备机上线，在故障被检测到的时候。为了避免脑裂的问题，我们使用用来存储虚拟机虚拟磁盘的共享存储。在主机或备机想上线的时候，在共享存储上执行一个原子的test-and-set锁指令。如果操作指令成功，则虚拟机可以上线。如果指令失败，则另外的虚拟机肯定仍在运行，所以当前的虚拟机实际上会结束运行(提交suicide).如果虚拟机无法访问共享存储，在尝试做原子操作指令的时候，只需要一直等到可以访问的时候。记住如果共享存储因为一些存储网络故障导致不能访问，那么虚拟机可能无论如何都不能正常工作，因为虚拟机磁盘也在共享存储上面。因此，使用共享存储来解决脑裂问题不会带来任何额外的不可用。</p><p>该设计的最后一个方面是一旦故障已经发生了并且其中一个虚拟机已经上线了，VMware容错会自动通过在另外主机上启动新的备机来恢复冗余。即使前面大部分没有提及这个过程，但是这一点对于实现有用的容错系统是基础的，并且需要仔细设计。更多的细节见3.1节。</p><h3 id="2-4-Go-live-Points"><a href="#2-4-Go-live-Points" class="headerlink" title="2.4 Go-live Points"></a>2.4 Go-live Points</h3><p>为了容错使用的确定性重放驱使我们在重放实现中增加了一种有趣的机制。因为会有网络问题以及主机故障可能发生在任何时刻，由备机正在读取或者重放的日志项流也可能在任何时刻终止。日志项在任何时刻终止的可能性会扩散到确定性重放的实现，因为每一个日志项(比如一个虚拟的设备实现)的潜在消费者都需要检查和处理所需日志不可用的问题。比如，给定一个之前的日志项和它现在的状态，虚拟设备实现可能需要一系列有关IO实现的额外的日志项。需要编写重放部分的代码来检查日志流的结束，退出一些可能复杂的重放代码，回复设备到合理的状态，使之可以在虚拟机上go live.</p><p>为了减轻系统上多数组件的负担，我们已经实现了go-live points.任何单个日志项都可以被标记为go-live points.这个思想是一个被标记为go-live point的日志项可以用来表示对于重放一个指令或者特别的设备操作必要的一系列日志项中的最后一个日志项。如果一个特别的操作或者指令需要一部分被记录的日志项，那么仅最后的日志项会被标记为go-live point.实际上，虚拟机管理程序会自动标记最后的一个新的日志项为go-live point,在它完成给定指令的所有事件和设备处理的时候。</p><p>go-live points在重放期间的使用如下。当所有从日志通道读取的日志项都被虚拟机管理程序缓存在正在重放的虚拟机上。只有最后的go-live point之前的日志项可以被重放的备机消费。也就是说，正在重放的虚拟机在消费最后一个被标记为go-live point的日志项之后会停止运行直到一系列包含go-live point的日志项已经被虚拟机管理程序拉取。结果是如果有一系列和设备操作关联的日志项，如果虚拟设备实现遇到了第一个日志项，就可以假定所有需要的日志项都是可用的。因此，虚拟设备实现不需要做所有额外的检查和恢复代码，如果日志项可以在任何时刻终止。类似的，任何代表虚拟机执行的单个指令生成多个日志项的时候，重放虚拟机的虚拟机管理程序仅在所有的对于完成指令仿真有必要的日志项都是可用的时候，才开始指令的模拟。标记方案不会对正在重放的虚拟机带来任何明显的延迟，因此记录(primary)虚拟机的虚拟机管理程序保证每一个模拟指令或者设备操作的最后的日志项被标记为go-live point.因此备机不会有明显的延迟，主机也不会受到go-live point的影响。</p><h2 id="3-PRACTICAL-IMPLEMENTATION-OF-FT"><a href="#3-PRACTICAL-IMPLEMENTATION-OF-FT" class="headerlink" title="3. PRACTICAL IMPLEMENTATION OF FT"></a>3. PRACTICAL IMPLEMENTATION OF FT</h2><p>第2节描述了容错的基础设计和协议。但是为了创建一个可用的，健壮的自动化系统，还需要设计实现许多其他组件。</p><h3 id="3-1-Starting-and-Restarting-FT-VMs"><a href="#3-1-Starting-and-Restarting-FT-VMs" class="headerlink" title="3.1 Starting and Restarting FT VMs"></a>3.1 Starting and Restarting FT VMs</h3><p>必须设计的最大的额外组件之一是以和主机相同的状态启动备机的机制。这个机制在故障发生重启备机的时候也会用到。因此，该机制对于运行任意状态(不仅仅是启动)的主机必须是可用的。另外，我们更希望该机制不会明显的打断主机的运行，因此这会影响到所有连接虚拟机的客户端。</p><p>对于VMware容错系统，我们适配了VMware vSphere的现有Vmotion功能。VMware VMotion可以在最小化中断的代价下将运行的虚拟机从一台服务器迁移到另一台服务器-虚拟机的暂停时间通常小于1秒。我们创建了一个修改版的Vmotion，通过在远端服务器上创建一个精确的虚拟机的运行拷贝，而不需要摧毁本地服务器上的虚拟机。也就是说，修改版的容错Vmotion克隆一个虚拟机到远端服务器而不是迁移虚拟机。容错Vmotion也会建立一个日志通道，源虚拟机会作为主机进入日志模式，目的虚拟机作为新的备机进入重放模式。和普通版本的Vmotion一样，容错Vmotion通常打断主机的时间少于1秒。因此，在运行中虚拟机启用容错是简单，无中断的操作</p><p>启动备机的另一个方面是选择哪台服务器来运行。容错虚拟机运行在访问共享存储的服务器集群上，因而所有的虚拟机是运行在集群中任意的服务器的。这种灵活性让VMware vSphere能够恢复容错冗余在一台或者多台服务器故障的时候。VMware vSphere实现了一个集聚服务来维护管理和资源信息。当故障发生而主机需要一个新的备机重建冗余的时候，主机会通知集聚服务它需要一个新的备机。集聚服务基于资源申请，使用和其他约束来选择运行备机的最佳服务器。然后集聚服务自动调用容错Vmotion来创建新的备机。当然，也有许多额外的复杂性，比如在第一次创建备机失败后的重试，和自动检测集群中服务器什么时候变为新的可用状态。最后的结果是VMware容错可以重建虚拟机冗余在服务器故障后几分钟，而不会对容错虚拟机执行有明显的打断。</p><h3 id="3-2-Managing-the-Logging-Channel"><a href="#3-2-Managing-the-Logging-Channel" class="headerlink" title="3.2 Managing the Logging Channel"></a>3.2 Managing the Logging Channel</h3><p>管理日志通道的流量有一系列有趣的实现细节。在我们实现中，虚拟机管理程序维护了一个大的缓冲，保存了主机和备机的日志项。当主机运行的时候，会产生日志项到日志缓冲，类似的，备机从日志缓冲消费日志项。主机日志缓冲的内容会尽快刷到日志通道中，日志项写到日志缓冲后也会尽快读取到备机的日志缓冲中。备机发送确认信息给主机，在每一次通过网络读取一些日志项到日志缓冲的时候。这些确认信息让VMvare容错能够决定什么时候被输出规则延迟的输出可以被发送。图3说明了这个过程。</p><p><img src="/image/Fault-Tolerant%20Virtual%20Machines/Snipaste_2021-02-17_23-19-37_water.jpg" alt="Figure 3: FT Logging Buffers and Channel"></p><p>如果备机在读取新的日志项的时候遇到了空的日志缓冲，则会停止运行直到日志项变为可用。因为备机不是在外部通信，这种暂停不会对虚拟机的客户端有影响。相似的，如果主机在需要写入日志项的时候发现复制缓冲满了，也会停止运行直到日志项被清除了。主机的停止是自然的流控机制，可以在生成的日志项速率过快的时候降低速度。然而，这种暂停会影响虚拟机的客户端，因为主机会完全停止变为不响应知道可以写入日志继续运行的时候。因此，我们的实现必须设计为最小化主机日志缓冲满的可能性。</p><p>主机日志缓冲满的一个原因是日志通道的带宽太小以至于无法承载正在生成的日志项的容量。因为日志通道的带宽通常不太高(见第5节)，我们强烈建议对于日志通道使用1Gbit&#x2F;s的网络来避免网络瓶颈。</p><p>主机缓冲满的另一个可能原因是备机执行过慢以至于消费日志项太慢。通常，备机必须能以和主机记录执行大致相同的速度重放执行。幸运的是，VMware确定性重放中记录和重放的负载是大致相同的。然而，如果承载备机的服务器也加载了其他的虚拟机(因此使用资源过渡)，备机可能无法获得足够的cpu和内存资源以和主机相同的速度执行，即使备机虚拟机管理程序的虚拟机调度器尽最大的努力。</p><p>除了避免在日志缓冲满时不希望的暂停，还有另外原因是我们不希望执行的滞后变得太大。如果主机故障了，备机必须通过重放它在之前已经确认的所有日志项来“追赶”主机，再成为主机上线。结束重放的时间基本上是故障点的执行滞后时间。因此，备机上线的时间大致等于故障检测时间加上当前执行滞后时间。所以，我们不希望执行滞后时间太大(超过1秒)，因为这将明显的增加故障转移的时间(备机上线的时间)。</p><p>因此，我们有一个额外的机制来减慢主机的速度，避免备机落后太多。在发送和确认日志项的协议中，会发送额外的信息来决定实时的运行延迟，在主机和备机之间。通常执行延迟少于100毫秒。如果备机开始有了明显的执行延迟(比如超过1秒)，VMware容错会开始减慢主机的速度，通过通知调度器给主机更少的cpu份额(初始时只有百分之几)。我们使用一个慢反馈环，会逐渐的精确化对于主机的cpu份额来让备机追上主机的运行。如果备机仍旧落后，我们会继续降低主机的cpu份额。相反的，如果备机追上了主机，我们会逐渐的增加主机的cpu份额直到备机返回微小的延迟。</p><p>注意对于主机的减速是很罕见的，通常只在系统处于极端压力的情况下发生。第5节的所有性能数字包含了这些减速的成本。</p><h3 id="3-3-Operation-on-FT-VMs"><a href="#3-3-Operation-on-FT-VMs" class="headerlink" title="3.3 Operation on FT VMs"></a>3.3 Operation on FT VMs</h3><p>另一个实际的问题是处理多种可能被应用于主机的控制操作。比如，当主机显式关机的时候，备机也应该关机，而不是尝试上线。另一个例子，主机上任何的资源管理改变(比如增加了cpu份额)也应该应用到备机。对于这些操作，特殊的控制项会通过日志通道从主机发送给备机，为了在备机上也应用适当的操作。</p><p>通常，虚拟机的多数操作仅在主机上初始化。VMware容错会发送所有必要的控制项在备机上应用适当的变更。唯一可以在主机和备机上独立执行的操作是VMotion.也就是说，主机和备机可以分别独立的Vmotiond到其他主机。注意，VMware容错确保主机和备机都不会被VMotioned到对方所在的服务器上，因为这种情况下不再提供容错。</p><p>主机的Vmotion相对于普通Vmotion增加了一些复杂性，因为备机必须和源主机断开连接然后在合适的时间重新连接到目的主机。备机的VMtion有相同的问题，但是增加了额外的复杂性。对于普通的Vmotion,我们要求所有未完成的磁盘IO都暂停(即完成)就像VMotion上发生的最终切换。对于主机，这种暂停容易处理，可以一直等待直到物理IO完成并发送完成信息给虚拟机。然而，对于备机，没有简单的方法在任何需要的时间点让所有IO完成，因为备机必须重放主机的执行并且在相同的执行点完成IO.主机可以运行在总是有磁盘IO的工作负载上，在正常运行期间。VMware容错有独特的方法解决这个问题。当备机在VMotion的最终切换点的时候，它通过日志通道要求主机临时停止所有的IO.备机的IO也会在单独的执行点上自然的暂停，因为备机会重放主机暂停操作的执行命令</p><h3 id="3-4-Implementation-Issues-for-Disk-IOs"><a href="#3-4-Implementation-Issues-for-Disk-IOs" class="headerlink" title="3.4 Implementation Issues for Disk IOs"></a>3.4 Implementation Issues for Disk IOs</h3><p>有一些和磁盘IO相关的细微的实现问题。首先，非阻塞的磁盘操作可以并行执行，因此对同一磁盘位置的同时访问可能导致不确定性。我们对磁盘IO的实现使用DMA直接读写虚拟机内存，所有对于相同内存页的同时访问也可能导致不确定性。我们的解决方案通常是检测所有这类IO竞争(是很罕见的)，然后强制这些竞争的磁盘操作以相同的方式在主机和备机上顺序执行。有趣的是，单个磁盘读取操作也可能造成竞争，因为散聚的阵列可能引用相同的内存块多次，而导致内存页的内容变得不确定性。我们的解决方案还是检测这些竞争，保证在这种情况下最后的内存内容会在日志通道上发送，这样备机可以以相同的内存内存结束。</p><p>第二，虚拟机上的应用程序(或操作系统)的有关内存访问的磁盘操作也可能产生竞争，因为磁盘操作直接通过DMA访问内存。比如，如果虚拟机中的应用程序&#x2F;操作系统在读取内存块的同时读取该块的磁盘，则可能会导致不确定性。这种情况也是类似的，但是我们必须检测并在它发生的时候解决它。我们的解决方案是设置临时的页保护在由磁盘操作的页上。如果虚拟机碰巧对未完成磁盘操作的标记页进行访问则页保护最终会进入陷阱，虚拟机会被暂停直到磁盘操作完成。因为修改页上的MMU保护是昂贵的操作，所以我们使用了bounce buffers. bounce buffer是磁盘操作正在访问的内存大小一致的临时缓冲。磁盘读操作被修改为在bounce buffer中读取特定数据，并且数据仅在IO操作完成并被传递的时候拷贝到虚拟机内存。类似的，对于磁盘写操作，将要被发送的数据会先拷贝到bounce buffer,磁盘写操作被修改为写数据到bounce buffer. bounce buffer的使用能够减慢磁盘操作，但是我们还没有看到任何明显的性能差异。</p><p>第三，当主机故障的时候在主机上可能会有一些未完成的和磁盘IO相关的问题，而备机进行了接管。对新提升的主机就没有办法确定磁盘IO被发布到磁盘还是已经成功完成。另外，因为磁盘IO没有在外部的备机进行发布，当新提升的主机继续运行的时候，不会有明确的IO完成，最终可能导致虚拟机的虚拟机操作系统开始终止或者重置程序。因此，我们希望确保对于每一个挂起的IO，将完成信息发送给虚拟机。我们可以发送错误完成信息来表明IO失败，因为即使IO成功完成，返回错误也是可接受的。然而，虚拟机操作系统可能不会从本地磁盘很好的响应错误。相反，我们在虚拟机go-live的过程重新发布IO，因为我们已经消除了所有的竞争并且所有的IO直接指定了要访问的内存和磁盘块，这些磁盘操作可以重新发布即使已经成功完成了（即是幂等的)。</p><h3 id="3-5-Implementation-Issues-for-Network-IO"><a href="#3-5-Implementation-Issues-for-Network-IO" class="headerlink" title="3.5 Implementation Issues for Network IO"></a>3.5 Implementation Issues for Network IO</h3><p>VMware vSphere对于虚拟机网络提供了许多性能优化。多数这些优化是基于虚拟机管理程序异步更新虚拟机网络设备的状态。比如，在虚拟机运行的时候接收缓冲区可以被虚拟机管理程序直接更新。不幸的是，这种对于虚拟机状态的异步更新增加了不确定性。除非我们能够保证所有的更新在主机和备机的指令流同时发生，否则备机的执行可能和主机不同。</p><p>对于容错的网络仿真代码的最大改变是消除了异步网络优化。所有对于虚拟机网络状态的更新必须在虚拟机不执行指令的时候完成，以便我们可以记录更新日志并在备机上指令流的同一点重放。异步更新虚拟机ring buffer的代码被修改为强制guest陷入到虚拟机管理程序，在虚拟机管理程序里可以更新然后应用更新日志带虚拟机。类似的，之前异步拉取传输队列的包的代码被容错禁用了，取而代之的我们要求通过陷入到虚拟机管理程序来完成传输(如下所示)。</p><p>网络设备异步更新的消除和2.2节描述的发送包的延迟，为网络的性能带来了挑战。我们已经使用两种方法来提高运行容错的虚拟机的网络性能。首先，我们实现了集群优化以减少虚拟机的陷阱和中断。当我们以足够的比特率传输数据，我们可以对于每一组包进行一次传输陷阱，最好的情况下是0陷阱，因为我们将包作为新接收的包的一部分进行传输。同样的，我们通过对每一组包发送一次中断，来降低对于传入包的虚拟机的中断次数。</p><p>我们对于网络的第二个性能优化涉及降低传输包的延迟。如前面提到的，我们必须延迟所有的传输包直到获取了备机的确认信息，在备机接受到合适的日志项。降低传输延迟的关键是减少向备份发送日志消息并获得确认所需的时间。我们在这个方面的主要优化设计确保发送接受日志项和确认信息都在不发生线程上下文切换的情况下完成。VMware vSphere虚拟机管理程序允许函数被注册为TCP栈，任何接收到tcp数据的时候，将在推迟执行上下文中调用(类似linux的软中断)。这允许我们在备机上快速处理所有的输入日志项和由主机收到的确认信息，而不会发生任何的线程上下文切换。另外，当主机将需要被传输的包入队，我们通过调度延迟执行上下文来将需要立即刷新的和输出日志项关联的日志进行刷新。</p><h2 id="4-DESIGN-ALTERNATIVES-替代方案"><a href="#4-DESIGN-ALTERNATIVES-替代方案" class="headerlink" title="4 DESIGN ALTERNATIVES 替代方案"></a>4 DESIGN ALTERNATIVES 替代方案</h2><h2 id="RELATED-READ"><a href="#RELATED-READ" class="headerlink" title="RELATED READ"></a>RELATED READ</h2><p><a href="https://www.cnblogs.com/zzk0/p/13504580.html">[1] 楷哥的论文笔记</a></p><p><a href="https://www.cnblogs.com/brianleelxt/p/13245754.html">[2] BrianLeeLXT的论文研读</a></p><section class="footnotes"><div class="footnote-list"><ol><li><span id="fn:1" class="footnote-text"><span>对于一系列输入，对主机的执行进行记录并确保备机以相同方式执行的基本技术称为确定性重放<a href="#fnref:1" rev="footnote" class="footnote-backref"> ↩</a></span></span></li></ol></div></section>]]></content>
    
    
    <categories>
      
      <category>Paper</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>MIT 6.824</title>
    <link href="/2022/03/29/Class%20Note/MIT%206.824/"/>
    <url>/2022/03/29/Class%20Note/MIT%206.824/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    <categories>
      
      <category>Class Note</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>GFS</title>
    <link href="/2022/03/29/Paper/GFS/"/>
    <url>/2022/03/29/Paper/GFS/</url>
    
    <content type="html"><![CDATA[<p>Google File System，一个适用于大规模分布式数据处理相关应用的，可扩展的分布式文件系统。</p><span id="more"></span><p><a href="https://www.cnblogs.com/guoyongrong/p/3700970.html">原文翻译地址网址 GFS论文中文翻译</a></p><p><a href="https://static.googleusercontent.com/media/research.google.com/zh-CN//archive/gfs-sosp2003.pdf">原始论文地址 2003</a></p><h2 id="ABSTRACT"><a href="#ABSTRACT" class="headerlink" title="ABSTRACT"></a>ABSTRACT</h2><p>我们已经设计和实现了Google File System，一个适用于大规模分布式数据处理相关应用的，可扩展的分布式文件系统。它基于普通的不算昂贵的硬件设备，实现了容错的设计，并且为大量客户端提供极高的聚合处理性能。 </p><p>我们的设计目标和上一个版本的分布式文件系统有很多相同的地方，我们的设计是依据我们应用的工作量以及技术环境来设计的，包括现在和预期的，都有一部分和早先的文件系统的约定有所不同。这就要求我们重新审视传统的设计选择，以及探索究极的设计要点。 </p><p>该文件系统已经成功地满足了我们的存储需求。它被广泛地部署在Google内部，作为存储平台，用于生成和处理我们的服务器使用的数据，以及需要大量数据集的研究和开发工作。迄今为止，最大的集群在超过一千台计算机上提供了跨越数千个磁盘的 tb 级存储，并且可以同时被数百个客户端访问。</p><p>在这个论文里，我们展示了用于支持分布式应用的扩展文件系统接口设计，讨论了许多我们设计的方面，并且列出了我们的 micro-benchmarks 以及真实应用性能指标。</p><p><strong>分类和主题描述</strong></p><p>D [4] : 3 – 分布式文件系统</p><p><strong>普通条目</strong></p><p>Design，reliability，performance，measurement</p><p><strong>关键词</strong></p><p>容错，扩展性，数据存储，集群数据存储</p><h2 id="1-INTRODUCTION"><a href="#1-INTRODUCTION" class="headerlink" title="1. INTRODUCTION"></a>1. INTRODUCTION</h2><p>我们设计并实施了 Google File System (GFS)，以满足谷歌数据处理需求迅速增长的需求。GFS 和上一个分布式文件系统有着很多相同的设计目标，比如性能、可伸缩性、可靠性、以及可用性。不过，他的设计是基于我们应用的工作量和技术环境驱动的，包括现在和预期的，都有部分和上一个版本的约定有点不同。这就要求我们重新审视传统的设计选择，以及探索究极的设计要点。</p><p>首先，组件故障是常态而不是例外。该文件系统由数百甚至数千个存储机器组成，这些存储机器由廉价的普通机器组成，可供相当数量的客户机访问。这些节点的质量和数量实际上都确定了在任意给定时间上，一定有一些会处于失效状态，并且某一些并不会从当前失效中恢复回来。这有可能由于程序错误、操作系统错误、人为错误以及硬盘、内存、网络、插板、电源故障等等。因此，持续监视、错误检测、容错处理、自动恢复必须是系统的一部分。</p><p>其次，按照传统的标准，文件是巨大的。数个GB的文件很常见。每个文件通常包含许多应用对象，例如web文档。当我们定期处理包含数十亿对象的快速增长的多个TBs数据集时，即使文件系统能够支持它，管理数十亿个kb大小的文件也是很难操作的。因此，必须重新考虑设计约定和参数，如i&#x2F;o操作和块大小。</p><p>第三，大多数文件是通过附加新数据而不是覆盖现有数据而变化的。文件中的随机写入实际上是不存在的。一旦写好，这些文件只能被读取，而且通常只有顺序。各种各样的数据都有这些特性。有些可能构成数据分析程序扫描的大型存储库。有些可能是通过运行应用而不断生成的数据流。有些可能是归档数据。有些是一个机器为另一个机器产生的中间结果，另一个机器及时或者随后处理这些中间结果。对于这些巨型文件的访问模式来说，增加模式是最重要的，所以我们首要优化性能的以及原子操作保证的就是它，而缓存客户端中的数据块将失去其吸引力。</p><p>第四，与应用一起设计的的文件系统API对于增加整个系统的灵活性有很大的好处。例如我们不用部署复杂的应用系统就可以把GFS应用到大量的简单文件系统基础上。我们也引入了原子的增加操作，这样可以让多个客户端同时操作一个文件，而不需要他们之间有额外的同步操作。这些在本论文的后边章节有描述。 </p><p>为了不同的目的，目前部署了多个 GFS 集群。其中最大的一个有超过1000个存储节点，超过300TB的磁盘存储，并且被数以百计的客户在不同的机器上大量访问。</p><h2 id="2-DESIGN-OVERVIEW"><a href="#2-DESIGN-OVERVIEW" class="headerlink" title="2. DESIGN OVERVIEW"></a>2. DESIGN OVERVIEW</h2><h3 id="2-1-Assumptions-约定"><a href="#2-1-Assumptions-约定" class="headerlink" title="2.1 Assumptions 约定"></a>2.1 Assumptions 约定</h3><p>在为我们的需求设计一个文件系统时，在为我们的需求设计一个文件系统时，我们一直受到既带来挑战又带来机遇的事先约定。我们早先提到的关于观测到的关键要点，现在详细用约定来说明。</p><ul><li><p>系统是建立在大量廉价的普通计算机上，这些计算机经常故障。必须对这些计算机持续进行检测，并且在系统的基础上进行：检查、容错、以及从故障中进行恢复。</p></li><li><p>系统存储了大量的超大文件。我们预计有好几百万个文件，每一个超过100MB。数GB的文件经常出现并且需要进行有效的管理。小文件必须支持，但我们不需要为它们进行优化</p></li><li><p>一般的工作都是由两类读取组成：大的流式读取和小规模的随机读取。在大的流式读取中，每个读操作通常要读取几百k的数据，每次读取1M或者以上的数据也很常见。对于同一个客户端来说，往往会发起连续的读取操作顺序读取一个文件。小规模的随机读取通常在文件的不同位置，读取几k数据。对于性能有过特别考虑的应用通常会作批处理并且对他们读取的内容进行排序，这样可以使得他们的读取始终是单向顺序读取，而不需要往回读取数据。</p></li><li><p>通常基于GFS的操作都有很多超大的，顺序写入的文件操作。通常写入操作的数据量和读取的数据量相当。一旦完成写入，文件就很少会更改。支持文件中任意位置的小写操作，但是不需要为此作特别的优化。</p></li><li><p>系统必须非常有效的、明确细节的对多客户端并行添加同一个文件进行支持。我们的文件经常使用生产者&#x2F;消费者队列模式，或者作为多路合并模式进行操作。好几百个运行在不同机器上的生产者，将会并行增加一个文件。其本质就是最小的原子操作的定义。读取操作可能接着生产者操作进行，消费者会同时读取这个文件。</p></li><li><p>高性能的稳定带宽的网络要比低延时更加重要。我们的目标应用程序一般会大量操作处理比较大块的数据，并且很少有应用要求某个读取或者写入要有一个很短的响应时间。</p></li></ul><h3 id="2-2-Interface"><a href="#2-2-Interface" class="headerlink" title="2.2 Interface"></a>2.2 Interface</h3><p>GFS提供了常见的文件系统的接口，虽然他没有实现一些标准的API比如 POSIX。文件是用 pathname 来通过目录进行分层管理的。我们支持的一些常见操作：create, delete, open, close, read, write。</p><p>另外，GFS有snapshot，record append等操作。snapshot创建一个文件或者一个目录树的快照，这个快照的耗费比较低。record append允许很多个客户端同时对一个文件增加数据，同时保证每一个客户端的原子性。这个对于多路合并操作和多个客户端同时操作的生产者&#x2F;消费者队列的实现非常有用，它不用额外的加锁处理。这种文件对于构造大型分布式应用来说，是不可或缺的。snapshot 和record append在后边的3.4 和3.3 节有单独讲述。</p><h3 id="2-3-Architecture"><a href="#2-3-Architecture" class="headerlink" title="2.3 Architecture"></a>2.3 Architecture</h3><p>GFS集群由一个 主节点和众多块服务器组成，GFS集群会有很多客户端访问 (图1)。每一个节点都是一个普通的Linux计算机，运行的是一个用户级别的服务器进程。只要机器资源允许，并且允许不稳定的应用代码导致的可靠性降低，我们就可以让块服务器和 client 可以运行在同一个机器上。 </p><p>在GFS下，每一个文件都拆成固定大小的 chunk。每一个都由 主节点根据其创建的时间产生一个全局唯一的以后都不会改变的64位的 chunk handle 标志。块服务器在本地磁盘上用Linux文件系统保存这些块，并且根据 chunk handle 和字节范围，通过Linux文件系统读写这些块的数据。出于可靠性的考虑，每一个块都会在不同的块服务器上保存备份。默认情况下，我们保存3个备份，不过用户可以对于不同的文件 namespace 区域，指定不同的复制级别。 </p><p>主节点负责管理所有的文件系统的元数据。包括 namespace、访问控制信息、文件到 chunk 的映射关系、当前 chunk 的位置等等信息。主节点也同样控制系统级别的活动，比如 chunk 的分配管理、孤立的 chunk 垃圾回收机制、块服务器之间的 chunk 镜像管理。主节点和这些块服务器之间会有定期的心跳机制进行通讯，以给出指令并收集其状态。 </p><p>连接到各个应用系统的GFS客户端代码包含了文件系统的API，并代表应用程序与 主节点和块服务器进行通信，读写数据。客户端与 主节点进行元数据交互的操作，但是所有的数据相关的通讯是直接和块服务器进行的。我们不提供 POSIX API，因此不需要对 Linux vnode 层进行深入研究。</p><p>客户端或者块服务器都不会缓存文件数据。客户端缓存机制没啥用处，这是因为大部分的应用都是流式访问超大文件或者操作的数据集太大而不能被缓存。不设计缓存系统使得客户端以及整个系统都大大简化了-少了缓存一致性问题(不过客户端会缓存元数据)。块服务器不需要缓存文件数据，因为 chunks 就像本地文件一样的被保存，所以 Linux 的 buffer cache 已经把常用的数据缓存到了内存里。</p><h3 id="2-4-Single-Master"><a href="#2-4-Single-Master" class="headerlink" title="2.4 Single Master"></a>2.4 Single Master</h3><p>拥有单一主节点能够极大的简化我们的设计，并且能使主节点根据整体的信息精确定位块（chunk）的位置以及进行复制决策。然而，我们必须最小化对主节点的读写操作，以此保证它不会成为系统的瓶颈。客户端不会通过主节点进行读写数据，相反，客户端询问主节点哪些块服务器需要进行联系，将这个数据缓存一段有限的时间，并直接与块服务器进行后面的操作交互。</p><p><img src="/image/GFS/WX20220329-180128@2x.png" alt="Figure 1: GFS Architecture"></p><p>让我们解释一下图1中的一个简单的读操作的交互。首先，使用固定的块大小，客户端将文件名和应用指定的字节偏移转换为文件块的索引。然后，它向主节点发送一个包含文件名和块索引的请求，主节点回复相应的块句柄和副本的位置。客户端使用文件名和块索引作为key缓存这条信息。</p><p>然后，客户端向其中的一个副本发送一个请求，大多数时会选择最近的那个。请求指定了块句柄和那个块的一个字节范围。在对相同块的后续读操作中，客户端无需额外的客户端-主节点交互，直到缓存信息过期或文件被重新打开。事实上，客户端通常在一个请求中询问多个块，主节点的回复也会包含紧跟在请求块后面的块的信息。在现实中，获取这些额外的信息在没有付出更多代价的情况下，可以减少一些将来的客户端-主节点的交互。</p><h3 id="2-5-Chunk-Size"><a href="#2-5-Chunk-Size" class="headerlink" title="2.5 Chunk Size"></a>2.5 Chunk Size</h3><p>块大小是关键的设计参数之一，我们选择了64MB，它比一般的文件系统的块大小大很多。每个块副本在块服务器上存储为一个普通的linux文件，并且只有在需要时才会扩大。惰性空间分配防止内存碎片造成空间的浪费，这可能是选择这么大的块大小的最具争议的一点。</p><p>采用大的块大小有几个重要的优点。第一，他能减少客户端与主节点的交互，因为对相同块的读和写操作只需要一次初始的请求，用于获取块的位置信息。对于我们的工作负载来说，这种减少更加明显，因为应用的大多数读和写文件操作都是顺序进行的。即使是小规模的随机读操作，客户端也能足够的缓存一个几TB工作集的所有位置信息。第二，由于大的块大小，客户端能在一个块上进行更多的操作，这样可以通过与块服务器在一段时间内保持一个TCP长连接来减少网络开销。第三，它减少了存储在主节点上的元数据，这样可以让我们将元数据存储在内存中，所带来的好处将在2.6.1中进行讨论。</p><p>另一方面，即使使用了惰性空间分配机制，采用大的块大小也有它自己的缺点。小文件包含较少的块，甚至只包含一个块。当有大量的客户端同时访问相同的文件时，存储这个块的块服务器将成为热点。在实际中，热点不是一个主要问题，因为我们的应用大多会顺序读取大量的包含多个块的文件。</p><p>然而，当GFS第一次用于一个批处理序列系统时，热点问题还是发生了：一个可执行文件以单个块的形式写入GFS，然后在数百台机器上同时启动。少量的存储这个文件的块服务器会由于数百台机器的同时访问而过载。我们通过提高可执行文件的复制因数和批队列处理系统应用交错启动的方法解决了这个问题。一个可能的长期解决方案是在这种情况下让客户端能够从其它的客户端读取数据。</p><h3 id="2-6-Metadata"><a href="#2-6-Metadata" class="headerlink" title="2.6 Metadata"></a>2.6 Metadata</h3><p>主节点存储了三种主要类型的元数据：文件和块的命名空间，文件到块的映射，以及每个块副本的位置。所有的元数据都保留在主节点的内存中。前两个类型（命名空间和文件到块的映射）通过将操作记录存储在本地磁盘上的日志文件中得以永久保存，并在远程的机器上进行日志备份。使用日志使我们能够简单可靠的更新主节点状态，并且不用担心由于主节点崩溃而造成的不一致性。主节点不会永久的保存块位置信息，相反，主节点会在启动时，以及有新的块服务器加入集群时，询问每个块服务器的块信息。</p><h4 id="2-6-1-In-Memory-Data-Structures"><a href="#2-6-1-In-Memory-Data-Structures" class="headerlink" title="2.6.1 In-Memory Data Structures"></a>2.6.1 In-Memory Data Structures</h4><p>由于元数据存放在内存中，所以主节点的操作非常快。此外，它也使主节点能够周期性的在后台简单有效的浏览整个系统的状态。这个周期性的浏览操作用于实现块的垃圾回收，块服务器出错后的重复制，以及均衡负载和磁盘空间使用的块迁移。4.3和4.4节会深入的讨论这些行为。</p><p>对于这种内存存储的方法有一个潜在的问题，块的数量和将来整个系统的容量受到主节点的内存大小限制。在实际中，这不是一个严重的问题，主节点为每个64MB大小的块保留不到64字节的元数据。大多数块都是满的，因为大多数文件都包含了多个块，只有最后一个块才可能被部分使用。相似的，每个文件命名空间数据通常也不到64字节，因为它使用前缀压缩来简洁的存储文件名。</p><p>即使是要支持更大的文件系统，为主节点增加额外的内存的花费，比起将元数据存放在内存中所带来的简单性、可靠性、有效性和扩展性来说，也是相当值得的。</p><h4 id="2-6-2-Chunk-Locations"><a href="#2-6-2-Chunk-Locations" class="headerlink" title="2.6.2 Chunk Locations"></a>2.6.2 Chunk Locations</h4><p>主节点不会永久保留哪些块服务器含有一个给定的块的记录，它只是简单的在启动时从块服务器获取这些信息，并能在此后保持最新状态，因为它控制所有的块分布，以及通过心跳消息监控块服务器的状态。</p><p>起初我们试图在主节点永久的保存块位置信息，但是我们决定在启动时向块服务器请求数据并在此后进行周期性更新的方法要简单很多。这消除了当块服务器加入或离开集群、更改名字、出错、重启等发生时，保持主节点和块服务器同步的问题。在一个包含数百个服务器的集群中，这些事件发生的很频繁。</p><p>理解这种设计决定的另一个方法是认识到一个块服务器对自身磁盘中含有或不含有哪些块有最终的话语权。这并不是表明要试图保持主节点上对这些信息的一致性视图，因为块服务器上的错误会造成其含有的块自动的消失（如，一个磁盘坏掉或不可用）或者是一个操作会改变块服务器的名字。</p><h4 id="2-6-3-Operation-Log"><a href="#2-6-3-Operation-Log" class="headerlink" title="2.6.3 Operation Log"></a>2.6.3 Operation Log</h4><p>操作日志包含了关键的元数据变化的历史记录，是GFS的核心。它不仅永久的记录了元数据，还能提供确定并发操作顺序的逻辑时间线服务。文件和块，连同它们的版本，都是由它们创建的逻辑时间唯一的、永久的进行标识的。</p><p>因为操作日志是临界资源，我们必须可靠的存储它，在元数据的变化进行持久化之前，客户端是无法看到这些操作日志的。否则，即使块本身保存下来，仍然有可能丢失整个文件系统或者客户端最近的操作。因此，我们将它复制到几个远程的机器上，并在将相应的操作刷新（flush）到本地和远程磁盘后回复客户端。主节点会在刷新之前批处理一些日志记录，因此减少刷新和系统内复制对整个系统吞吐量的影响。</p><p>主节点通过重新执行操作日志来恢复状态。为了使启动时间尽量短，我们必须保持日志较小。当日志超过一个特定的大小时，主节点会检查它的状态，以使它能够通过载入本地磁盘的最后一个检查点，并重新执行检查点（checkpoint）后的日志记录进行恢复。检查点是一个压缩B树类似的形式存储，能够直接映射到内存中，并且在用于命名空间查询时无需额外的解析。这大大提高了恢复速度，增加了可用性。</p><p>因为创建检查点需要一定的时间，所以主节点的内部状态会结构化为一种格式，在这种格式下，新检查点的创建不会阻塞正在进行的修改操作。主节点切换到新的日志文件，并通过另一个线程进行新检查点的创建。新检查点包括切换前所有的修改操作。对于一个有几百万文件的集群来说，创建一个新检查点大概需要1分钟。当创建完成后，它将写入本地和远程磁盘。</p><p>恢复只需要最近完成的检查点和在此之后的日志文件。老的检查点和日志文件能够被删除，但为了应对灾难性故障，我们会保留其中的一部分。检查点的失败不会影响恢复的正确性，因为恢复代码会探测并跳过未完成的检查点。</p><h3 id="2-7-Consistency-Model"><a href="#2-7-Consistency-Model" class="headerlink" title="2.7 Consistency Model"></a>2.7 Consistency Model</h3><p>GFS采用松弛一致性模型，能很好的支持高分布式应用，但同时保持相对简单，易于实现。我们现在讨论GFS的保障机制以及对于应用的意义。我们也着重描述了GFS如何维持这些保障机制，但将一些细节留在了其它章节。</p><h4 id="2-7-1-Guarantees-保障-by-GFS"><a href="#2-7-1-Guarantees-保障-by-GFS" class="headerlink" title="2.7.1 Guarantees(保障) by GFS"></a>2.7.1 Guarantees(保障) by GFS</h4><p>文件命名空间修改（如，创建文件）是原子性的。它们仅由主节点进行处理：命名空间锁保障了操作的原子性和正确性；主节点操作日志定义了这些操作的全局排序。</p><p><img src="/image/GFS/09113934-0769397dafac49b7950284959c0fcc38.png" alt="Table 1: File Region State After Mutation"></p><p>一个文件区域（region）在一个数据修改后的状态依赖于该修改的类型、成功或失败、以及是否为同步的修改。表1总结了修改的结果。如果所有的客户端无论从哪些副本读取数据，得到的数据都是相同的，则这个文件区域为一致的。在一个文件数据修改后，如果它是一致的，则这个区域已定义，客户端将看到被写入的全部内容。当一个修改没有受到并发写入操作的影响而成功时，那么影响到的区域已定义（隐含一致性）：所有的客户端将总会看到修改已经写入的内容。并发成功的修改使区域处于未定义，但一致的状态：所有的客户端将看到相同的数据，但是它可能不能反映出任意一个修改已写入的内容，通常，它是由一些来自多个修改操作的、混合的数据碎片组成的。一个失败的修改会造成区域的不一致性（因此也没有被定义）：不同的客户端在不同的时间可能会看到不同的数据。我们将在后面描述我们的应用如何区分已定义和未定义的区域。这些应用不需要更深入的区分不同未定义区域间的区别。</p><p>数据修改操作可能是写入或记录追加操作。一个写操作会将数据写入到应用指定的文件位置；即使有多个并发修改操作，一个记录追加操作会将数据（记录）至少一次的原子性的追加到文件，而具体的偏移量是由GFS选定的。（与其相比，一个通常的追加操作仅仅是将数据追加到客户端认为是当前文件结尾的位置。）偏移位置返回给客户端，并标明包含这个记录的已定义区间的开始位置。此外，GFS能够在文件中插入数据或复制记录，这些数据占据的文件区域被认为为非一致性的，数量通常比用户数据总量要小很多。</p><p>在一系列成功的修改操作后，被修改的文件区域被保证为是已定义的，并且包含了最后一次修改操作写入的数据。GFS通过以下措施完成上面行为：（a）在所有副本上按相同的顺序执行一个块上的修改操作（3.1），（b）使用版本号来检测并复制过期文件（4.5），这种过期可能是由于块服务器宕机而造成了部分修改丢失引起的。过期的副本不会再涉及修改操作，主节点也不会将该副本返回给客户端。它们会尽快的进行垃圾回收操作。</p><p>因为客户端缓存了块位置信息，它们可能会在位置信息更新前直接访问过期的副本。这个窗口是受缓存条目的超时时间和下一次文件的打开时间限制的，下一次文件打开才会对这个文件的所有块信息的缓存进行清理。此外，由于大多数文件都是只能追加的，一个过期的副本经常会返回一个过早结束的块而不是过期的数据。当一个读客户端再次与主节点查询时，它将会立即获得当前块的位置信息。</p><p>在一个修改操作成功执行完一段时间后，组件的失效依然能损坏或删除数据。GFS通过在主节点和所有块服务器间定期的握手来标识失效的块服务器，并通过校验和探测数据损坏（5.2）。一旦问题被发现，数据将会尽快的利用有效副本进行恢复（4.3）。只有在GFS反应之前，通常在几分钟之内，一个块的所有副本都丢失，这个块才会彻底的丢失。即使在这种情况下，它会变为不可用，而不是被损坏的数据：应用会接收到明确的错误码而不是损坏的数据。</p><h4 id="2-7-2-Implications-for-Applications"><a href="#2-7-2-Implications-for-Applications" class="headerlink" title="2.7.2 Implications for Applications"></a>2.7.2 Implications for Applications</h4><p>GFS利用一些简单的用于其它目的的技术实现了一个宽松的一致性模型：依赖追加而不是覆盖、检查点、以及写入自验证、自标识的记录。</p><p>实际中，我们所有的应用都是通过追加操作来修改文件，而不是覆盖。在一个典型的例子中，一个写操作生成一个文件，并从头到尾的写入数据。它将写入完数据的文件原子性的重命名为一个不变的名字，或者周期性的创建检查点，记录有多少执行成功的写操作。检查点也含有应用层的校验和。读操作仅验证并处理上一个检查点之后的文件区域，这个文件区域应该是已定义的。即使一致性和并发性问题，这个方法都很好的满足了我们的需求。追加写操作比随机写操作更有效率，对应用的错误更有弹性。检查点允许写操作逐步的进行重启，并防止读操作处理已成功写入但在应用角度没有完成的文件数据。</p><p>在另一个典型应用中，许多写操作并行的追加一个文件，如进行结果的合并或者作为一个生产者-消费者队列。记录追加方式的“至少一次追加”的特性保证了写操作的输出。读操作使用下面的方法处理偶尔的填充数据和重复数据。每个写操作写入的记录都包含了一些额外的信息，如校验和，以使这个记录能够被验证。一个读操作能够通过校验和识别并丢弃额外的填充数据和记录碎片。如果它不能处理偶而的重复数据（如，如果他们将引发非幂等的操作），它能通过记录中的唯一标识来进行过滤，这些标识通常用于命名相关的应用实体，如网页文档。这些记录I&#x2F;O的函数（除了删除重复数据）都在应用的共享库中，并且适用于Google其它的文件接口实现。于是，相同序列的记录，加上偶尔出现的重复数据，总是被分发到记录的读操作上。</p><h2 id="3-SYSTEM-INTERACTIONS-交互"><a href="#3-SYSTEM-INTERACTIONS-交互" class="headerlink" title="3. SYSTEM INTERACTIONS 交互"></a>3. SYSTEM INTERACTIONS 交互</h2><p>我们设计这个系统时，需要最小化所有操作与主节点的交互。依照这个前提，我们描述了客户端、主节点和块服务器如何进行交互，来实现数据的修改、原子记录追加，以及快照。</p><h3 id="3-1-Leases-租约-and-Mutation-Order"><a href="#3-1-Leases-租约-and-Mutation-Order" class="headerlink" title="3.1 Leases 租约 and Mutation Order"></a>3.1 Leases 租约 and Mutation Order</h3><p>一个修改操作是一个改变了内容或块的元数据的操作，如一个写操作或者一个追加操作。一个修改操作将在一个块的所有副本上进行。我们使用租约来保证一个一致性操作在副本间的顺序。Master将一个块租约授予副本中的某一个，我们称之为 primary。primary 对一个块的所有修改操作选择一个串行顺序，所有的副本在执行修改时都按照这个顺序。因此，<strong>全局的修改操作的顺序首先由 Master 选择的授予租约的顺序决定，然后由租约中 primary 分配的序列号决定</strong>。</p><p>租约机制的设计是为了最小化 Master 的管理开销，一个租约初始超时时间为60秒，然而，只要块正在被修改，primary 就能请求续约，并通常会收到主节点租约延长的响应。这些续约请求和授予都包含在主节点和所有块服务器间定期交换的心跳消息中。主节点有时会在租约到期之前尝试取消它（如，当Master想要禁止对一个被重命名的文件的修改操作时）。即使 Master 与 primary 失去通信，它也能在前一个租约到期后安全的将一个新租约授予另一个副本。</p><p><img src="/image/GFS/09113940-dc2039a6f61f42e3b167722bf203cde4.png" alt="Figure 2: Write Control and Data Flow"></p><p>在图2中，我们通过跟踪一个写操作的控制流的这些步骤，描述了这个过程：</p><ol><li><p>客户端询问 Master 哪个块服务器持有这个块的当前租约，以及这个块的其它副本位置。如果没有一个租约，则 Master 选择一个副本并授予一个租约（没有在图上显示）。</p></li><li><p>Master 回复客户端 primary 的标识，以及其它（secondary）副本的位置。客户端缓存这些数据用于以后的修改操作。只有当 primary 不可达或者接收到 primary 不再持有租约时才需要再一次请求主节点。</p></li><li><p>客户端将数据推送到所有的副本。一个客户端能够以任意顺序进行推送。每个块服务器将数据保存在内部的LRU缓存中，直到数据被使用或者过期被替换掉。通过对数据流和控制流的分流，我们能够通过基于网络拓扑来调度数据流，不管哪个块服务器为 primary，以此提高性能。3.2节将进一步讨论。</p></li><li><p>一旦所有的副本都确认接收到了数据，客户端将向 primary 发送一个写请求。这个请求确定了之前的数据被推送到了所有副本。primary为接收到的所有修改操作分配连续的序列号，这些操作可能来自多个客户端，序列号提供了严格的序列化，应用按序列号顺序执行修改操作，进而改变自己的状态。</p></li><li><p>primary 将写请求发送到所有的 secondary 副本上。每个 secondary 副本按照 primary 分配的相同的序列号顺序执行这些修改操作。</p></li><li><p>secondary 副本回复 primary ，表示它们已经完成了所有的操作。</p></li><li><p>primary 回复客户端。任意副本上的任意错误都将报告给客户端。在一些错误情况下，写操作可能在 primary 和一些 secondary 副本上执行成功。（如果失败发生在 primary，它将不会分片一个序列号，并且不会被传递。）客户端的请求被视为已经失败，这个修改的区域停留在不一致的状态上。我们的客户端代码通过重试失败的修改操作来处理这种错误。在从头开始重复执行之前，它将在3-7步骤上做几次尝试。</p></li></ol><p>如果一个应用的写操作数据很大或者跨越了一个块的边界，GFS客户端会将这个操作分割成几个写操作。这些操作都遵循上面描述的控制流，但是可能会被其它客户端上的请求打断或覆盖。因此，共享的文件区域可能最终包含不同客户端的数据碎片，尽管如此，所有的副本都是完全相同的，因为这些独立的写操作在所有副本上都按着相同的顺序成功执行。如2.7节所提到的那样，这使文件区域处于一个一致的但未定义的状态。</p><h3 id="3-2-Data-Flow"><a href="#3-2-Data-Flow" class="headerlink" title="3.2 Data Flow"></a>3.2 Data Flow</h3><p>为了有效的利用网络，我们将数据流和控制流分开。控制流从客户端到 primary 上，再到所有的 secondary 上，而<strong>数据则以管道形式、线性的沿一个精心设计的块服务器链进行推送</strong>。我们的目标是最大限度的使用每台服务器的网络带宽，避免网络瓶颈和高延迟，最小化推送所有数据的时间延迟。</p><p>为了有效利用每台机器的网络带宽，数据被线性的沿一个块服务器组成的链进行推送，而不是按着其它拓扑进行分发（如，树）。因此每台机器的出口带宽都用于以最快的速度传输数据，而不是分配给多个接收者。</p><p>为了尽可能的避免网络瓶颈和高延迟链路，每台机器只将数据推送给网络拓扑中最近的没有接收到数据的机器。假设客户端将数据推送给块服务器S1到S4。它将数据发送给最近的块服务器，成为S1，S1将数据推送给S2到S4中最近的块服务器，成为S2，类似的，S2将数据推送到S3或S4中距离S2较近的块服务器等等。我们的网络拓扑足够简单，可以通过IP地址来精确的估计距离。</p><p>最后，我们通过在TCP连接上使用管道传输数据来最小化时间延迟。一旦一个块服务器接收到数据，则马上开始进行数据推送。管道对我们的帮助很大，因为我们采用了全双工的交换网络。立刻推送数据不会降低数据的接收速率。在没有网络拥塞的情况下，将B个字节传输到R个副本的理想时间消耗为B&#x2F;T+RL，这里T是网络的吞吐量，L是两台机器间的传输延迟。我们的网络链路通常为100Mbps（T），并且L远小于1ms，因此，在理想情况下，1MB的数据能够在80ms内分发完成。</p><h3 id="3-3-Atomic-Record-Appends"><a href="#3-3-Atomic-Record-Appends" class="headerlink" title="3.3 Atomic Record Appends"></a>3.3 Atomic Record Appends</h3><p>GFS提供了一种原子性的追加操作称为记录追加。在传统的写操作中，客户端指定数据写入的偏移量，对同一个文件区域的并行写操作不能进行序列化：该区域最终可能包含来自多个客户端的数据片段。然而，在一个记录追加操作中，客户端只需要指定数据，GFS将数据至少一次的原子性的追加到文件（如，一个连续的字节序列）里GFS选定的一个偏移位置，并将这个偏移位置返回给客户端。这与在没有竞争的情况下，Uinx下多个并发写操作向一个使用 <strong>O_APPEND</strong> 选项打开的文件中写数据相似。</p><p>记录追加操作在我们的分布式应用中使用频繁，许多运行在不同机器上的客户端并行的向同一文件上追加数据。如果使用传统的写操作进行并发写，客户端将需要额外复杂的、昂贵的同步机制，比如，通一个分布式锁的管理器。在我们的工作中，这样的文件通常用于多个生产者&#x2F;一个消费者队列，或者合并来自许多不同客户端的数据结果。</p><p>记录追加操作是修改操作中的一种，遵循3.1中介绍的控制流程，只在primary上有一些额外的逻辑。客户端把数据推送到文件最后一个块的所有的副本上，然后将向primary发送它的请求。primary会检查这次追加操作是否使块的大小超过了最大尺寸（64MB）。如果超过，它将把这个块填充满，通知所有的secondary副本进行相同的操作，并回复客户端表明这个操作将在下一个块上重新执行。（记录追加操作的数据大小严格控制在最大尺寸的1&#x2F;4以内，以确保最坏情况下碎片的数量在一个可接受范围。）通常情况下，如果记录不超过最大尺寸，primary将数据追加到它的副本上，然后通知secondary把数据写到与primary相同的位置上，最后回复客户端操作成功。</p><p>如果在任意一个副本上的记录追加失败，客户端将重试这个操作。因此，在同一个块的副本上可能包含不同的数据，包括同一个记录的全部或部分的重复数据。GFS不保证写入的数据在字节上完全相同，它只保证作为一个原子单元至少被写入一次。这个特性能够通过简单的观察得到：如果操作执行成功，数据肯定被写入到了某些块副本的相同位置。此外，在这之后，所有副本至少都达到了记录尾部的长度，因此，即使一个不同的副本成为了primary，以后的任何记录也都将被放置在更大的偏移位置或者是一个不同的块上。在我们的一致性保障方面，记录追加操作成功的写入数据的区域是被定义的（因此是一致的），反之，介于中间状态的区域是不一致的（因此是未定义的）。我们的应用使用在2.7.2讨论的方法处理这种不一致的区域。</p><h3 id="3-4-Snapshot"><a href="#3-4-Snapshot" class="headerlink" title="3.4 Snapshot"></a>3.4 Snapshot</h3><p>快照操作几乎瞬间的为一个文件或一个目录树（源）创建一个拷贝，并且不会对正在进行的其它操作造成任何影响。我们的用户使用它为一个巨大的数据集创建一个拷贝分支（而且经常递归的对拷贝进行拷贝），或者是在尝试变化之前对当前的状态创建检查点，之后可以轻松的进行提交或回滚。</p><p>像AFS一样，我们使用标准的写时拷贝（Copy-On-Write）技术来实现快照。当Master接收到一个快照请求时，它先取消快照相关的文件块的所有租约。这确保了任何后面对这些块的写操作将需要与Master进行交互，以获取租约的持有者，这将为Master提供一个为块创建一个新拷贝的机会。</p><p>在租约被取消或者过期后，Master将这些操作记录到磁盘，然后通过复制源文件或目录树的元数据在它内存中的状态上执行这些日志记录。新创建的快照文件与源文件指向相同的块。</p><p>在快照操作后，客户端第一次想要向块C中写入数据前，它将向Master发送一个请求来查找当前的租约持有者。Master注意到块C的引用计数大于1，它将推迟回复客户端的请求，并选择一个新的块句柄C’，然后通知每个拥有块C副本的块服务器，创建一个新的块C’。通过在同一个块服务器上创建一个新的块，我们能确保这个拷贝是本地的，不需要通过网络进行的（我们的磁盘速度是100MB以太网链路的3倍）。从这点上看，请求的处理不会与其它的块处理有差别：主节点将新块C’的租约授予其中一个副本，并回复客户端，客户端能够进行一般的写操作，并不知道这个块是从一个已存在的块上创建出来的。</p><h2 id="4-MASTER-OPERATION"><a href="#4-MASTER-OPERATION" class="headerlink" title="4. MASTER OPERATION"></a>4. MASTER OPERATION</h2><p>Master执行所有的命名空间操作，此外，它管理整个系统内的所有块的副本：它决定块的存储位置，以及协调系统范围内的各种行为以保障块能够有足够的副本，均衡所有块服务器的负载，以及回收不再使用的存储空间。我们现在讨论这里提到的每一个话题。</p><h3 id="4-1-Namespace-Management-and-Locking"><a href="#4-1-Namespace-Management-and-Locking" class="headerlink" title="4.1 Namespace Management and Locking"></a>4.1 Namespace Management and Locking</h3><p>许多Master操作会占用较长时间：例如，一个快照操作必须撤销所有进行快照的块所在块服务器的租约，我们不想推迟正在进行的其它Master操作，因此，我们允许多个操作同时进行，并使用<strong>命名空间区域的锁来确保这些操作按适当的顺序执行</strong>。</p><p>不像许多传统的文件系统那样，GFS没有一个目录数据结构，它列出了这个目录下的所有文件，也不支持对文件和目录的别名操作（如，Unix术语中的硬链接或符号链接）。GFS的命名空间逻辑上表现为一个将全路径名映射为元数据的查询表。利用前缀压缩，这个表能够高效的存储在内存中。每个命名空间树中的节点（无论是一个绝对文件名还是一个绝对目录名）都有一个与之关联的读写锁。</p><p>每个主节点操作在执行前都先获得一系列的锁，通常，如果它涉及到&#x2F;d1&#x2F;d2&#x2F;…&#x2F;dn&#x2F;leaf，它将获得目录名的读锁&#x2F;d1，&#x2F;d1&#x2F;d2，…，&#x2F;d1&#x2F;d2&#x2F;…&#x2F;dn，然后获取完全文件名&#x2F;d1&#x2F;d2&#x2F;…&#x2F;dn&#x2F;leaf的一个读锁或写锁。注意，这里的leaf根据其操作，可能是一个文件，也可能是一个目录。</p><p>我们现在能阐明在&#x2F;home&#x2F;user快照成&#x2F;save&#x2F;user时，这个锁机制如何防止创建一个文件&#x2F;home&#x2F;user&#x2F;foo。快照操作获得了&#x2F;home和&#x2F;save上的读锁，以及&#x2F;home&#x2F;user和&#x2F;save&#x2F;user上的写锁，而文件创建操作则获得了&#x2F;home和&#x2F;home&#x2F;user上的读锁，以及&#x2F;home&#x2F;user&#x2F;foo上的写锁。因为它们都试图获得&#x2F;home&#x2F;user上的锁而造成冲突，所以这两个操作将适当的进行排序。文件创建不需要获取它的父目录的写锁，因为这里没有“目录”或类似inode等用来防止被修改的数据结构。文件名上的读锁足以防止父目录被删除。</p><p>这种锁机制的一个很好的性质是它允许对同一个目录下的并发操作。比如，在一个相同目录下，多个文件创建操作可以同时进行：每个操作获取目录上的读锁，以及其文件名上的写锁。目录名上的读锁足以防止目录被删除、重命名或进行快照。文件名上的写锁可以使使用同一名字创建文件的两次操作顺序执行。</p><p>因为命名空间可能包含很多节点，所以读写锁对象采用惰性分配策略，一旦不再使用则被删除。同样，锁需要按一个相同的顺序被获取来防止死锁：他们先对命名空间进行排序，并在同一级别按字典序排序。</p><h3 id="4-2-Replica-Placement"><a href="#4-2-Replica-Placement" class="headerlink" title="4.2 Replica Placement"></a>4.2 Replica Placement</h3><p>一个GFS集群采用高度分布的多层结构，它通常有几百个块服务器分布在许多机架上。这些块服务器被来自相同或不同机架上的数百个客户端轮流访问。不同机架上的两台机器间的通信可能要经过一个或多个网络交换，此外，机架的入口或出口带宽可能比机架上所有机器的带宽总和要小。多层的分布式对数据的灵活性、可靠性和可用性提出了挑战。</p><p>块副本布局策略有两大目标：最大化数据的可靠性和可用性，最大化带宽利用率。为了这两个目标，将副本分布在不同的机器是不够的，它只防止了磁盘或机器的失效，以及最大化了机器的带宽利用率。我们也必须将副本分布到不同的机架上，这样可以确保在整个机架损坏或掉线（例如，由于网络交换或电源线路的问题造成的资源共享失效）的情况下，一个块的一些副本能够保存下来并能正常使用。这意味着在网络流量上，特别是在读取一个块时，可以利用多个机架的整合带宽。另一方面，写操作必须将数据导向多个机架，这个代价是我们愿意付出的。</p><h3 id="4-3-Creation-Re-replication-Rebalancing"><a href="#4-3-Creation-Re-replication-Rebalancing" class="headerlink" title="4.3 Creation, Re-replication, Rebalancing"></a>4.3 Creation, Re-replication, Rebalancing</h3><p>三个原因造成了块的复制：<strong>块创建、重新复制和重新负载均衡。</strong></p><p>当主节点创建一个块时，它会选择在哪初始化一个空的副本。主节点会考虑几个因素：（1）我们想要在一个空间使用率低于平均值的块服务器上放置新的副本。经过一段时间，这将会使块服务器间的磁盘利用率基本相等。（2）我们想要限制每台块服务器上“最近”创建块的数量。尽管创建本身是廉价的，但是它也预示着马上就会有大量的数据写入，因为只有在需要进行写数据时，块才会被创建，在我们“一次写多次读”的工作中，他们通常一旦写完数据就变为只读的了。（3）如上面讨论的那样，我们想要将一个块的副本分布到不同的机架上。</p><p>当副本的可用数量低于用户指定的值时，Master会尽快进行块的重新复制。以下原因可能引起这个操作：一个块服务器不可用，它会报告存储的副本可能被损坏，其中的一个磁盘由于错误不可用，或者副本的目标数变大了。每个需要进行重新复制的块基于几个因素优先进行：一个是块现有的副本数量与目标数差多少。比如，一个丢失两个副本的块比丢失一个副本的优先级高；此外，相对于最近被删除的文件的块来说，我们优先对活跃的文件的块进行重新复制（4.4）；最后，为了最小化故障对正在运行的应用的影响，我们会提高阻塞客户进程的块的优先级。</p><p>Master选取优先级最高的块，通过通知一些块服务器从一个存在的可用副本上拷贝块数据来“克隆”它。选择副本位置的方法与创建时类似：平均磁盘空间是使用率，限制单一块服务器上运行的克隆操作，以及跨机架分布。为了防止克隆操作的流量影响到客户端的流量，Master限制了集群和每个块服务器上正在运行的克隆操作数量。此外，每个块服务器通过减少发往源块服务器的读请求，限制了每个克隆操作所占用的带宽。</p><p>最后，Master周期性的重新均衡副本的负载：它检查当前的副本分布情况，并将副本移动到更好的磁盘空间上，达到负载均衡。通过这个过程，Master逐步的填充新的块服务器，而不是马上使用新的块和大量的写入流量填充它。这个新副本的分布标准与上面提到的类似。此外，Master必须选择移动哪个已存在的副本，通常情况下，它更倾向于从剩余空间小于平均值的那个块服务器上移动副本，以使磁盘使用率相等。</p><h3 id="4-4-Garbage-Collection"><a href="#4-4-Garbage-Collection" class="headerlink" title="4.4 Garbage Collection"></a>4.4 Garbage Collection</h3><p>在一个文件被删除后，GFS不会立即回收可用的物理存储空间。它只有在文件和块级别上定期的垃圾回收时才会进行。我们发现，这个方法使系统更加简单，更加可靠。</p><h4 id="4-4-1-Mechanism-机制"><a href="#4-4-1-Mechanism-机制" class="headerlink" title="4.4.1 Mechanism 机制"></a>4.4.1 Mechanism 机制</h4><p>当一个文件被应用删除时，Master会像其他操作一样立即记录下这个删除操作。然而，文件仅仅会被重命名为一个包含删除时间戳的、隐藏的名字，而不是立即回收资源。在Master定期的扫描文件系统的命名空间期间，它将真正删除已经被隐藏超过三天的文件（这个间隔可以配置），在此之前，文件仍然可以通过新的特殊的名字进行读取，也可以通过重命名为普通的文件名而撤销删除操作。当隐藏文件从命名空间中真正被删除时，内存中对应的元数据也会被清除，这样能有效的切断文件和它的所有块的连接。</p><p>在对块的命名空间做类似的扫描时，Master标识出孤儿块（任何文件都无法访问到的块），并将那些块的元数据清除。在与Master进行定期的心跳信息交换时，每个块服务器报告其所含有块的集合，Master回复块服务器哪些块没有出现在Master的元数据中，块服务器将释放并删除这些块的副本。</p><h4 id="4-4-2-Discussion"><a href="#4-4-2-Discussion" class="headerlink" title="4.4.2 Discussion"></a>4.4.2 Discussion</h4><p>虽然分布式回收机制在编程语言领域是一个需要复杂解决方案的难题，但在我们的系统中十分简单。我们能简单的确定一个块的所有引用：它们唯一的保存在Master的文件-块映射中。我们也能轻松的确定一个块的所有副本：它们都以Linux文件的形式存储在每台块服务器的指定目录下。任何Master不认识的副本都是“垃圾”</p><p>用于存储回收的垃圾回收方法通过惰性删除拥有几个优势。首先，对于组件失效是常态的大规模分布式系统来说，这种方式简单可靠。块创建操作可能在一些块服务器上执行成功，但在另一些服务器上执行失败，残余的副本在主节点上无法识别。副本删除消息可能丢失，Master必须重新发送执行失败的消息，包括自身的和块服务器的。垃圾回收机制提供了一个一致的、可靠的方法来清除没用的副本。其次，它将存储回收操作合并到了Master定期的后台操作中，比如，定期的浏览命名空间和与块服务器握手。因此，它被批处理完成，开销被分摊了。此外，只有在Master相对空闲时才会完成垃圾回收，Master对客户端需要及时回复的请求有更高的优先级进行响应。第三，延迟回收存储空间可以为防止意外的、不可撤销的删除操作提供一个安全保障。</p><p>在我们的经验中，主要的缺点是，当存储空间紧张时，会阻碍用户在使用时的调优工作。频繁创建和删除临时文件的应用不能马上重用删除数据后的可用空间。我们通过在已被删除的文件上显式的再次进行删除来解决垃圾回收的这些问题。我们也可以允许用户对命名空间的不同部分应用不同的复制和回收策略。比如，用户可以指定一些目录树下的所有文件进行无副本存储，任何被删除的文件会从系统上迅速的、不可恢复的删除。</p><h3 id="4-5-Stale-过期-Replica-Detection"><a href="#4-5-Stale-过期-Replica-Detection" class="headerlink" title="4.5 Stale 过期 Replica Detection"></a>4.5 Stale 过期 Replica Detection</h3><p>如果一个块服务器失效并在宕机期间丢失了块的修改操作，块副本可能会过期。对于每个块，Master维护一个块版本号来区分最新的副本和过期的副本。</p><p>每当Master授予某个块一个新租约，它都会增加块的版本号，并通知最新的副本。Master和其它副本都在它们的持久状态中记录了新的版本号，这会在任何客户端接收到通知并开始进行写操作之前进行。如果其它副本当前不可用，它的块版本号将不会被更新。当块服务器重启并报告它所有的块集合和它们相应的版本号时，Master还会探测到这个块服务器有过期的副本。如果Master发现有一个版本号高于自己的记录，Master会假设在它授予租约时失败，因此会选择更高的版本号作为最新的版本号。</p><p>Master在定期的垃圾回收操作中清除过期的副本。在这之前，当它回复客户端的块信息请求时，它将认为一个过期的副本实际上根本并不存在。作为另一个安全措施，当Master通知客户端哪个块服务器持有这个块的租约时，或者在进行克隆操作期间它通知一个块服务器从另一个块服务器上读取数据时，包含块版本号。客户端或块服务器在执行操作时会验证这个版本号，以保证总是可访问的最新的数据。</p><h2 id="5-FAULT-TOLERANCE-AND-DIAGNOSIS-诊断"><a href="#5-FAULT-TOLERANCE-AND-DIAGNOSIS-诊断" class="headerlink" title="5. FAULT TOLERANCE AND DIAGNOSIS 诊断"></a>5. FAULT TOLERANCE AND DIAGNOSIS 诊断</h2><p>在设计系统时，最大的挑战之一就是如何处理频繁的组件故障。组件的数量和质量让这些问题变得更为普通，而不是作为异常情况：我们不能完全的信任机器，也不能完全的信任磁盘。组件故障可能会造成系统不可用，我们讨论了我们如何应对这些挑战，以及我们在系统中内置的工具，用于在不可避免地发生问题时诊断问题。</p><h3 id="5-1-High-Availability"><a href="#5-1-High-Availability" class="headerlink" title="5.1 High Availability"></a>5.1 High Availability</h3><p>在GFS集群的数百台服务器中，必定有一些机器在给定的一段时间内是不可用的。我们通过两个简单但有效的策略来保证整个系统的高可用性：<strong>快速恢复</strong>和<strong>复制</strong>。</p><h4 id="5-1-1-Fast-Recovery"><a href="#5-1-1-Fast-Recovery" class="headerlink" title="5.1.1 Fast Recovery"></a>5.1.1 Fast Recovery</h4><p>Master和块服务器都被设计为无论它们如何终止都能够在几秒内恢复自己的状态并重新启动。实际上，我们并不区分正常的和不正常的终止；可以通过kill掉进程来关闭服务。由于它们的请求超时而没有完成，客户端或其他服务器可能经历小的颠簸，它们会重新连接服务器并重试。6.2.2节报告了经过观察的启动时间。</p><h4 id="5-1-2-Chunk-Replication"><a href="#5-1-2-Chunk-Replication" class="headerlink" title="5.1.2 Chunk Replication"></a>5.1.2 Chunk Replication</h4><p>如之前讨论过的，每个块被复制到不同机架上的多个块服务器上。用户能够为文件命名空间的不同部分指定不同的复制级别，默认为三个。当有块服务器掉线或通过校验和（5.2节）检测出损坏的副本时，Master克隆已存在的副本来保证每个块有足够的副本。尽管复制策略非常有效，但我们也在探索其他的跨服务器的冗余解决方案，如奇偶校验，或者纠删码（erasure code），来应对我们日益增长的只读存储需求。我们希望在我们的高度松耦合的系统中，这些复杂的冗余方案是具有挑战的，但并不是不可实现的，因为我们的操作主要是追加和读取，而不是小规模的随机写。</p><h4 id="5-1-3-Master-Replication"><a href="#5-1-3-Master-Replication" class="headerlink" title="5.1.3 Master Replication"></a>5.1.3 Master Replication</h4><p>为了可靠性，Master的状态也被复制。它的操作日志和检查点被复制到多个机器上。一个修改操作只有在它的日志被刷新到本地磁盘和所有的Master副本后才认为被提交完成。简单的说，一个Master负责所有的操作，包括后台的行为，如垃圾回收等改变系统内部状态的行为。当它失效时，能够瞬间重启。如果它的机器或磁盘发送故障，GFS的外部监控会让其它有副本操作日志的机器上启动一个新的Master。客户端只使用主节点的名字（如，gfs-test），它是一个DNS的别名，可以更改这个名字来访问被重新放置到其它机器上的Master。</p><p>此外，当primary Master宕机时，“影子”Master可以为文件系统提供一个只读的访问接口。它们是影子，而不是镜像，它们内部的数据会稍微的落后于primary Master，通常不到1秒。因此，它们对于那些不经常修改的文件的读取，或是不太在意得到的是稍微过期的数据的应用来说是有效的。实际中，因为文件内容是从块服务器读取的，所以应用察觉不到过期的文件内容。在短暂的时间窗口内，过期的可能是文件的元数据，如目录内容，或访问控制信息。</p><p>为了保持最新的状态，影子Master读取一个正在增长的操作日志副本，并执行与primary Master相同的操作序列来改变自己的数据结构。像primary那样，它在启动后轮询块服务器（之后也经常）来定位块副本，通过频繁的交换握手信息来监控它们的状态。当primary Master决定创建或删除副本造成位置信息更新时，影子Master才会通过primary Master更新状态。</p><h3 id="5-2-Data-Integrity-完整性"><a href="#5-2-Data-Integrity-完整性" class="headerlink" title="5.2 Data Integrity 完整性"></a>5.2 Data Integrity 完整性</h3><p>每个块服务器使用校验和来探测存储的数据是否被损坏。考虑到一个GFS集群经常由数百个机器上的数千块磁盘组成，由于磁盘的损坏而造成的读和写路径上的数据损坏或丢失是很常见的。（其中的一个原因见7.1节。）我们能够使用块的其它副本来进行恢复，但是通过不同块服务器上的副本的比较无法探测出数据块是否损坏。此外，不同的副本可能是合理的：GFS修改操作的语法，特别是之前讨论过的原子追加操作，不能保证所有副本都相同。因此，每个块服务器必须独立的通过校验和来验证它所拥有的拷贝是否合法。</p><p>一个块被分割成64KB大小的block，每个block都有一个对应的32bit校验和。像其它元数据一样，校验和保存在内存中，并通过日志永久存储，与用户数据分开。</p><p>对于读操作，在把数据返回给请求者之前，块服务器要验证读范围内所有数据block的校验和，因此，块服务器不会将损坏的数据传播到其它机器上。如果一个block与记录的校验和不匹配，块服务器会返回给请求者一个错误，并向Master报告这个错误。在响应中，请求者将从其它的副本读取数据，同时，Master将从其它副本上克隆这个块。在一个新的可用的副本复制完毕后，Master会通知报告错误的块服务器删除出错的副本。</p><p>校验和对读操作几乎没有影响，原因有几个。因为大多数的读操作至少需要读取几个块，我们只需要读取一小部分额外的数据用于验证校验和。GFS客户端代码通过试图将读操作对齐到校验和的block边界上，大大减小了验证的开销。此外，块服务器上校验和的查询和对比不需要任何I&#x2F;O就能完成，校验和的计算可以和I&#x2F;O操作同时进行。</p><p>校验和计算针对在块尾部进行追加写操作做了很大的优化（相对于覆盖已有数据的写操作），因为写操作在我们的工作中是占主导的。我们仅增量更新最后一个不完整的块的校验和，并用追加的新的校验和来计算block的新校验和。即使最后一个不完整的校验和已经被损坏，并且我们现在没有探测出来，新的校验和将不匹配存储的数据，当这个块下一次被读取时，就是检测出数据已经损坏。</p><p>相反的，如果写操作覆盖块中已经存在的一个范围内，我们必须读取并验证要被覆盖的这个范围内的第一个和最后一个block，然后执行写操作，最后计算并记录新的校验和。如果我们在覆盖它们之前不进行对第一个和最后一个block的验证，新的校验和可能会隐藏没有被覆盖区域的错误。</p><p>在空闲的时候，块服务器能浏览和验证不活跃的块的内容，这允许我们探测很少被读取的块的数据损坏。一旦损坏被探测到，Master就能创建一个新的没有损坏的副本，并删除已损坏的副本。这能够防止不活跃的、已损坏的块欺骗Master，使Master认为它是块的一个可用的副本。</p><h3 id="5-3-Diagnostic-Tools"><a href="#5-3-Diagnostic-Tools" class="headerlink" title="5.3 Diagnostic Tools"></a>5.3 Diagnostic Tools</h3><p>在问题隔离、调试和性能分析方面，详尽的、细节的诊断日志给我们很大的帮助。如果没有日志，我们很难理解短暂的、不重复的机器间的消息交互。GFS服务器生成诊断日志用于记录许多关键的事件（如块服务器启动和关闭），以及所有的远程调用（RPC）的请求和响应。这些诊断日志能够被自由的删除，不会给系统带来任何影响。然而，在空间允许的情况下，我们会尽量保存这些日志。</p><p>远程调用（RPC）日志包括网络上所有的请求和响应，除了文件数据被读取或写入。通过匹配请求和响应，以及核对其它机器上的RPC记录，我们能重建这个交互历史用于诊断错误。这些日志也能用于跟踪负载测试和性能分析。</p><p>记录日志所造成的性能影响很小（远小于它带来的好处），因为这些日志异步的、顺序的被写入。最近的事件也会保存在内存中，可用于持续的在线监控。</p><h2 id="6-MEASUREMENTS-度量"><a href="#6-MEASUREMENTS-度量" class="headerlink" title="6. MEASUREMENTS 度量"></a>6. MEASUREMENTS 度量</h2><p>在这章中，我们介绍几个微基准测试来描述GFS架构和实现中固有的瓶颈，还有一些来自于Google正在使用的集群中。</p><h3 id="6-1-Micro-benchmarks"><a href="#6-1-Micro-benchmarks" class="headerlink" title="6.1 Micro-benchmarks"></a>6.1 Micro-benchmarks</h3><p>我们在一个由1个主节点，2个主节点副本，16个块服务器和16个客户端组成的GFS系统上进行性能测试。注意，这个配置是为了方便测试，一般的集群包含数百个块服务器和数百个客户端。</p><p>所有的机器都配置为两个1.4GHz的PIII处理器，2GB的内存，两个5400rpm的80GB的磁盘，以及一个100Mpbs全双工以太网连接到一个HP2524的交换机上。两个交换机之间只用1Gpbs的链路连接。</p><h4 id="6-1-1-Reads"><a href="#6-1-1-Reads" class="headerlink" title="6.1.1 Reads"></a>6.1.1 Reads</h4><p>N个客户端同时从文件系统读取数据。每个客户端从320GB的数据中，随机的选取4MB区间进行读取。这个读操作会重复256次，使客户端最终读取到1GB的数据。块服务器总共只有32GB的内存，，所以我们期望最多有10%的缓存命中率。我们的结果应该与没有缓存的情况下相近。</p><p><img src="/image/GFS/image-20220330154901599.png" alt="image-20220330154901599"></p><p>图3：总吞吐量。顶上的曲线显示了理论情况下的由我们的网络拓扑引入的限制。下面的曲线显示了测试的吞吐量。它们显示了置信区间为95%的误差，在一些情况下，由于测量的方差小而不太明显。</p><p>图3（a）中显示了N个客户端的总读取速率和它的理论极限。当两个交换机之间的1Gpbs链路饱和时，理论极限为125MB&#x2F;s，或者当客户端的网络接口达到饱和时，每个客户端的理论极限为12.5MB&#x2F;s，无论哪个都适用。当只有一个客户端进行读取时，观测到的读取速率为10MB&#x2F;s，或者是每个客户端极限的80%。对于16个读操作，总速率可以达到94MB&#x2F;s，大约是125MB&#x2F;s网络极限的75%，或者是每个客户端到达6MB&#x2F;s的速率。效率从80%下降到75%的原因是，当读取操作的数量增加时，多个读操可能同时的从同一个块服务器上读取数据。</p><h4 id="6-1-2-Writes"><a href="#6-1-2-Writes" class="headerlink" title="6.1.2 Writes"></a>6.1.2 Writes</h4><p>N个客户端同时往N个不同文件进行写操作。每个客户端以每次1MB的速率向一个新文件写入1GB的数据。总的写入速率和理论极限显示在图3（b）中。理论极限是67MB&#x2F;s，因为我们需要把每个字节都写入到16个块服务器中的3个，而每个块服务器的输入连接极限为12.5MB&#x2F;s。</p><p>每个客户端的写入速率为6.3MB&#x2F;s，大约是极限的一半，主要的原因是我们的网络协议栈，它与我们用于推送块副本的管道（pipelining）方式不太适应。从一个副本到另一个副本传播数据的延迟降低了整个系统的写入速率。</p><p>16个客户端的总写入速率达到35MB&#x2F;s（每个客户端的速率大概是2.2MB&#x2F;s），大约是理论极限的一半。与多个客户端进行读操作的情况类似，由于进行写操作的客户端数量的增加，客户端同时向同一个块服务器写入的几率也会增加。此外，写操作冲突的几率比读操作的要更大，因为每次写操作需要涉及三个不同的副本。</p><p>写操作比我们想要的要慢，在实际中，这不会成为一个主要的问题，因为即使对于单个客户端它也增加了时延，但是对于含有大量客户端的系统来说，它不会对系统的写入带宽有太大影响。</p><h4 id="6-1-3-Record-Appends"><a href="#6-1-3-Record-Appends" class="headerlink" title="6.1.3 Record Appends"></a>6.1.3 Record Appends</h4><p>图3（c）显示了记录追加的性能，N个客户端同时向一个单独的文件追加数据。性能受存储文件最后一个块的块服务器的网络带宽的限制，而不是客户端的数量。它的速率由一个客户端的6MB&#x2F;s下降到16个客户端的4.8MB&#x2F;s，主要是由冲突和不同客户端的网络传输速率不同造成的。</p><p>我们的应用倾向于同时处理多个这样的文件。换句话说，N个客户端同时向M个共享文件追加数据，N和M在0到几百之间。因此，在我们的经验中，块服务器网络冲突在实际中不是一个严重的问题，因为当块服务器正在忙于处理一个文件时，客户端可以进行另一个文件的写入操作。</p><h3 id="6-2-Real-World-Clusters"><a href="#6-2-Real-World-Clusters" class="headerlink" title="6.2 Real World Clusters"></a>6.2 Real World Clusters</h3><p>我们现在测试了两个Google正在使用的集群，它们有一定的代表性。集群A通常用于上百个工程师进行研究和开发。一个普通的任务被人为初始化，并运行几个小时，它读取几MB到几TB的数据，进行转换或分析数据，并将结果写回到集群中。集群B主要用于生产数据的处理。在很少人为干预下，这些任务运行更长的时间，持续的产生和处理几TB的数据集。在这两个实例中，一个单独的任务由运行在很多机器上的很多进程同时读和写很多文件组成。</p><p><img src="/image/GFS/image-20220330154835412.png" alt="Table 2: Characteristics of two GFS clusters"></p><h4 id="6-2-1-Storage"><a href="#6-2-1-Storage" class="headerlink" title="6.2.1 Storage"></a>6.2.1 Storage</h4><p>如表2的前五个条目所示，两个集群都有上百个块服务器，支持数TB的磁盘空间，存储了大小合适的数据，但没有占满。“已使用空间”包括所有的块副本。实际上，所有的文件都有三个副本，因此，集群实际上存储了18TB和52TB的文件数据。</p><p>两个集群的文件数量相近，不过B含有更大比例的死文件，死文件是指被删除或者被新版本替换的文件，但它们的存储空间还没有被回收。它也存储了更多的块，因为它的文件较大。</p><h4 id="6-2-2-Metadata"><a href="#6-2-2-Metadata" class="headerlink" title="6.2.2 Metadata"></a>6.2.2 Metadata</h4><p>块服务器总共存储了数10GB的元数据，大多数是用户数据64KB的block的校验和。块服务器上其它的元数据则是4.5节讨论的块版本号。</p><p>Master上的元数据要小很多，只有几十MB，或者说，每个文件平均有100字节的元数据。这符合我们对Master内存在实际中不会限制系统能力的设想。大多数的文件元数据是以前缀压缩方式存放的文件名，其它的元数据包括文件的所有者和权限，文件到块的映射表，以及每个块的当前版本号。此外，还为每个块存储了当前副本的位置信息和引用计数用来实现写时拷贝（COW）。</p><p>每个单独的服务器，不论是块服务器还是Master，只有50-100MB的元数据。因此恢复速度很快：在服务器能够应答请求之前，它会只花费几秒时间先从磁盘中读取元数据。然而，主节点会持续颠簸一段时间，通常是30秒-60秒，直到它从所有的块服务器上获取到块位置信息。</p><h4 id="6-2-3-Read-and-Write-Rates"><a href="#6-2-3-Read-and-Write-Rates" class="headerlink" title="6.2.3 Read and Write Rates"></a>6.2.3 Read and Write Rates</h4><p><img src="/image/GFS/image-20220330155632174.png" alt="Table 3: Performance Metrics for Two GFS Clusters"></p><p>表3中显示了持续时间不同的读写速率，两个集群在做这些测试前都已经运行了大概一个星期的时间。（这两个集群是因为GFS更新到新版本而进行重启。）</p><p>自从重启后，平均写速率一直小于30MB&#x2F;s。当我们做这些测试时，B正在进行速率为100MB&#x2F;s的大量写操作，因为写操作被传送到三个副本上，所以将产生300MB&#x2F;s的网络负载。</p><p>读速率要达到高于写速率。如我们设想的那样，整个工作由更多的读操作组成。两个集群都在进行繁重的读操作，特别是，集群A在前些周维持了580MB&#x2F;s的读速率。它的网络配置能够支持750MB&#x2F;s的速率，所以它有效的利用了它的资源。集群B支持的极限读速率为1300MB&#x2F;s，但是，它的应用只用到了380MB&#x2F;s。</p><h4 id="6-2-4-Master-Load"><a href="#6-2-4-Master-Load" class="headerlink" title="6.2.4 Master Load"></a>6.2.4 Master Load</h4><p>表3也显示了发往Master的操作速率，每秒有200-500个操作。Master可以轻松的应对这个速率，因此Master的处理性能不是瓶颈。</p><p>在早期的GFS版本中，Master有时会成为瓶颈。它花费大多数时间连续的浏览大的目录（可能含有几百几千个文件）来查找指定的文件。我们已经改变了Master的数据结构，使用二分查找在命名空间中进行查找，以此提高效率。它也能轻松的支持每秒数千次的文件访问。如果需要，我们能通过在命名空间数据结构之前放置名字查询缓存的方法来进一步提高速度。</p><h4 id="6-2-5-Recovery-Time"><a href="#6-2-5-Recovery-Time" class="headerlink" title="6.2.5 Recovery Time"></a>6.2.5 Recovery Time</h4><p>在一个块服务器发生故障后，一些块的副本数量会小于指定值，必须进行克隆操作使副本数恢复到指定值。恢复所有块所需的时间由资源的数量决定。在一个试验中，我们杀掉了B集群中的一个单独的块服务器，这个块服务器大概有15,000个块，包含了600GB的数据。为了减小对正在运行的应用的影响，以及为调度决策提供修正空间，我们的默认参数限制了集群的并发克隆数为91（块服务器数量的40%），在这里，每个克隆操作被允许最多使用6.2MB&#x2F;s的带宽。所有的块在23.2分钟后恢复，复制速率为440MB&#x2F;s。</p><p>在另一个试验中，我们杀掉了两个块服务器，每个包含了大约16000个块和660GB的数据。这个双故障造成了有266个块的成为单副本。这266个块作为更高的优先级被克隆，并在两分钟之内恢复到至少有两个副本的状态，这样可以让集群处于一个能够容忍另一个块服务器故障而不丢失数据的状态。</p><h3 id="6-3-Workload-Breakdown-工作负荷分析"><a href="#6-3-Workload-Breakdown-工作负荷分析" class="headerlink" title="6.3 Workload Breakdown 工作负荷分析"></a>6.3 Workload Breakdown 工作负荷分析</h3><p>在这章中，我们对两个GFS集群的工作进行详细的分解介绍，这两个集群与6.2节中的类似，但不完全相同。集群X用于研究和开发，而集群Y用于生产数据的处理。</p><h4 id="6-3-1-Methodology-方法论-and-Caveats-注意事项"><a href="#6-3-1-Methodology-方法论-and-Caveats-注意事项" class="headerlink" title="6.3.1 Methodology 方法论 and Caveats 注意事项"></a>6.3.1 Methodology 方法论 and Caveats 注意事项</h4><p>这些结果中包含了只有用户发起的请求，以至于它们能够反映出由应用文件系统整体产生的工作量。它们不包含用于执行客户端请求或者内部的后台行为的服务器间的请求，如正向写或重新负载均衡。</p><p>I&#x2F;O操作的统计是基于从GFS服务器的实际RPC请求日志上重新建立起来的信息的。例如，GFS客户端为了增加并行性，会将一个读操作分解成多个RPC，通过这些调用，我们可以推导出原始的读操作。因为我们的访问模式是高度模程式的，我们认为任何错误都属于误差。应用记录的详细日志能够提供更准确的数据，但是为了这个目的重新编译和重启上千个客户端在逻辑上是不可能的，而且从这么多机器上收集结果也是非常麻烦的。</p><p>应该注意不要对我们的工作量做过度的归纳，因为Google完全控制着GFS和其它自己的应用，应用针对于GFS做了优化，同样，GFS也是为了这些应用而设计的。这类的相互作用同样也存在于普通应用和文件系统之间，但是在我们的实例中，这种作用更加显著。</p><h4 id="6-3-2-Chunkserver-Workload"><a href="#6-3-2-Chunkserver-Workload" class="headerlink" title="6.3.2 Chunkserver Workload"></a>6.3.2 Chunkserver Workload</h4><p><img src="/image/GFS/image-20220330194111553.png" alt="Table 4: Operations Breakdown by Size (%)"></p><p>表4显示了操作数量的分布。读操作展现出一个双峰的分布，小规模读（64KB以内的）来自于查询为主的客户端，它从海量文件中查询小片的数据。大规模读取（大于512KB）来自于从头到尾读取整个文件的连续读操作。</p><p>在集群Y中有一些读操作没有返回任何数据。我们的应用，特别是哪些在生产系统中的，经常将文件用于生产者-消费者队列。生产者同时向一个文件追加数据，同时消费者从文件尾部读取数据。有时，当消费者超过生产者时，就没有数据返回了。集群X显示这种情况不常发生，因为它经常用于进行短暂的数据分析，而不是分布式应用的长久数据分析。</p><p>写操作也展现出一个双峰的分布。大规模写操作（超过256KB）通常是由于Writer使用了缓存机制造成的；缓存了较少的数据，频繁的进行检查点操作或同步操作，或者仅仅生成了少量数据的Writer解释了为什么存在小规模的写操作（小于64KB）。</p><p><img src="/image/GFS/image-20220330194303246.png" alt="Table 5: Bytes Transferred Breakdown by Opera-tion Size (%)"></p><p>表5：字节传输明细表（%）。对于读操作，这个大小是实际的读取和传输数据的总量，而不是请求的数据量。这两个可能的不同点在于如果试图读取超过文件结束的大小，这样的操作在我们的工作中并不常见。</p><p>对于记录追加操作，集群Y比集群X中有更高的大规模追加操作比例，这是因为我们的生产系统使用了集群Y，针对GFS做了更多的优化。</p><p>表5显示了按操作的数据大小得到的总的数据传输量。对于所有的操作，较大规模的操作（大于256KB）占据了主要的传输量；小规模的读操作（小于64KB）传输量较小，但是在读取的数据量中仍占有相当的比例，因为随机读操作需要进行查找工作。</p><h4 id="6-3-3-Appends-versus-对抗-Writes"><a href="#6-3-3-Appends-versus-对抗-Writes" class="headerlink" title="6.3.3 Appends versus 对抗 Writes"></a>6.3.3 Appends versus 对抗 Writes</h4><p>追加操作被频繁的使用，尤其是在我们的生产系统中。对于集群X，写操作与记录追加操作在字节传输量上的比例为108:1，在操作数量上的比例为8:1。对于集群Y，，这个比例为3.7:1和2.5:1。此外，这些比例说明了对于两个集群，记录追加操作所占的比例都比写操作的大。然而，对于集群X，在测试期间，使用的追加操作相当少，以至于结果几乎被一两个使用特定缓存大小的应用歪曲了。</p><p>不出所料的，记录追加操作占据了我们的数据修改的主要工作量，而不是覆盖写操作。我们测试了在primary副本上被覆盖的数据总量。这近似于一种情况，其中客户端故意的覆盖之前写入的数据，而不是追加新的数据。对于集群X，覆盖操作占字节修改的不到0.0001%，占操作数量的不到0.0003%。对于集群Y，这两个比例都为0.05%。尽管这是微小的，但是仍然比我们预期的要高。它证明了这些覆盖操作来自于客户端对于错误和超时的重试操作。它们不是工作量的一部分，而是重试机制的结果。</p><h4 id="6-3-4-Master-Workload"><a href="#6-3-4-Master-Workload" class="headerlink" title="6.3.4 Master Workload"></a>6.3.4 Master Workload</h4><p><img src="/image/GFS/image-20220330194852455.png" alt="Table 6: Master Requests Breakdown by Type (%)"></p><p>表6显示了根据发往Master的请求类型的明细。大多数请求都是读取操作查询块的位置信息（FindLocation）和数据修改操作的租约持有者的信息（FindLeaseHolder）。</p><p>集群X和Y在删除请求的数量上有显现的差别，因为集群Y存储生产数据集，这些数据集会定期的重新生成数据以及用新版本的数据替换旧的数据。其中的一些不同被隐藏在了Open请求中，因为旧版本的文件可能以写模式打开并从头开始的方式，被隐式的删除。</p><p>FindMatchingFiles是一个模式匹配请求，提供了“ls”和类似的文件操作。不像其他的Master操作，它可能处理一大部分命名空间，所以可能很昂贵。集群Y中看到了更多的这类请求，因为自动化的数据处理任务倾向检测部分文件系统，来获知整个应用的状态。相反的，集群X的应用更多的处于用户的显式控制之下，经常预先知道所有所需文件的名字。</p><h2 id="7-EXPERIENCES"><a href="#7-EXPERIENCES" class="headerlink" title="7. EXPERIENCES"></a>7. EXPERIENCES</h2><p>在建造和部署GFS的过程中，我们经历了各种问题，一些是操作上的，一些是技术上的。</p><p>起初，GFS被想象为是我们生产系统的一个后台的文件系统。随着时间的推移，GFS的使用逐渐包含了研究和开发的任务。它开始完全不支持类似权限和配额的功能，但是现在已经初步的包含了这些功能。虽然生产系统是被严格控制的，但是用户则不会总是这样。更多的基础构件被需要用来防止用户间的干扰。</p><p>一些最大的问题是磁盘和Linux相关的问题。我们的许多磁盘要求Linux驱动，它们支持一定范围的IDE协议版本，但在实际中，只对最新版本的响应可靠。因为协议版本非常相似，这些驱动多数可以工作，但是偶尔也会有错误，造成驱动和内核对驱动器状态的认识不一致。由于内核的问题，这会导致数据静默的被损坏。这个问题迫使我们使用校验和来检测数据是否损坏，同时我们修改内核来处理这些协议错误。</p><p>早期在使用Linux2.2内核时，由于fsync()效率问题，我们遇到了一些问题。它花费与文件大小成正比的时间，而不是修改部分的大小。对于我们的海量操作日志，特别是在检查点之前来说，确实是一个问题。我们在这个问题上花费了一些时间，通过同步写解决了这个问题，最后还是移植到了Linux2.4上。</p><p>另一个Linux的问题是一个单独的读写锁的问题，在这个地址空间内的任何线程都必须在将磁盘page in时（读锁）或在调用mmap()进行修改地址空间时持有这个锁。我们发现我们的系统在低负载时，也会短暂出现超时现象，我们艰难的寻找资源瓶颈，或不定时发生的硬件故障。最后，我们发现在磁盘线程正在page in之前的映射数据时，这个单独的锁阻塞了主网络线程向内存中映射新数据。因为我们主要受网络接口的限制，而不是内存拷贝的带宽，所以，我们用pread()来代替mmap()，使用一个额外的拷贝开销来解决了这个问题。</p><p>尽管偶尔会有问题，Linux代码常常帮助我们发现和理解系统行为。在适当的时候，我们会推进这个内核，并与开源社区共享我们的这些改动。 </p><h2 id="8-RELATED-WORK"><a href="#8-RELATED-WORK" class="headerlink" title="8. RELATED WORK"></a>8. RELATED WORK</h2><p>像其他的大型分布式文件系统一样，如AFS，GFS提供了一个与位置无关的命名空间，它能使数据为了负载均衡或容错透明的迁移。与AFS不同的是，GFS把文件数据分别到不同的存储服务器上，这种方式更像xFS和Swift，这是为了提高整体性能和增加容错能力。</p><p>由于磁盘相对便宜，并且复制要比RAID的方法简单许多，GFS当前只使用了复制来提供冗余，所以比xFS和Swift存储了更多的原始数据。</p><p>与AFS、xFS、Frangipani以及Intermezzo等文件系统不同，GFS并没有在文件系统接口下提供任何缓存机制。我们的目标工作是一个运行的应用很少会读取重复的数据，因为他们要么是从一个大的数据集中流式的读取数据，要么是随机的进行读取。</p><p>一些分布式文件系统，如Frangipani、xFs、Minnesota’s GFS和GPFS，去掉了中间的服务器，依靠分布式算法来保证一致性和进行管理。为了简单的设计、增加它的可靠性和获得弹性，我们选择了中心化的方法。特别的是，因为Master已经保存有大多数有关的信息，并可以控制它们的改变，因此，它极大地简化了原本非常复杂的块分配和复制策略的方法。我们通过保持较小的Master状态信息，以及在其它机器上做完整的备份来提高系统容错性。弹性和高可用性（对于读操作）通过影子Master机制来提供的。更新Master状态是通过追加预写日志来实现持久化的。因此，我们可以调整为使用类似Harp的主拷贝方式来提供高可用性的，它比我们目前的方式有更高的一致性保证。</p><p>我们解决了一个类似Lustre在有大量客户端时总的传输性能的问题。然而，我们通过只关注我们自己的应用，而不是创建一个适用于POSIX的文件系统来简化这个问题。此外，GFS采取大量的不可靠组件，所以容错将是我们设计的中心问题。</p><p>GFS十分接近NASD架构，NASD架构是基于网络磁盘的，GFS使用了一般的机器作为块服务器，与NASD协议类型相同。但是与NASD不同的是，我们的块服务器使用了惰性分配固定大小块的方式，而不是可变大小的块。此外，GFS实现了在生产环境中所需的一些功能，如重新负载均衡、复制和恢复等。</p><p>不像Minnesota’s GFS和NASD，我们不会去追求改变存储设备的模式。我们只关注由一般组件组成的复杂分布式系统所需要的日常数据的处理。</p><p>通过原子记录追加操作实现的生产者-消费者队列解决了一个与River中的分布式队列类似的简单问题。River使用了基于内存的分布式队列，必须小心的控制数据流，GFS则能够使用被很多生产者同时追加持久化的文件。River模型支持m-n的分布式队列，但是缺少由持久化存储提供的容错功能，而GFS只能够有效的支持m-1的队列。多个消费者能够读取同一文件，但他们必须协调分区输入的负载。</p><h2 id="9-CONCLUSIONS"><a href="#9-CONCLUSIONS" class="headerlink" title="9. CONCLUSIONS"></a>9. CONCLUSIONS</h2><p>GFS展示了一个在一般硬件上支持大规模数据处理工作的核心特性。一些设计决定都是根据我们的特殊环境定制的，但许多还是能够用于类似规模和成本的数据处理任务。</p><p>首先，根据我们当前的和预期的应用工作量和技术环境来重新考察传统的文件系统。观察结果引导出一个完全不同的设计思路。我们将组件失败看成是普通现象而非异常情况，对于向大文件进行追加（可能是并行的）和读操作（通常是序列化的）来进行优化，以及通过扩展接口和放松限制来改进整个系统。</p><p>我们的系统通过持续健康、复制关键数据以及快速自动的恢复来提供容错。块复制允许我们容忍块服务器的错误。这些错误的频率促进了一个新奇的在线修复机制，它定期的、透明的修复损坏的数据，并尽快对丢失的副本进行补偿。此外，在磁盘或IDE子系统层上，我们使用了校验和来探测数据是否损坏，在这种规模的磁盘数量上，这种问题十分普遍。</p><p>对于进行许多并行读写操作的各种任务，我们的设计提供了很高的总吞吐量。我们通过将控制流和数据流分开来实现这个目标，控制流直接经过Master，数据流通过块服务器和客户端之间传输。通过大的块大小和在数据修改操作中授予主拷贝一个块租约，能够最小化Master涉及的操作，这使简单的、中心的Master不会太可能成为瓶颈。我们相信我们的网络协议栈的改进可以提高从客户端看到的写入吞吐量的限制。</p><p>GFS很好的满足了我们的存储需求，并作为存储平台在Google中得到广泛使用，无论在研究和开发，还是生产数据处理上。它是我们持续创新和攻克整个web范围的难题的一个重要工具。</p><h2 id="PERSONAL-CONCLUSIONS"><a href="#PERSONAL-CONCLUSIONS" class="headerlink" title="PERSONAL CONCLUSIONS"></a>PERSONAL CONCLUSIONS</h2><h3 id="Architecture"><a href="#Architecture" class="headerlink" title="Architecture"></a>Architecture</h3><p><img src="/image/GFS/image-20220330201151094.png" alt="GFS Architecture Summary"></p><h3 id="Storage"><a href="#Storage" class="headerlink" title="Storage"></a>Storage</h3><p><img src="/image/GFS/image-20220330201313433.png" alt="GFS Storage Structure"></p><h3 id="Metadata"><a href="#Metadata" class="headerlink" title="Metadata"></a>Metadata</h3><p><img src="/image/GFS/image-20220330201411626.png" alt="GFS Metadata And File Location"></p>]]></content>
    
    
    <categories>
      
      <category>Paper</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>ETCD</title>
    <link href="/2022/03/28/Container/ETCD/"/>
    <url>/2022/03/28/Container/ETCD/</url>
    
    <content type="html"><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>etcd是CoreOS团队于2013年6月发起的开源项目，它的目标是构建一个高可用的分布式键值(key-value)数据库。etcd内部采用Raft协议作为一致性算法，etcd基于Go语言实现。</p><ul><li>简单：提供定义明确且面向用户的API</li><li>安全：支持SSL证书验证</li><li>性能：基准压测支持1w+&#x2F;sec写入</li><li>可靠：采用Raft协议保证分布式系统数据的可用性和一致性。</li></ul><h2 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h2><p>配置中心：etcd是一个分布式的键值存储系统，其优秀的读写性能、一致性和可用性的机制，非常适合用来做配置中心角色。</p><p><strong>分布式锁：</strong>etcd的强一致性保证，可以用来做分布式场景下的同步机制保证。</p><p>Leader选举：分布式场景下，常采用leader-follower模式来保证有状态服务的高可用（即使leader挂掉，其他follower立马补上），比如k8s和kafka partition高可用机制。可以很方便的借助etcd来实现leader选举机制。</p><p>服务注册发现：为了解决微服务场景下，服务地址的注册和发现问题。和配置中心功能类似，不同之处在于服务注册和服务发现，还伴随着状态检测。</p><p>消息订阅和发布：etcd内置watch机制，完全可以实现一个小型的消息订阅和发布组件。</p><h2 id="产品对比"><a href="#产品对比" class="headerlink" title="产品对比"></a>产品对比</h2><p><strong>Redis：</strong>etcd诞生之日起，就定位成一种分布式存储系统，并在k8s 服务注册和服务发现中，为大家所认识。它偏重的是节点之间的通信和一致性的机制保证，并不强调单节点的读写性能。</p><p>而redis最早作为缓存系统出现在大众视野，也注定了redis需要更加侧重于读写性能和支持更多的存储模式，它不需要care一致性，也不需要侧重事务，因此可以达到很高的读写性能。</p><p>总结一下，redis常用来做缓存系统，etcd常用来做分布式系统中一些关键数据的存储服务，比如服务注册和服务发现。</p><p><strong>Zookeeper：</strong>「服务发现」<strong>是开发者考虑 etcd 的主要原因，</strong>「高性能，易于生成节点特定配置」**被认为是选择 Zookeeper 的关键因素。</p><p>而且Zookeeper的虚拟节点可以在客户端断开后立马检测到，而etcd要靠keepAlive续约机制，超过几秒不续约了，则认为掉线了。</p>]]></content>
    
    
    <categories>
      
      <category>Container</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Kubernetes</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Istio</title>
    <link href="/2022/03/28/Container/Istio/"/>
    <url>/2022/03/28/Container/Istio/</url>
    
    <content type="html"><![CDATA[<h2 id="出现背景"><a href="#出现背景" class="headerlink" title="出现背景"></a>出现背景</h2><p>当「<strong>微服务架构</strong>」的趋势开始在互联网中蔓延，之所以微服务架构里，我们选择在应用层面而不是基础设施层面去解决这些分布式问题，完全是因为由硬件构成的基础设施，跟不上由软件构成的应用服务的灵活性的无奈之举。为此我们进入了「<strong>后微服务架构</strong>」的时代，Kubernetes出现了！当 Kubernetes 统一了容器编排管理系统之后，这些纯技术性的底层问题，便开始有了被广泛认可和采纳的基础设施层面的解决方案。</p><p>Kubernetes 的实现版本中直接删除了配置中心、服务注册中心的工程，在其他工程的 pom.xml 中也删除了如 Eureka、Ribbon、Config 等组件的依赖。取而代之的是新增了若干以 YAML 配置文件为载体的<strong>Skaffold</strong>和 Kubernetes 的资源描述，这些资源描述文件，将会动态构建出 DNS 服务器、服务负载均衡器等一系列虚拟化的基础设施，去代替原有的应用层面的技术组件。</p><p>可是，单纯的 Kubernetes 仍然不能解决我们面临的所有分布式技术问题，它难以做到精细化的服务治理，譬如熔断、流控、观测，等等。而即使是那些它可以提供支持的分布式能力，譬如通过 DNS 与服务来实现的服务发现与负载均衡，也只能说是初步解决了的分布式中如何调用服务的问题而已，只靠 DNS 难以满足根据不同的配置规则、协议层次、均衡算法等去调节负载均衡的执行过程这类高级的配置需求。</p><p>Kubernetes 给予了我们强大的虚拟化基础设施，这是一把好用的锤子，但我们却不必把所有问题都看作钉子，不必只局限于纯粹基础设施的解决方案。现在，基于 Kubernetes 之上构筑的<strong>服务网格（Service Mesh）</strong>是目前最先进的架构风格，即通过中间人流量劫持的方式，以介乎于应用和基础设施之间的边车代理（Sidecar）来做到既让用户代码可以专注业务需求，不必关注分布式的技术，又能实现几乎不亚于此前 Spring Cloud 时代的那种通过代码来解决分布式问题的可配置、安全和可观测性。</p><p>这一个目标，现在已成为了最热门的服务网格框架 <font color='blue'><strong>Istio</strong></font> 的 Slogan：Connect, Secure, Control, And Observe Services。</p><h2 id="流量管理"><a href="#流量管理" class="headerlink" title="流量管理"></a>流量管理</h2><p>我们可以使用Istio流量管理API对服务网格中的流量进行精细控制。我们可以使用这些API将自己的流量配置添加到Istio。此外，我们可以使用Kubernetes自定义资源定义（CRD）定义API资源。帮助我们控制流量路由的关键API资源是虚拟服务和目标规则。</p><p>基本上，虚拟服务使我们可以配置如何将请求路由到Istio服务网格中的服务。因此，虚拟服务由一个或多个按顺序评估的路由规则组成。评估虚拟服务的路由规则后，将应用目标规则。目标规则有助于我们控制到达目标的流量，例如，按版本对服务实例进行分组。</p><p><img src="/image/Istio/v2-e6ba4a015d8955c05015d5a41ca9b007_1440w.jpg" alt="img"></p><h2 id="安全性"><a href="#安全性" class="headerlink" title="安全性"></a>安全性</h2><p>Istio为每个服务提供身份。与每个Envoy代理一起运行的Istio代理与istiod一起使用以自动进行密钥和证书轮换。</p><p>Istio提供两种身份验证 <strong>对等身份验证、请求身份验证</strong>。对等身份验证用于服务到服务的身份验证，其中Istio提供双向TLS作为全栈解决方案。请求身份验证用于最终用户身份验证，其中Istio使用自定义身份验证提供程序或OpenID Connect（OIDC）提供程序提供JSON Web令牌（JWT）验证。</p><p>Istio还允许我们通过简单地将授权策略应用于服务来实施对服务的访问控制。授权策略对Envoy代理中的入站流量实施访问控制。这样，我们就可以在各种级别上应用访问控制：网格，命名空间和服务范围。</p><h2 id="可观察性"><a href="#可观察性" class="headerlink" title="可观察性"></a>可观察性</h2><p>Istio为网格网络内的所有服务通信生成详细的遥测，例如度量，分布式跟踪和访问日志。 Istio生成一组丰富的代理级指标，面向服务的指标和控制平面指标。</p><p>之前，Istio遥测体系结构将Mixer作为核心组件。但是从<strong>Telemetry v2</strong>开始，混音器提供的功能已替换为Envoy代理插件：</p><p>此外，Istio通过Envoy代理生成分布式跟踪。 Istio支持许多跟踪后端，例如Zipkin，Jaeger，Lightstep和Datadog。我们还可以控制跟踪速率的采样率。此外，Istio还以一组可配置的格式生成服务流量的访问日志。</p><h2 id="缺陷"><a href="#缺陷" class="headerlink" title="缺陷"></a>缺陷</h2><ol><li>服务网格处理所有服务到服务的通信，而部署和操作服务网格则需要支付额外的费用。对于较简单的应用程序，这可能是不合理的。</li><li>由于我们已经习惯于处理一些此类问题，例如应用程序代码中的熔断，因此可能导致服务网格中的重复处理。</li><li>越来越依赖于诸如服务网格之类的外部系统可能会损害应用程序的可移植性，尤其是因为没有针对服务网格的行业标准。</li><li><strong>由于服务网格通常通过拦截通过代理的网格流量来工作，因此它可能会给请求增加不希望的延迟。</strong></li><li>服务网格增加了许多其他组件和配置，需要精确处理。这需要专业知识，并增加了学习曲线。</li></ol><h2 id="替代品"><a href="#替代品" class="headerlink" title="替代品"></a>替代品</h2><p>尽管Istio非常受欢迎，并得到了业内一些领导者的支持，但它当然不是唯一的选择。尽管我们在这里无法进行全面的比较，但让我们看一下Linkerd和Consul这两个选项。</p><p><font color='blue'>Linkerd</font> 是已为Kubernetes平台创建的开源服务网格。它也很受欢迎，目前在CNCF中具有孵化项目的地位。它的工作原理类似于Istio等任何其他服务网格。它还利用TCP代理来处理网格流量。 Linkerd使用用Rust编写的微型代理，称为Linkerd代理。</p><p><font color='blue'>Consul</font> 是HashiCorp的服务网格的开源实现。它的好处是可以与HashiCorp的其他基础架构管理产品套件很好地集成，以提供更广泛的功能。 Consul中的数据平面可以灵活地支持代理以及本机集成模型。它带有内置代理，但也可以与Envoy一起使用。尽管它提供了服务网格（如Istio）的所有标准功能，但它是<strong>部署和管理的更复杂的系统</strong>。</p>]]></content>
    
    
    <categories>
      
      <category>Container</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Kubernetes</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Rancher</title>
    <link href="/2022/03/28/Container/Rancher/"/>
    <url>/2022/03/28/Container/Rancher/</url>
    
    <content type="html"><![CDATA[<h2 id="Why-Rancher"><a href="#Why-Rancher" class="headerlink" title="Why Rancher?"></a><a href="https://docs.rancher.cn/docs/rancher2.5/overview/_index">Why Rancher?</a></h2><p>Rancher 对于采用容器的团队来说是一个完整的软件栈。它解决了跨任何基础设施管理多个Kubernetes集群的操作和安全挑战，同时为 DevOps 团队提供运行集装箱式工作负载的集成工具。</p><h2 id="K8S-Environment"><a href="#K8S-Environment" class="headerlink" title="K8S Environment"></a>K8S Environment</h2><h3 id="Build-Virtual-Machines"><a href="#Build-Virtual-Machines" class="headerlink" title="Build Virtual Machines"></a>Build Virtual Machines</h3><p>创建虚拟机模拟生产环境的多台主机。</p><figure class="highlight bash"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></div></td><td class="code"><pre><code class="hljs Bash"><span class="hljs-comment"># docker run --network=host -p 8080:8080</span><br>docker run -itd --privileged --hostname=master --name centos7-master loveaeen/centos-docker:1.0 /usr/sbin/init<br><br>docker run -itd --privileged --hostname=minio1 --name centos7-minio1 loveaeen/centos-docker:1.0 /usr/sbin/init<br><br>docker run -itd --privileged --hostname=minio2 --name centos7-minio2 loveaeen/centos-docker:1.0 /usr/sbin/init<br><br>docker run -itd --privileged --hostname=minio3 --name centos7-minio3 loveaeen/centos-docker:1.0 /usr/sbin/init<br><br><span class="hljs-comment"># modify hostname</span><br><span class="hljs-comment"># hostnamectl set-hostname master</span><br></code></pre></td></tr></table></figure><h3 id="Network-File-System"><a href="#Network-File-System" class="headerlink" title="Network File System"></a>Network File System</h3><p>NFS（Network File System）即网络文件系统，它允许网络中的计算机之间通过网络共享资源。<strong>将NFS主机分享的目录，挂载到本地客户端当中，本地NFS的客户端应用可以透明地读写位于远端NFS服务器上的文件，在客户端端看起来，就像访问本地文件一样。</strong></p><p>Rancher有方便的PV(Persistent volume)配置，允许开发人员将容器内文件进行远程挂载。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs Bash">docker run -itd --privileged --hostname=nfs --name centos7-minio3 loveaeen/centos-docker:1.0 /usr/sbin/init<br></code></pre></td></tr></table></figure><h3 id="Run-Rancher"><a href="#Run-Rancher" class="headerlink" title="Run Rancher"></a>Run Rancher</h3><p>启动Rancher，并新建集群，运行他的docker命令，创建好主节点与工作节点，管理kubernetes。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs Bash">docker run -d --restart=unless-stopped -p 80:80 -p 443:443 -e CATTLE_SYSTEM_DEFAULT_REGISTRY=registry.cn-hangzhou.aliyuncs.com -e CATTLE_BOOTSTRAP_PASSWORD=admin --privileged rancher/rancher:v2.6.0<br></code></pre></td></tr></table></figure><h2 id="K3S-Environment"><a href="#K3S-Environment" class="headerlink" title="K3S Environment"></a>K3S Environment</h2><h3 id="Master"><a href="#Master" class="headerlink" title="Master"></a>Master</h3><p>使用<code>docker</code>方式在主节点上安装k3s server服务</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs Bash">curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | INSTALL_K3S_MIRROR=cn sh -s - --docker<br></code></pre></td></tr></table></figure><h3 id="Worker"><a href="#Worker" class="headerlink" title="Worker"></a>Worker</h3><p>使用<code>docker</code>方式在工作节点上安装k3s agent服务</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs Bash"><span class="hljs-comment"># k3s_token 可以在master节点的/var/lib/rancher/k3s/server/node-token找到</span><br><br>curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | INSTALL_K3S_MIRROR=cn K3S_URL=https://110.42.229.50:6443 K3S_TOKEN=K105e759bc78f55939faf9fd8c6018f2df53390e2572ef18d80180b71af65455895::server:992cc950fe1898069d48ff826912bcc6 sh -<br></code></pre></td></tr></table></figure><h3 id="Rancher-UI"><a href="#Rancher-UI" class="headerlink" title="Rancher UI"></a>Rancher UI</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs Bash">docker run -d --restart=unless-stopped -p 80:80 -p 443:443 -e CATTLE_SYSTEM_DEFAULT_REGISTRY=registry.cn-hangzhou.aliyuncs.com -e CATTLE_BOOTSTRAP_PASSWORD=admin --privileged rancher/rancher:v2.6.0<br></code></pre></td></tr></table></figure><h2 id="Spring-Cloud"><a href="#Spring-Cloud" class="headerlink" title="Spring Cloud"></a>Spring Cloud</h2><h3 id="Step"><a href="#Step" class="headerlink" title="Step"></a>Step</h3><ol><li>在自己的微服务中添加<code>docker-compose.yml</code>，创建好每一个微服务的构建命令。</li><li>每一个微服务有自己的<code>Dockerfile</code>，主要选择好&#x2F;target&#x2F;jar文件并配置相关参数，在<code>maven install</code>后可以直接执行compose命令做构建。</li><li><strong>注意：所有ip名称写对应的容器名字，让docker帮我们管理容器的互相访问。</strong></li><li>将所有镜像构建后，上传至私有服务器Harbor中，这样可以方便的放在内网中部署。</li><li>Rancher从Harbor中拉取镜像并创建Pod，在一些对外访问的Pod中升级端口映射或添加Ingress组件。如Nacos、Nginx。</li></ol><p><strong>PLEASE SEE VIDEO</strong> : <a href="https://www.bilibili.com/video/BV1XJ411D7Qu?p=9&amp;spm_id_from=pageDriver">https://www.bilibili.com/video/BV1XJ411D7Qu?p=9&amp;spm_id_from=pageDriver</a></p>]]></content>
    
    
    <categories>
      
      <category>Container</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Kubernetes</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>ElasticSearch</title>
    <link href="/2022/03/28/Distributed%20System/ElasticSearch/"/>
    <url>/2022/03/28/Distributed%20System/ElasticSearch/</url>
    
    <content type="html"><![CDATA[<h2 id="Documents"><a href="#Documents" class="headerlink" title="Documents"></a>Documents</h2><p>ElasticSearch是面向文档的, 这也就意味着索引和搜索数据的最小单位是<strong>文档</strong>. 文档有三个重要的属性</p><ul><li>自我包含: 意思是文档中会同时包含字段及对应的值, 也就是同时包含 key:value.</li><li>层次型: 一个泛化概念,表示一个文档可以有多层次的结构体, 你可以想象json, 某个属性可以是一个实体.</li><li>灵活的结构: 在ElasticSearch中, 你可以预定义文档的具体结构类型, 也可以动态添加字段, ElasticSearch会根据你添加的数据, 创建最适合的字段类型.</li></ul><p>尽管我们可以随意的新增或者忽略某个字段, 但是, 每个字段的类型非常重要, 比如一个<strong>年龄</strong>字段类型, 可以是字符串也可以是整形. 因为ElasticSearch会保存字段和类型之间的映射及其他的设置. 这种映射具体到每个映射的每种类型, 这也是为什么在elasticsearch中, 类型有时候也称为映射类型</p><h2 id="Types"><a href="#Types" class="headerlink" title="Types"></a><strong>T</strong>ypes</h2><p>类型是文档的逻辑容器,就像关系型数据库一样,表格是行的容器. 类型中对于字段的定义称<strong>为映射</strong>, 比如name映射为字符串类型. 我们说文档是无模式的 它们不需要拥有映射中所定义的所有字段, 比如新增一个字段, 那么ElasticSearch是怎么做的呢?</p><p>ElasticSearch会自动的将新字段加入映射, 但是这个字段的不确定它是什么类型, ElasticSearch就开始猜, 如果这个值是18, 那么ElasticSearch会认为它是整形. 但是ElasticSearch也可能猜不对, 所以最安全的方式就是提前定义好所需要的映射, 这点跟关系型数据库殊途同归了, 先定义好字段, 然后再使用, 别整什么幺蛾子.</p><h2 id="Index"><a href="#Index" class="headerlink" title="Index"></a><strong>Index</strong></h2><p>索引在ElasticSearch中就是关系型数据库的<strong>数据库</strong>, 索引存储了映射类型的字段和其他设置. 然后它们被存储到了各个分片上了.</p><h2 id="Alias"><a href="#Alias" class="headerlink" title="Alias"></a><strong>Alias</strong></h2><p>当A索引和B索引同时被设置了alias后, 例如:<code>ali</code>, 对该别名进行查询时, 则可以直接查询到A索引和B索引的数据, ElasticSearch会自动帮我们整合数据. 但是我们无法直接对别名索引进行写操作. 如果想进行写操作, 只能指定具体的索引. 既然索引可以设置别名, 字段同样可以设置别名. 但是我觉得用的地方不是很多.</p><h2 id="Shards"><a href="#Shards" class="headerlink" title="Shards"></a><strong>Shard</strong>s</h2><p>什么是分片? 简单来讲就是咱们存储在ElasticSearch中所有数据的文件块, 也就是数据的最小单元块。</p><p>ElasticSearch的核心就是对所有分片的分布, 索引, 负载, 路由等达到惊人的速度. 比如我们设置了一个索引中有两个主分片, 我们向里面插入10条数据. 那么这10条数据会尽可能均匀的存储在这两个分片中. <strong>每个分片理论上不存储超过30G的数据</strong>, 每一个分片对应着一个节点, 节点数≥分片数. 如果为了保证数据的容灾, 我们就要引入副本分片了</p><p>主分片是在索引创建时就固定不可更改的，而副本分片可以动态增减。</p><h3 id="How-to-write？"><a href="#How-to-write？" class="headerlink" title="How to write？"></a>How to write？</h3><p>首先客户端发送请求, 找到某个节点后转发到协调节点, 然后根据数据id进行HASH路由找到具体的分片中进行写入. 当数据请求到分片中以后, 首先会存储在内存中(buffer和TransLog<sup id="fnref:1" class="footnote-ref"><a href="#fn:1" rel="footnote"><span class="hint--top hint--rounded" aria-label="该文件实时记录所有的修改索引操作确保数据不丢失, 提供索引恢复.">[1]</span></a></sup>文件) .此时数据无法被查询到.</p><p>然后ElasticSearch的定时线程每隔1秒钟(<strong>refresh</strong>)将buffer数据刷入到段文件里, 同时建立好倒排索引, 并清空buffer. 这时的段文件并没有存储在磁盘里, 是放在了系统缓存(Os Cache)中.</p><p>ElasticSearch另外一个定时线程每隔5秒钟(<strong>flush,fsync</strong>)会将TransLog数据刷入磁盘. 所以在严格意义上来说, ElasticSearch会丢失5秒钟的数据</p><p>当TransLog文件大小达到一定的阈值后, 会触发Commit操作. 就是将Os Cache数据全部刷入磁盘. ElasticSearch也会有一个定时器每隔30分钟进行一次Commit操作</p><p><img src="/image/ElasticSearch/11.png" alt="img"></p><h3 id="How-to-read？"><a href="#How-to-read？" class="headerlink" title="How to read？"></a>How to read？</h3><p>那么既然我们存在了两个主分片, 当我们查询其中一条数据时, ElasticSearch如何帮我们找到具体在哪个分片中呢? 其实与写入操作是相似的, 也是需要根据id来进行HASH路由找到具体的分片, 如果该分片有备份分片的话, 则会默认采取round-robin随机轮询算法去找一个分片来查询.</p><h2 id="Segment-file"><a href="#Segment-file" class="headerlink" title="Segment file"></a>Segment file</h2><p>段文件存储的是数据信息, 你可以理解为Mysql的[[数据页]], 并且会定期进行<strong>段合并</strong>操作</p><p>因ElasticSearch每秒定时器影响. 并且代码中也可能会手动调用刷新操作. 这就会导致短时间内段文件数量会暴增. 而每一个段文件都会消耗文件句柄, 内存和cpu运行周期. <strong>更重要的是, 每个搜索请求都会轮询搜索每一个段, 所以段越多, 搜索越慢</strong></p><p>为了解决这种段文件越来越多的问题, ElasticSearch出现了<strong>段合并</strong>功能. 段合并会将那些旧的已删除的文档从文件系统中清除.</p><p>段合并操作不需要我们手动配置, 在进行搜索时会自动进行</p><h2 id="Index-Templates"><a href="#Index-Templates" class="headerlink" title="Index Templates"></a><strong>Index</strong> Templates</h2><p>在实际开发中, ElasticSearch很大一部分工作是用来处理日志信息的, 比如某公司对于日志处理策略是以日期为名创建每天的日志索引. 并且每天的索引映射类型和配置信息都是一样的, 只是索引名称改变了. 如果手动的创建每天的索引, 将会是一件很麻烦的事情. 为了解决类似问题, ElasticSearch提供了预先定义的模板进行索引创建, 这个模板称作为Index Templates. 通过索引模板可以让类似的索引重用同一个模板</p><ul><li>索引模版内容</li></ul><figure class="highlight json"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br></pre></div></td><td class="code"><pre><code class="hljs JSON">PUT _template/open_api_logs_template<br><span class="hljs-punctuation">&#123;</span><br>  <span class="hljs-attr">&quot;index_patterns&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><span class="hljs-string">&quot;open_api_logs.*&quot;</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;settings&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;number_of_shards&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">3</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;number_of_replicas&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;analysis&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>      <span class="hljs-attr">&quot;analyzer&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>        <span class="hljs-comment">// 逗号分割字符</span><br>        <span class="hljs-attr">&quot;comma&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>          <span class="hljs-attr">&quot;type&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;pattern&quot;</span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;pattern&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;,&quot;</span><br>        <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;pinyin_analyzer&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>          <span class="hljs-attr">&quot;tokenizer&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;hotline_pinyin&quot;</span><br>        <span class="hljs-punctuation">&#125;</span><br>      <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-comment">// 拼音分词器，需要自己下载一下给ES</span><br>      <span class="hljs-attr">&quot;tokenizer&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>        <span class="hljs-attr">&quot;hotline_pinyin&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>          <span class="hljs-attr">&quot;type&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;pinyin&quot;</span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;keep_joined_full_pinyin&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-keyword">true</span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;keep_none_chinese_in_joined_full_pinyin&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-keyword">true</span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;keep_original&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-keyword">true</span><br>        <span class="hljs-punctuation">&#125;</span><br>      <span class="hljs-punctuation">&#125;</span><br>    <span class="hljs-punctuation">&#125;</span><br>  <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;aliases&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>      <span class="hljs-attr">&quot;open_api_logs&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><span class="hljs-punctuation">&#125;</span><br>    <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;mappings&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;properties&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>      <span class="hljs-attr">&quot;id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>        <span class="hljs-attr">&quot;type&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;keyword&quot;</span><br>      <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;loginName&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>        <span class="hljs-attr">&quot;type&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;keyword&quot;</span><br>      <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;content&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>        <span class="hljs-attr">&quot;type&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;text&quot;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;analyzer&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;ik_max_word&quot;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;search_analyzer&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;ik_smart&quot;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;fields&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>          <span class="hljs-attr">&quot;search_pinyin&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>            <span class="hljs-attr">&quot;type&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;text&quot;</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">&quot;analyzer&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;pinyin_analyzer&quot;</span><br>          <span class="hljs-punctuation">&#125;</span><br>        <br>        <span class="hljs-punctuation">&#125;</span><br>      <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;type&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>        <span class="hljs-attr">&quot;type&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;integer&quot;</span><br>      <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;methodName&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>        <span class="hljs-attr">&quot;type&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;text&quot;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;analyzer&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;ik_max_word&quot;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;search_analyzer&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;ik_smart&quot;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;fields&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>          <span class="hljs-attr">&quot;search_pinyin&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>            <span class="hljs-attr">&quot;type&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;text&quot;</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">&quot;analyzer&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;pinyin_analyzer&quot;</span><br>          <span class="hljs-punctuation">&#125;</span><br>        <br>        <span class="hljs-punctuation">&#125;</span><br>      <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;parameters&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>        <span class="hljs-attr">&quot;type&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;text&quot;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;analyzer&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;ik_max_word&quot;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;search_analyzer&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;ik_smart&quot;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;fields&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>          <span class="hljs-attr">&quot;search_pinyin&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>            <span class="hljs-attr">&quot;type&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;text&quot;</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">&quot;analyzer&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;pinyin_analyzer&quot;</span><br>          <span class="hljs-punctuation">&#125;</span><br>        <br>        <span class="hljs-punctuation">&#125;</span><br>      <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;ip&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>        <span class="hljs-attr">&quot;type&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;keyword&quot;</span><br>      <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;result&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>        <span class="hljs-attr">&quot;type&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;text&quot;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;analyzer&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;ik_max_word&quot;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;search_analyzer&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;ik_smart&quot;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;fields&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>          <span class="hljs-attr">&quot;search_pinyin&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>            <span class="hljs-attr">&quot;type&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;text&quot;</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">&quot;analyzer&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;pinyin_analyzer&quot;</span><br>          <span class="hljs-punctuation">&#125;</span><br>        <br>        <span class="hljs-punctuation">&#125;</span><br>      <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;startTime&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>        <span class="hljs-attr">&quot;type&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;date&quot;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;format&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||yyyy/MM/dd HH:mm:ss&quot;</span><br>      <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;takeTime&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>        <span class="hljs-attr">&quot;type&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;integer&quot;</span><br>      <span class="hljs-punctuation">&#125;</span><br>    <span class="hljs-punctuation">&#125;</span><br>  <span class="hljs-punctuation">&#125;</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><h2 id="Rollover-Index"><a href="#Rollover-Index" class="headerlink" title="Rollover Index"></a>Rollover Index</h2><p>滚动索引一般可以与<strong>索引模板</strong>结合使用, 实现按一定条件自动创建索引. 设置<code>Rollover</code> 满足条件后, 会自动新建索引, 将索引别名转向新索引. 当现有的索引太久或者太大时, 往往使用rollover index创建新索引</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs Java">POST /logs_write/_rollover <br>&#123;<br>  <span class="hljs-string">&quot;conditions&quot;</span>: &#123;<br>    <span class="hljs-comment">// 如果索引创建超过了7天, 最大文档数到达了1000, 大小到达了5g, 则新建一个索引-000002</span><br>    <span class="hljs-string">&quot;max_age&quot;</span>:   <span class="hljs-string">&quot;7d&quot;</span>,<br>    <span class="hljs-string">&quot;max_docs&quot;</span>:  <span class="hljs-number">1000</span>,<br>    <span class="hljs-string">&quot;max_size&quot;</span>:  <span class="hljs-string">&quot;5gb&quot;</span><br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="Index-Sorts"><a href="#Index-Sorts" class="headerlink" title="Index Sorts"></a><strong>I</strong>ndex Sorts</h2><ul><li>ElasticSearch默认对数据的排序是写入排序, 意味着谁先写进来, 谁就排在最后面. 但是实际开发中, 我们都是对某字段做排序检索, 当我们指定某字段排序时, 在ElasticSearch底层是需要对所有倒排索引进行遍历, 然后对我们指定的某个字段做排序, 并取出前TopN的结果集.</li><li>如果数据量较小的情况, 性能无需担心, 但是当数据量特别大的情况下, 这种遍历过程就会耗费较长的时间. 于是, ElasticSearch为了解决这种问题, 推出了<strong>索引排序</strong></li><li>顾名思义, 就是对索引里的数据做排序. 当我们配置了指定字段的排序后, 检索方式符合ElasticSearch推荐的方式, 比如不统计命中总数, 不统计最大值等, 那么我们就会触发Early Termination机制, 不会再遍历所有文档, 而是按照顺序找到N条数据</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs Java">PUT events<br>&#123;<br>    <span class="hljs-string">&quot;settings&quot;</span> : &#123;<br>        <span class="hljs-string">&quot;index&quot;</span> : &#123;<br>            <span class="hljs-string">&quot;sort.field&quot;</span> : <span class="hljs-string">&quot;timestamp&quot;</span>,<br>            <span class="hljs-string">&quot;sort.order&quot;</span> : <span class="hljs-string">&quot;desc&quot;</span> <br>        &#125;<br>    &#125;,<br>    <span class="hljs-string">&quot;mappings&quot;</span>: &#123;<br>        <span class="hljs-string">&quot;properties&quot;</span>: &#123;<br>            <span class="hljs-string">&quot;timestamp&quot;</span>: &#123;<br>                <span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;date&quot;</span><br>            &#125;<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="Optimization"><a href="#Optimization" class="headerlink" title="Optimization"></a>Optimization</h2><ol><li><p><code>/etc/elasticsearch/jvm.options</code> - <code>-Xms32g -Xmx32g -Xx:+ExitOnOutOfMemoryError</code> - 这里建议，不管物理内存有多大，分配给Elasticsearch的只设成32G，同时后面如果出现OOM，进程直接退出 - 为什么说要把它改成这个呢？因为我们在使用一个集群时看到，有时因为聚合操作的原因，会导致某一台机器上的JAVA进程出现OOM，但是这个JVM进程还在，并没有退出，退出的话可以通过monit捕捉到，也可以进行重启。如果没有退出，而是一直挂在那的话，就不能提供正常的服务。 此外加上这个参数的话，需要升级一下JDK版本，JDK要求1.8.0_92, 从这个版本开始支持<code>ExitOnOutOfMemoryError</code>参数</p></li><li><p><code>/etc/elasticsearch/elasticsearch.yml</code> - <code>bootstarp.memory_lock:true</code> 锁定内存，防止内存交换。</p><p><code>bootstrap.system_call_filter:false</code> 禁用seccomp</p></li><li><p>参数优化 - <code>index.refresh_interval = 15</code>s 数据多久可以被查询到，控制buffer存入到段文件的速度。每秒写入量越大，该值也应更大。</p><p> <code>index.translog.flush_threshold_size = 2g</code> 当内存中的translog达到2g，tanslog会执行刷盘</p></li></ol><h3 id="Search"><a href="#Search" class="headerlink" title="Search"></a>Search</h3><p>虽然ElasticSearch查询性能极佳, 但是合理的调整服务器与数据模型设计, 是我们区别于只会使用ElasticSearch查询的人群的关键.</p><h4 id="文件系统缓存"><a href="#文件系统缓存" class="headerlink" title="文件系统缓存"></a>文件系统缓存</h4><ul><li>Elasticsearch 高度依赖操作系统的 <code>filesystem cache</code> 来提升其数据读取效率，如果我们将大量的系统内存分配给 JVM 进程(例如将堆内存设置的很大), 那么将导致操作系统无法得到足够的内存来作为 <code>filesystem cache</code>, 这会严重的影响 Elasticsearch 的性能.</li><li>我们知道现代操作系统中的内存都是按页分配的，操作系统在把某些数据从外存读取到内存中的页面上时，会把紧邻在被读取数据后面的几个页面的数据也读到内存中，这叫做<strong>文件预读</strong>，文件预读会极大的提升硬盘的顺序读取速度。除此之外，数据在被读取到内存中之后，即使用户已经使用完毕，操作系统也不会立即把这些数据所占用的内存给释放掉，这些数据会暂时的保存在内存中，如果此时用户开始读取硬盘上的同一块数据，操作系统会立即从内存中把该数据返回给用户而不需要再去操作硬盘进行数据读取操作，这部分暂时留存在内存中的数据就叫做<strong>页缓存</strong> (<a href="https://en.wikipedia.org/wiki/Page_cache">page cache</a>)。</li></ul><h4 id="数据预热"><a href="#数据预热" class="headerlink" title="数据预热"></a>数据预热</h4><ul><li>每当机器重启时, <code>filesystem cache</code>就会被清空, OS将索引的热点数据加载进来是需要花费时间的. 所以我们可以增加<code>index.store.preload</code> 告知OS, 优先将这些数据加载进入</li></ul><h4 id="冷热分离思想"><a href="#冷热分离思想" class="headerlink" title="冷热分离思想"></a>冷热分离思想</h4><ul><li>就是将冷数据与热数据进行分离, 让热数据被默认搜索, 而冷数据需要选取时间节点后才允许搜索到. 如果要进行这项功能的话, 单机情况可以采用<a href="((H7wp71XmU))">索引别名</a>的方式, 而集群的话需要采用[[数据分层]]功能</li></ul><h4 id="文档结构设计"><a href="#文档结构设计" class="headerlink" title="文档结构设计"></a>文档结构设计</h4><ul><li>既然ElasticSearch是搜索引擎, 那么我们就不要将非查询字段添加进来了, 一方面会让文件增大, 一方面也会让索引查询变慢.</li></ul><h4 id="分页性能优化"><a href="#分页性能优化" class="headerlink" title="分页性能优化"></a>分页性能优化</h4><ul><li>ElasticSearch的分页效率不高, 按照实际开发中的那种方式分页的话, 初始速度还可以, 但是越到后面速度越慢. 所以ElasticSearch有其他的推荐分页方式<ul><li><ol><li><code>scroll api</code> 快照下拉滚动方式. 这个方式有时间限制, 超出该时间会报错</li></ol></li><li><ol><li><code>search after</code> 通过上一页的结果获取下一页数据</li></ol></li></ul></li></ul><h2 id="Ingest-Pipeline"><a href="#Ingest-Pipeline" class="headerlink" title="Ingest Pipeline"></a>Ingest Pipeline</h2><h3 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h3><p>默认情况下，每个节点都是Ingest Node，可以通过node.ingest&#x3D;true|false来设置</p><p>目前最常用的就是在doc中追加插入时间, 采用pipeline的方式配置, 这样可以有效的在kibana进行时间查询.</p><h3 id="功能"><a href="#功能" class="headerlink" title="功能"></a>功能</h3><p>ingest node具有预处理，可拦截Index或者Bulk API的请求. 对数据进行转化和加工，并重新返回给Index或者Bulk API的功能</p><h3 id="组件"><a href="#组件" class="headerlink" title="组件"></a>组件</h3><p>Pipeline 对通过的数据按照顺序进行加工 Processor 对一些加工的行为进行了封装</p><h2 id="Cluster"><a href="#Cluster" class="headerlink" title="Cluster"></a>Cluster</h2><p><img src="/image/ElasticSearch/iShot2021-09-03%2013.52.52.png" alt="img"></p><h3 id="Summary-摘要"><a href="#Summary-摘要" class="headerlink" title="Summary(摘要)"></a>Summary(摘要)</h3><p>节点(<code>node</code>)是你运行的Elasticsearch实例。一个集群(<code>cluster</code>)是一组具有相同cluster.name的节点集合，他们协同工作，共享数据并提供故障转移和扩展功能，当有新的节点加入或者删除节点，集群就会感知到并平衡数据。集群中一个节点会被选举为主节点(master),它用来管理集群中的一些变更，例如新建或删除索引、增加或移除节点等;当然一个节点也可以组成一个集群。</p><p>当你的集群扩容或缩小，Elasticsearch将会自动在你的节点间迁移分片，以使集群保持平衡。</p><p>当我们指定了某个索引有主分片以及副本分片时，在集群中，该索引会自动的将各个分片有效分配到不同节点中，避免了单点故障的风险。</p><p>当主节点宕机，集群会自动选举某从节点为主节点，并将主分片从故障节点转移。此时的集群状态是Yellow，需要重启故障节点才会Green。</p><h3 id="Enviroment-amp-Config"><a href="#Enviroment-amp-Config" class="headerlink" title="Enviroment &amp; Config"></a>Enviroment &amp; Config</h3><p>集群配置中最重要的两项是<code>node.name</code>与<code>network.host</code>，每个节点都必须不同。其中<code>node.name</code>是节点名称主要是在Elasticsearch自己的日志加以区分每一个节点信息。 <code>discovery.zen.ping.unicast.hosts</code>是集群中的节点信息，可以使用IP地址、可以使用主机名(必须可以解析)。</p><figure class="highlight avrasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs avrasm">vim /etc/elasticsearch/elasticsearch.yml<br><br><span class="hljs-symbol">cluster.name:</span> my-els                               <span class="hljs-meta"># 集群名称,设置成一样的才能放在一个集群中。</span><br><span class="hljs-symbol">node.name:</span> els-node1                               <span class="hljs-meta"># 节点名称，仅仅是描述名称，用于在日志中区分</span><br><br><span class="hljs-symbol">path.data:</span> /opt/elasticsearch/data                 <span class="hljs-meta"># 数据的默认存放路径</span><br><span class="hljs-symbol">path.logs:</span> /opt/elasticsearch/log                  <span class="hljs-meta"># 日志的默认存放路径</span><br><br><span class="hljs-symbol">network.host:</span> <span class="hljs-number">192.168</span><span class="hljs-number">.60</span><span class="hljs-number">.201</span>                        <span class="hljs-meta"># 当前节点的IP地址</span><br><span class="hljs-symbol">http.port:</span> <span class="hljs-number">9200</span>                                    <span class="hljs-meta"># 对外提供服务的端口，9300为集群服务的端口</span><br><span class="hljs-meta">#添加如下内容</span><br><span class="hljs-meta">#culster transport port</span><br><span class="hljs-symbol">transport.tcp.port:</span> <span class="hljs-number">9300</span><br><span class="hljs-symbol">transport.tcp.compress:</span> true<br><br><span class="hljs-symbol">discovery.zen.ping.unicast.hosts:</span> [<span class="hljs-string">&quot;192.168.60.201&quot;</span>, <span class="hljs-string">&quot;192.168.60.202&quot;</span>,<span class="hljs-string">&quot;192.168.60.203&quot;</span>]       <br><span class="hljs-meta"># 集群个节点IP地址，也可以使用els、els.shuaiguoxia.com等名称，需要各节点能够解析</span><br><br><span class="hljs-symbol">discovery.zen.minimum_master_nodes:</span> <span class="hljs-number">2</span>              <span class="hljs-meta"># 为了避免脑裂，集群节点数最少为 半数+1</span><br></code></pre></td></tr></table></figure><h3 id="UserAdd"><a href="#UserAdd" class="headerlink" title="UserAdd"></a>UserAdd</h3><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs awk"><span class="hljs-comment"># 创建用户组</span><br>groupadd es<br><span class="hljs-comment"># 创建用户并添加至用户组</span><br>useradd es -g es <br><span class="hljs-comment"># 更改用户密码（输入 123123）</span><br>passwd es<br><br>chown -R es:es  <span class="hljs-regexp">/etc/</span>share<span class="hljs-regexp">/elasticsearch/</span><br>chown -R es:es  <span class="hljs-regexp">/usr/</span>share<span class="hljs-regexp">/elasticsearch/</span><br>chown -R es:es  <span class="hljs-regexp">/var/</span>log<span class="hljs-regexp">/elasticsearch/</span>      <span class="hljs-comment"># 以上操作都是为了赋予es用户操作权限</span><br><br><span class="hljs-comment"># 需切换为es用户</span><br>su es<br><span class="hljs-comment"># 启动服务（当前的路径为：/usr/share/elasticsearch/）</span><br>.<span class="hljs-regexp">/bin/</span>elasticsearch -p <span class="hljs-regexp">/tmp/</span>elasticsearch-pid -d<br></code></pre></td></tr></table></figure><h3 id="Head"><a href="#Head" class="headerlink" title="Head"></a>Head</h3><p>head插件是一个ES集群的web前端工具，它提供可视化的页面方便用户查看节点信息，对ES进行各种操作，如查询、删除、浏览索引等。</p><h2 id="Problems"><a href="#Problems" class="headerlink" title="Problems"></a>Problems</h2><ul><li>LocalDateTime：请使用String类型的日期时间格式化，或者使用long类型存储。其他解决方式都太麻烦了。</li><li>采用上方String存入的话，kibana设置browser，会存在kibana的时间查询有问题，改成UTC模式的话，需要选择精确的时间范围，不能用默认的now()来确定当前时间。</li></ul><section class="footnotes"><div class="footnote-list"><ol><li><span id="fn:1" class="footnote-text"><span>该文件实时记录所有的修改索引操作确保数据不丢失, 提供索引恢复.<a href="#fnref:1" rev="footnote" class="footnote-backref"> ↩</a></span></span></li></ol></div></section>]]></content>
    
    
    <categories>
      
      <category>Distributed System</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Database</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Zookeeper</title>
    <link href="/2022/03/28/Distributed%20System/Zookeeper/"/>
    <url>/2022/03/28/Distributed%20System/Zookeeper/</url>
    
    <content type="html"><![CDATA[<h2 id="集群与节点"><a href="#集群与节点" class="headerlink" title="集群与节点"></a>集群与节点</h2><p>首先，Zookeeper 集群中有几个关键的概念：<strong>Leader</strong>、<strong>Follower</strong> 和 <strong>Observer</strong>。</p><p>Zookeeper 中通常只有 Leader 节点可以写入，Follower 和 Observer 都只是负责读，但是 Follower 会参与节点的选举和过半写成功，Observer 则不会，他只是单纯的提供读取数据的功能。</p><p>通常这样设置的话，是为了避免太多的从节点参与过半写的过程，导致影响性能，这样 Zookeeper 只要使用一个几台机器的小集群就可以实现高性能了，如果要横向扩展的话，只需要增加 Observer 节点即可。</p><p>Zookeeper 建议集群节点个数为奇数，只要超过一半的机器能够正常提供服务，那么整个集群都是可用的状态。</p><p><img src="/image/Zookeeper/52A2EAAD-2AFE-4559-BEF9-88CAD40D9FB2_2.jpeg" alt="Image"></p><h3 id="数据节点-Znode"><a href="#数据节点-Znode" class="headerlink" title="数据节点 Znode"></a>数据节点 Znode</h3><p>Zookeeper 中数据存储于内存之中，这个数据节点就叫做 Znode，他是一个树形结构，比如&#x2F;a&#x2F;b&#x2F;c 类似。</p><p>而 Znode 又分为<strong>持久节点、临时节点、顺序节点</strong>三大类。</p><p><strong>持久节点：</strong>是指只要被创建，除非主动移除，否则都应该一直保存在 Zookeeper 中。</p><p><strong>临时节点：</strong>不同的是，他的生命周期和客户端 Session 会话一样，会话失效，那么临时节点就会被移除。</p><p>还有就是临时顺序节点和持久顺序节点，除了基本的特性之外，子节点的名称还具有有序性。</p><h2 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h2><ol><li>命名服务 Name Service，依赖 Zookeeper 可以生成全局唯一的节点 ID，来对分布式系统中的资源进行管理。</li><li>分布式协调，这是 Zookeeper 的核心使用了。利用 Wather 的监听机制，一个系统的某个节点状态发生改变，另外系统可以得到通知。</li><li>集群管理，分布式集群中状态的监控和管理，使用 Zookeeper 来存储。</li><li>Master 选举，利用 Zookeeper 节点的全局唯一性，同时只有一个客户端能够创建成功的特点，可以作为 Master 选举使用，创建成功的则作为 Master。</li><li>分布式锁，利用 Zookeeper 创建临时顺序节点的特性。</li></ol><h3 id="分布式协调"><a href="#分布式协调" class="headerlink" title="分布式协调"></a>分布式协调</h3><p>这个其实是 zookeeper 很经典的一个用法，简单来说，就好比，你 A 系统发送个请求到 mq，然后 B 系统消息消费之后处理了。那 A 系统如何知道 B 系统的处理结果？用 zookeeper 就可以实现分布式系统之间的协调工作。A 系统发送请求之后可以在 zookeeper 上<strong>对某个节点的值注册个监听器</strong>，一旦 B 系统处理完了就修改 zookeeper 那个节点的值，A 系统立马就可以收到通知，完美解决。</p><h2 id="监听机制和原理"><a href="#监听机制和原理" class="headerlink" title="监听机制和原理"></a>监听机制和原理</h2><p>Zookeeper 可以提供分布式数据的发布&#x2F;订阅功能，依赖的就是 Wather 监听机制。</p><p><strong>客户端可以向服务端注册 Wather 监听，服务端的指定事件触发之后，就会向客户端发送一个事件通知</strong>。</p><p>他有几个特性：</p><ul><li>一次性：一旦一个 Wather 触发之后，Zookeeper 就会将它从存储中移除</li><li>客户端串行：客户端的 Wather 回调处理是串行同步的过程，不要因为一个 Wather 的逻辑阻塞整个客户端</li><li>轻量：Wather 通知的单位是 WathedEvent，只包含通知状态、事件类型和节点路径，不包含具体的事件内容，具体的时间内容需要客户端主动去重新获取数据</li></ul><p>主要流程如下：</p><ul><li>客户端向服务端注册 Wather 监听；</li><li>保存 Wather 对象到客户端本地的 WatherManager 中；</li><li>服务端 Wather 事件触发后，客户端收到服务端通知，从 WatherManager 中取出对应 Wather 对象执行回调逻辑。</li></ul><p><img src="/image/Zookeeper/8F31D61E-FDF7-43E9-B7E4-3E752D3EE02C_2.jpeg" alt="Image"></p><h2 id="数据一致性"><a href="#数据一致性" class="headerlink" title="数据一致性"></a>数据一致性</h2><p>Zookeeper 通过 ZAB 原子广播协议来实现数据的最终顺序一致性，他是一个类似 2PC 两阶段提交的过程。</p><p>由于 Zookeeper 只有 Leader 节点可以写入数据，如果是其他节点收到写入数据的请求，则会将之转发给 Leader 节点。</p><p>主要流程如下：</p><ol><li>Leader 收到请求之后，将它转换为一个 proposal 提议，并且为每个提议分配一个全局唯一递增的事务 ID：zxid，然后把提议放入到一个 FIFO 的队列中，按照 FIFO 的策略发送给所有的 Follower</li><li>Follower 收到提议之后，以事务日志的形式写入到本地磁盘中，写入成功后返回 ACK 给 Leader</li><li>Leader 在收到超过半数的 Follower 的 ACK 之后，即可认为数据写入成功，就会发送 commit 命令给 Follower 告诉他们可以提交 proposal了</li></ol><p><img src="/image/Zookeeper/4FB6945B-83C4-4D08-AA4D-E1376A07BD8C_2.jpeg" alt="Image"></p><p>ZAB 包含两种基本模式，崩溃恢复和消息广播。</p><p>整个集群服务在启动、网络中断或者重启等异常情况的时候，首先会进入到崩溃恢复状态，此时会通过选举产生 Leader 节点，当集群过半的节点都和 Leader 状态同步之后，ZAB 就会退出恢复模式。之后，就会进入消息广播的模式。</p><h2 id="Leader-选举"><a href="#Leader-选举" class="headerlink" title="Leader 选举"></a>Leader 选举</h2><p>Leader 的选举可以分为两个方面，同时选举主要包含事务 zxid 和 myid，节点主要包含 <code>LEADING</code> <code>FOLLOWING</code> <code>LOOKING</code> 3 个状态。</p><ul><li>服务启动期间的选举</li><li>服务运行期间的选举</li></ul><p><strong>服务启动期间的选举</strong></p><ol><li>首先，每个节点都会对自己进行投票，然后把投票信息广播给集群中的其他节点</li><li>节点接收到其他节点的投票信息，然后和自己的投票进行比较，首先 zxid 较大的优先，如果 zxid 相同那么则会去选择 myid 更大者，此时大家都是 LOOKING 的状态</li><li>投票完成之后，开始统计投票信息，如果集群中过半的机器都选择了某个节点机器作为 leader，那么选举结束</li><li>最后，更新各个节点的状态，leader 改为 LEADING 状态，follower 改为 FOLLOWING 状态</li></ol><p><strong>服务运行期间的选举</strong></p><p>如果开始选举出来的 leader 节点宕机了，那么运行期间就会重新进行 leader 的选举。</p><ul><li>leader 宕机之后，非 observer 节点都会把自己的状态修改为 LOOKING 状态，然后重新进入选举流程</li><li>生成投票信息(myid,zxid)，同样，第一轮的投票大家都会把票投给自己，然后把投票信息广播出去</li><li>接下来的流程和上面的选举是一样的，都会优先以 zxid，然后选择 myid，最后统计投票信息，修改节点状态，选举结束</li></ul><h2 id="选举后数据同步"><a href="#选举后数据同步" class="headerlink" title="选举后数据同步"></a>选举后数据同步</h2><p>那实际上 Zookeeper 在选举之后，Follower 和 Observer （统称为Learner）就会去向 Leader 注册，然后就会开始数据同步的过程。</p><p>数据同步包含 3 个主要值和 4 种形式。</p><p>PeerLastZxid：Learner服务器最后处理的 ZXID</p><p>minCommittedLog：Leader提议缓存队列中最小 ZXID</p><p>maxCommittedLog：Leader提议缓存队列中最大 ZXID</p><p><strong>直接差异化同步 DIFF 同步</strong></p><p>如果 PeerLastZxid 在 minCommittedLog 和 maxCommittedLog 之间，那么则说明 Learner 服务器还没有完全同步最新的数据。</p><ol><li>首先 Leader 向 Learner 发送 DIFF 指令，代表开始差异化同步，然后把差异数据（从 PeerLastZxid 到 maxCommittedLog 之间的数据）提议 proposal 发送给 Learner</li><li>发送完成之后发送一个 NEWLEADER 命令给 Learner，同时 Learner 返回 ACK 表示已经完成了同步</li><li>接着等待集群中过半的 Learner 响应了 ACK 之后，就发送一个 UPTODATE 命令，Learner 返回 ACK，同步流程结束</li></ol><p><img src="/image/Zookeeper/CBEDB9AF-C2F4-4BAF-9C34-FE071D753680_2.jpeg" alt="Image"></p><p><strong>先回滚再差异化同步 TRUNC+DIFF 同步</strong></p><p>这个设置针对的是一个异常的场景。</p><p>如果 Leader 刚生成一个 proposal，还没有来得及发送出去，此时 Leader 宕机，重新选举之后作为 Follower，但是新的 Leader 没有这个 proposal 数据。</p><h3 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h3><p>假设现在 Leader 是 A，minCommittedLog&#x3D;1，maxCommittedLog&#x3D;3，刚好生成的一个 proposal 的 ZXID&#x3D;4，然后挂了。</p><p>重新选举出来的 Leader是B，B 之后又处理了 2 个提议，然后minCommittedLog&#x3D;1，maxCommittedLog&#x3D;5。</p><p>这时候 A 的 PeerLastZxid&#x3D;4，在(1,5)之间。</p><p>那么这一条只存在于 A 的提议怎么处理？</p><p>A 要进行事务回滚，相当于抛弃这条数据，并且回滚到最接近于 PeerLastZxid 的事务，对于 A 来说，也就是 PeerLastZxid&#x3D;3。</p><p>流程和 DIFF 一致，只是会先发送一个 TRUNC 命令，然后再执行差异化 DIFF 同步。</p><p><strong>仅回滚同步 TRUNC 同步</strong></p><p>针对 PeerLastZxid 大于 maxCommittedLog 的场景，流程和上述一致，事务将会被回滚到 maxCommittedLog 的记录。</p><p>这个其实就更简单了，也就是你可以认为 TRUNC+DIFF 中的例子，新的Leader B 没有处理提议，所以 B 中 minCommittedLog&#x3D;1，maxCommittedLog&#x3D;3。</p><p>所以 A 的 PeerLastZxid&#x3D;4 就会大于 maxCommittedLog 了，也就是 A 只需要回滚就行了，不需要执行差异化同步 DIFF 了。</p><p><strong>全量同步 SNAP 同步</strong></p><p>适用于两个场景：</p><ul><li>PeerLastZxid 小于 minCommittedLog</li><li>Leader 服务器上没有提议缓存队列，并且 PeerLastZxid 不等于 Leader 的最大 ZXID</li></ul><p>这两种场景下，Leader 将会发送 SNAP 命令，把全量的数据都发送给 Learner 进行同步。</p>]]></content>
    
    
    <categories>
      
      <category>Distributed System</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>HELM</title>
    <link href="/2022/03/28/Container/HELM/"/>
    <url>/2022/03/28/Container/HELM/</url>
    
    <content type="html"><![CDATA[<h2 id="What-is-Helm"><a href="#What-is-Helm" class="headerlink" title="What is Helm?"></a><a href="https://helm.sh/">What is Helm?</a></h2><p>Helm是查找，共享和使用为Kubernetes构建的软件的最佳方法。</p><p>Helm帮助您管理Kubernetes应用程序。Helm Charts帮助您定义、安装和升级即使是最复杂的Kubernetes应用程序。</p><p>Charts易于创建，版本，共享和发布。因此，请开始使用Helm并停止复制和粘贴。</p>]]></content>
    
    
    <categories>
      
      <category>Container</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Kubernetes</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>K3S入门</title>
    <link href="/2022/03/28/Container/K3S%E5%85%A5%E9%97%A8/"/>
    <url>/2022/03/28/Container/K3S%E5%85%A5%E9%97%A8/</url>
    
    <content type="html"><![CDATA[<h2 id="What-is-k3s？"><a href="#What-is-k3s？" class="headerlink" title="What is k3s？"></a><a href="https://docs.rancher.cn/docs/k3s/_index">What is k3s？</a></h2><p>K3s 是一个轻量级的 Kubernetes 发行版，它针对边缘计算、物联网等场景进行了高度优化。</p><h2 id="Why-is-k3s？"><a href="#Why-is-k3s？" class="headerlink" title="Why is k3s？"></a>Why is k3s？</h2><p>使用内嵌轻量级数据库 SQLite 作为默认数据存储替代 etcd，当然 etcd 仍然是支持的。</p><p>内置了 local storage provider、service load balancer、helm controller、Traefik ingress controller，开箱即用。</p><p>所有 Kubernetes 控制平面组件如 api-server、scheduler 等封装成为一个精简二进制程序，控制平面只需要一个进程即可运行。</p><p>删除内置插件(比如 cloudprovider 插件和存储插件)。</p><p>减少外部依赖，操作系统只需要安装较新的内核以及支持 cgroup 即可，k3s 安装包已经包含了 containerd、Flannel、CoreDNS，非常方便地一键式安装，不需要额外安装 Docker、Flannel 等组件。</p><h2 id="Manual-run-k3s"><a href="#Manual-run-k3s" class="headerlink" title="Manual run k3s"></a>Manual run k3s</h2><h3 id="K3S-Environment"><a href="#K3S-Environment" class="headerlink" title="K3S Environment"></a>K3S Environment</h3><h2 id="AutoK3s"><a href="#AutoK3s" class="headerlink" title="AutoK3s"></a><a href="https://docs.rancher.cn/docs/k3s/autok3s/_index">AutoK3s</a></h2><p>AutoK3s 是用于简化 K3s 集群管理的轻量级工具，您可以使用 AutoK3s 在任何地方运行 K3s 服务。</p><h3 id="Docker"><a href="#Docker" class="headerlink" title="Docker"></a>Docker</h3><figure class="highlight bash"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><pre><code class="hljs Bash">docker run -itd --restart=unless-stopped -p 8080:8080 cnrancher/autok3s:v0.4.5<br></code></pre></td></tr></table></figure><h3 id="CLI"><a href="#CLI" class="headerlink" title="CLI"></a>CLI</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs Bash">curl -sS http://rancher-mirror.cnrancher.com/autok3s/install.sh  | INSTALL_AUTOK3S_MIRROR=cn sh<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Container</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Kubernetes</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Kubernetes入门</title>
    <link href="/2022/03/28/Container/Kubernetes%E5%85%A5%E9%97%A8/"/>
    <url>/2022/03/28/Container/Kubernetes%E5%85%A5%E9%97%A8/</url>
    
    <content type="html"><![CDATA[<h2 id="1-MASTER-NODE"><a href="#1-MASTER-NODE" class="headerlink" title="1. MASTER NODE"></a>1. MASTER NODE</h2><ul><li><a href="https://kubernetes.io/zh/docs/concepts/architecture/control-plane-node-communication/">API SERVER</a> : 你可以理解为网关. 当一个请求 (命令) 进入后, 首先就会请求到 API SERVER , 该组件也可以进行鉴权功能</li><li><a href="https://kubernetes.io/zh/docs/concepts/scheduling-eviction/kube-scheduler/">Scheduler</a> : 决定了你应该在哪台 Node 上进行 Pod 相关操作, 该组件只是去对应的 Node 中调度 Kubelet 组件, 比如你需要新增几个 Pod , 该组件就会根据 Node 目前资源使用量, 找到最不繁忙的一个 Node ,进行调度操作.</li><li><a href="https://kubernetes.io/zh/docs/concepts/architecture/cloud-controller/">Controller Manager</a> : 管理集群健康状况, 比如某个 Pod 宕机&#x2F;死去, 那么该组件检测到以后, 通知 Scheduler 选取一个适合的 Node , 然后调度对应的 Kubelet 组件进行资源重启</li><li><a href="https://etcd.io/">etcd</a> : 键值存储集群状态的组件, 想象它是集群的大脑🧠 如果一个 Pod 新生或者死亡, 都会将信息存储在该组件中. 很多组件都会通过它来获取一些必要的信息</li></ul><h2 id="2-SLAVE-NODE"><a href="#2-SLAVE-NODE" class="headerlink" title="2. SLAVE NODE"></a><strong>2. SLAVE NODE</strong></h2><ul><li><p><a href="https://kubernetes.io/zh/docs/setup/production-environment/container-runtimes/">Container Runtime</a> : 负责运行容器的软件, 一般来说, 大家都会使用 [[Docker]]</p></li><li><p><a href="https://kubernetes.io/zh/docs/reference/command-line-tools-reference/kubelet/">Kubelet</a> : 实际管理一个 Pod 或者重启它</p></li><li><p><a href="https://kubernetes.io/zh/docs/concepts/services-networking/ingress/">Ingress</a> : 公开了从集群外部到集群内<a href="https://kubernetes.io/zh/docs/concepts/services-networking/service/">服务</a>的 HTTP 和 HTTPS 路由. 流量路由由 Ingress 资源上定义的规则控制, 之后再发送至 Service</p></li><li><p><a href="https://kubernetes.io/zh/docs/concepts/services-networking/service/">Service</a> : 提供 Pod 的服务发现, 公开网络服务</p></li><li><p><a href="https://kubernetes.io/zh/docs/concepts/configuration/secret/">Secret</a> : 专门用于鉴权配置的组件, 比如配置 Mongodb 的账户和密码, 并在 Mongo 那边引用 Secret</p></li><li><p><a href="https://kubernetes.io/zh/docs/concepts/configuration/configmap/">ConfigMap</a> : 用于放置一些公共配置的组件</p></li><li><p><a href="https://kubernetes.io/zh/docs/concepts/workloads/controllers/statefulset/">StatefulSet</a>：StatefulSet 是用来管理有状态的应用，例如数据库。前面我们部署的应用，都是不需要存储数据，不需要记住状态的，可以随意扩充副本，每个副本都是一样的，可替代的。而像数据库、Redis 这类有状态的，则不能随意扩充副本。StatefulSet 会固定每个 Pod 的名字</p></li><li><p>Deployment</p><p> : Pod 的声明式抽象层, 负责管理 Pod, 现在已经不会直接创建 Pod , 而是使用 Deployment 代替.</p><ul><li><a href="https://kubernetes.io/zh/docs/concepts/workloads/pods/">Pod</a> : Kubernetes 中创建和管理的最小单元</li><li><a href="https://kubernetes.io/zh/docs/concepts/workloads/controllers/replicaset/">ReplicaSet</a> : 当你创建了一个 Deployment 后, 就会自动创建一个该组件出来, 反之删除也会一样. 主要用于维护 Pod 的数量</li></ul></li></ul><h2 id="3-KUBECTL"><a href="#3-KUBECTL" class="headerlink" title="3. KUBECTL"></a><strong>3. KUBECTL</strong></h2><ul><li>Kubectl 命令行工具管理 Kubernetes 集群, 所有的命令实际都是调用 REST API , 都会走 API SERVER.</li></ul><h2 id="4-NAMESPACE"><a href="#4-NAMESPACE" class="headerlink" title="4. NAMESPACE"></a><strong>4. NAMESPACE</strong></h2><ul><li>命名空间可以隔离资源, 并且 Kubernetes 可以限制每一个命名空间的最大使用资源情况</li><li>可以使用 <code>brew install kubectx</code> 安装插件, 切换默认的命名空间</li></ul><h2 id="5-TOOLS"><a href="#5-TOOLS" class="headerlink" title="5. TOOLS"></a><strong>5. TOOLS</strong></h2><ul><li><p>5.1</p><p>minikube</p><ul><li>Minikube 将 Master 与 Slave 放置在一个虚拟 Node 中运行, 并附加基本的 Container Runtime(Docker)</li></ul></li><li><p>5.2</p><p>Helm</p><ul><li>Helm 是查找、分享和使用软件构建 <a href="https://kubernetes.io/">Kubernetes</a> 的最优方式</li></ul></li></ul><h2 id="6-Sping-Cloud-amp-Kubernates"><a href="#6-Sping-Cloud-amp-Kubernates" class="headerlink" title="6. Sping Cloud &amp; Kubernates"></a>6. Sping Cloud &amp; Kubernates</h2>]]></content>
    
    
    <categories>
      
      <category>Container</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Kubernetes</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Docker Swarm</title>
    <link href="/2022/03/28/Container/Docker%20Swarm/"/>
    <url>/2022/03/28/Container/Docker%20Swarm/</url>
    
    <content type="html"><![CDATA[<h2 id="What-is-a-swarm"><a href="#What-is-a-swarm" class="headerlink" title="What is a swarm?"></a><a href="https://docs.docker.com/engine/swarm/key-concepts/#what-is-a-swarm">What is a swarm?</a></h2><p><font color='gray'>The cluster management and orchestration features embedded in the Docker Engine are built using swarmkit. Swarmkit is a separate project which implements Docker’s orchestration layer and is used directly within Docker.</font></p><p>Docker 引擎中嵌入的集群管理和编排特性是使用群集构建的。Swarmkit 是一个独立的项目，它实现了 Docker 的编排层，并直接在 Docker 中使用。</p><p><font color='gray'>A swarm consists of multiple Docker hosts which run in swarm mode and act as managers (to manage membership and delegation) and workers (which run swarm services). A given Docker host can be a manager, a worker, or perform both roles. When you create a service, you define its optimal state (number of replicas, network and storage resources available to it, ports the service exposes to the outside world, and more). Docker works to maintain that desired state. For instance, if a worker node becomes unavailable, Docker schedules that node’s tasks on other nodes. A task is a running container which is part of a swarm service and managed by a swarm manager, as opposed to a standalone container.</font></p><p>一个群体由多个 Docker 主机组成，它们以群体模式运行，充当管理者(管理成员资格和授权)和工作者(运行群体服务)。给定的 Docker 主机可以是管理者、工作者，或者同时执行这两个角色。当您创建一个服务时，您将定义它的最佳状态(副本的数量、可用的网络和存储资源、服务向外部世界公开的端口等)。多克尔工作是为了保持所需的状态。例如，如果一个工作节点变得不可用，Docker 将该节点的任务调度到其他节点上。任务是一个正在运行的容器，它是群服务的一部分，由群管理器管理，而不是一个独立的容器。</p><p><font color='gray'>One of the key advantages of swarm services over standalone containers is that you can modify a service’s configuration, including the networks and volumes it is connected to, without the need to manually restart the service. Docker will update the configuration, stop the service tasks with the out of date configuration, and create new ones matching the desired configuration.</font></p><p>与独立容器相比，群服务的一个关键优势是，您可以修改服务的配置，包括它所连接的网络和卷，而无需手动重新启动服务。Docker 将更新配置，使用过期配置停止服务任务，并创建与所需配置匹配的新任务。</p><p><font color='gray'>When Docker is running in swarm mode, you can still run standalone containers on any of the Docker hosts participating in the swarm, as well as swarm services. A key difference between standalone containers and swarm services is that only swarm managers can manage a swarm, while standalone containers can be started on any daemon. Docker daemons can participate in a swarm as managers, workers, or both.</font></p><p>当 Docker 在群模式下运行时，你仍然可以在任何参与群的 Docker 主机上运行独立的容器，以及群服务。独立容器和群服务的一个关键区别是，只有群管理器可以管理群，而独立容器可以在任何守护进程上启动。多克尔守护进程可以作为管理者、工作者或两者都参与到群中。</p><p><font color='gray'>In the same way that you can use Docker Compose to define and run containers, you can define and run Swarm service stacks.</font></p><p>与使用 dockercompose 定义和运行容器一样，您可以定义和运行 Swarm 服务堆栈。</p><p><font color='gray'>Keep reading for details about concepts relating to Docker swarm services, including nodes, services, tasks, and load balancing.</font></p><p>继续阅读关于 Docker 群服务相关概念的详细信息，包括节点、服务、任务和负载平衡。</p>]]></content>
    
    
    <categories>
      
      <category>Container</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Docker</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Harbor</title>
    <link href="/2022/03/28/Container/Harbor/"/>
    <url>/2022/03/28/Container/Harbor/</url>
    
    <content type="html"><![CDATA[<h2 id="What-is-Harbor"><a href="#What-is-Harbor" class="headerlink" title="What is Harbor?"></a>What is Harbor?</h2><blockquote><p>Harbor is an open source registry that secures artifacts with policies and role-based access control, ensures(确保) images are scanned and free from vulnerabilities(脆弱性), and signs images as trusted. Harbor, a CNCF Graduated project, delivers compliance, performance, and interoperability to help you consistently and securely manage artifacts across cloud native compute platforms like Kubernetes and Docker.</p></blockquote><p>Harbor是一个开源的注册中心，它通过政策和以角色为基础的存取控制保护工件，确保图像被扫描并且没有漏洞，并且标记镜像为可信的。Harbor 是 CNCF 的一个毕业项目，它提供了遵从性、性能和互操作性，以帮助您在像 Kubernetes 和 Docker 这样的云本地计算平台上稳定和安全地管理工件。</p><p>主要用于为企业管理私有镜像，由Docker部署并运行。</p><h2 id="Installation"><a href="#Installation" class="headerlink" title="Installation"></a><a href="https://github.com/goharbor/harbor/releases">Installation</a></h2><ul><li><p><font color='gray'><strong>Online installer</strong>: The online installer downloads the Harbor images from Docker hub. For this reason, the installer is very small in size.</font></p><p>在线下载：在线安装程序从 Docker hub 下载 Harbor 镜像。因此，安装程序的体积非常小。</p></li><li><p><font color='gray'><strong>Offline installer</strong>: Use the offline installer if the host to which are are deploying Harbor does not have a connection to the Internet. The offline installer contains pre-built images, so it is larger than the online installer.</font></p><p>离线下载：如果正在部署 Harbor 的主机没有连接到 Internet，请使用离线下载。离线下载包含预先构建的镜像，因此它比联机安装程序大。</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></div></td><td class="code"><pre><code class="hljs Bash"><span class="hljs-comment"># github install offline installer.tgz</span><br><span class="hljs-comment"># then scp remote linux</span><br>scp harbor-offline-installer-v2.4.1.tgz root@110.42.229.50:/root/harbor-offline-installer-v2.4.1.tgz<br><br><span class="hljs-comment"># tar</span><br>tar -zxvf harbor-offline-installer-v2.4.1.tgz<br><br><span class="hljs-comment"># config yml &amp; modify **hostname to ip**</span><br><span class="hljs-built_in">cd</span> /harbor<br>vim harbor.yml<br>./install.sh<br><br><span class="hljs-comment"># http request</span><br>[http://110.42.229.50/harbor](http://110.42.229.50/harbor)<br></code></pre></td></tr></table></figure><h2 id="Docker-Integrate-集成"><a href="#Docker-Integrate-集成" class="headerlink" title="Docker Integrate(集成)"></a>Docker Integrate(集成)</h2><p>好像也不用。为了让harbor感知到docker，所以需要让docker重启，再用compose启动harbor。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs Bash"><span class="hljs-comment"># restart docker</span><br><span class="hljs-comment"># systemctl restart docker</span><br><br><span class="hljs-comment"># cd /harbor</span><br><span class="hljs-comment"># docker-compose start</span><br><br><span class="hljs-comment"># docker login &amp; push image</span><br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Container</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Docker</tag>
      
      <tag>kubernetes</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Docker Compose</title>
    <link href="/2022/03/28/Container/Docker%20Compose/"/>
    <url>/2022/03/28/Container/Docker%20Compose/</url>
    
    <content type="html"><![CDATA[<p>我们可以通过<code>Dockerfile</code>文件让用户很方便的定义一个单独的应用容器。然而，在日常工作中，经常会碰到需要多个容器相互配合来完成某项任务的情况，或者开发一个Web应用，除了Web服务容器本身，还需要数据库服务容器、缓存容器，甚至还包括负载均衡容器等等。</p><p><code>Docker Compose</code>是用于定义和运行多容器Docker应用程序的工具。通过Compose，您可以使用YAML文件来配置应用程序所需要的服务。然后使用一个命令，就可以通过YAML配置文件创建并启动所有服务。</p><h3 id="Samples"><a href="#Samples" class="headerlink" title="Samples"></a>Samples</h3><h4 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h4><ul><li>如果修改了jar文件后, 如果直接用docker-compose -f -d 直接重启容器的话, jar文件并不会改变, 我们需要使用-build命令进行重新构建才可以</li><li>spring的yaml配置中, 不要再设置固定ip了, 因为docker-compose管理中是默认给容器设置动态ip的, 如果想用服务连接nacos的话, 我们需要在需要的服务容器中添加nacos的link, 然后在spring的yaml配置中ip修改为link名称即可</li></ul><h4 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h4><figure class="highlight yaml"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br></pre></div></td><td class="code"><pre><code class="hljs YAML"><span class="hljs-attr">version :</span> <span class="hljs-string">&#x27;3.8&#x27;</span><br><span class="hljs-attr">services:</span><br>  <span class="hljs-attr">ruoyi-nacos:</span><br>    <span class="hljs-attr">container_name:</span> <span class="hljs-string">ruoyi-nacos</span><br>    <span class="hljs-attr">image:</span> <span class="hljs-string">nacos/nacos-server</span><br>    <span class="hljs-attr">build:</span><br>      <span class="hljs-attr">context:</span> <span class="hljs-string">./nacos</span><br>    <span class="hljs-attr">environment:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">MODE=standalone</span><br>    <span class="hljs-attr">volumes:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">./nacos/logs/:/home/nacos/logs</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">./nacos/conf/application.properties:/home/nacos/conf/application.properties</span><br>    <span class="hljs-attr">ports:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;8848:8848&quot;</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;9848:9848&quot;</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;9849:9849&quot;</span><br>    <span class="hljs-attr">depends_on:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">ruoyi-mysql</span><br>  <span class="hljs-attr">ruoyi-mysql:</span><br>    <span class="hljs-attr">container_name:</span> <span class="hljs-string">ruoyi-mysql</span><br>    <span class="hljs-attr">image:</span> <span class="hljs-string">mysql:5.7</span><br>    <span class="hljs-attr">build:</span><br>      <span class="hljs-attr">context:</span> <span class="hljs-string">./mysql</span><br>    <span class="hljs-attr">ports:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;3306:3306&quot;</span><br>    <span class="hljs-attr">volumes:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">./mysql/conf:/etc/mysql/conf.d</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">./mysql/logs:/logs</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">./mysql/data:/var/lib/mysql</span><br>    <span class="hljs-attr">command:</span> [<br>          <span class="hljs-string">&#x27;mysqld&#x27;</span>,<br>          <span class="hljs-string">&#x27;--innodb-buffer-pool-size=80M&#x27;</span>,<br>          <span class="hljs-string">&#x27;--character-set-server=utf8mb4&#x27;</span>,<br>          <span class="hljs-string">&#x27;--collation-server=utf8mb4_unicode_ci&#x27;</span>,<br>          <span class="hljs-string">&#x27;--default-time-zone=+8:00&#x27;</span>,<br>          <span class="hljs-string">&#x27;--lower-case-table-names=1&#x27;</span><br>        ]<br>    <span class="hljs-attr">environment:</span><br>      <span class="hljs-attr">MYSQL_DATABASE:</span> <span class="hljs-string">&#x27;ry-cloud&#x27;</span><br>      <span class="hljs-attr">MYSQL_ROOT_PASSWORD:</span> <span class="hljs-string">password</span><br>  <span class="hljs-attr">ruoyi-redis:</span><br>    <span class="hljs-attr">container_name:</span> <span class="hljs-string">ruoyi-redis</span><br>    <span class="hljs-attr">image:</span> <span class="hljs-string">redis</span><br>    <span class="hljs-attr">build:</span><br>      <span class="hljs-attr">context:</span> <span class="hljs-string">./redis</span><br>    <span class="hljs-attr">ports:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;6379:6379&quot;</span><br>    <span class="hljs-attr">volumes:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">./redis/conf/redis.conf:/home/ruoyi/redis/redis.conf</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">./redis/data:/data</span><br>    <span class="hljs-attr">command:</span> <span class="hljs-string">redis-server</span> <span class="hljs-string">/home/ruoyi/redis/redis.conf</span><br>  <span class="hljs-attr">ruoyi-nginx:</span><br>    <span class="hljs-attr">container_name:</span> <span class="hljs-string">ruoyi-nginx</span><br>    <span class="hljs-attr">image:</span> <span class="hljs-string">nginx</span><br>    <span class="hljs-attr">build:</span><br>      <span class="hljs-attr">context:</span> <span class="hljs-string">./nginx</span><br>    <span class="hljs-attr">ports:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;80:80&quot;</span><br>    <span class="hljs-attr">volumes:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">./nginx/html/dist:/home/ruoyi/projects/ruoyi-ui</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">./nginx/conf/nginx.conf:/etc/nginx/nginx.conf</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">./nginx/logs:/var/log/nginx</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">./nginx/conf.d:/etc/nginx/conf.d</span><br>    <span class="hljs-attr">depends_on:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">ruoyi-gateway</span><br>    <span class="hljs-attr">links:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">ruoyi-gateway</span><br>  <span class="hljs-attr">ruoyi-gateway:</span><br>    <span class="hljs-attr">container_name:</span> <span class="hljs-string">ruoyi-gateway</span><br>    <span class="hljs-attr">build:</span><br>      <span class="hljs-attr">context:</span> <span class="hljs-string">./ruoyi/gateway</span><br>    <span class="hljs-attr">ports:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;8080:8080&quot;</span><br>    <span class="hljs-attr">depends_on:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">ruoyi-redis</span><br>    <span class="hljs-attr">links:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">ruoyi-redis</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">ruoyi-nacos</span><br>  <span class="hljs-attr">ruoyi-auth:</span><br>    <span class="hljs-attr">container_name:</span> <span class="hljs-string">ruoyi-auth</span><br>    <span class="hljs-attr">build:</span><br>      <span class="hljs-attr">context:</span> <span class="hljs-string">./ruoyi/auth</span><br>    <span class="hljs-attr">ports:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;9200:9200&quot;</span><br>    <span class="hljs-attr">depends_on:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">ruoyi-redis</span><br>    <span class="hljs-attr">links:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">ruoyi-redis</span><br>  <span class="hljs-attr">ruoyi-modules-system:</span><br>    <span class="hljs-attr">container_name:</span> <span class="hljs-string">ruoyi-modules-system</span><br>    <span class="hljs-attr">build:</span><br>      <span class="hljs-attr">context:</span> <span class="hljs-string">./ruoyi/modules/system</span><br>    <span class="hljs-attr">ports:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;9201:9201&quot;</span><br>    <span class="hljs-attr">depends_on:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">ruoyi-redis</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">ruoyi-mysql</span><br>    <span class="hljs-attr">links:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">ruoyi-redis</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">ruoyi-mysql</span><br>  <span class="hljs-attr">ruoyi-modules-gen:</span><br>    <span class="hljs-attr">container_name:</span> <span class="hljs-string">ruoyi-modules-gen</span><br>    <span class="hljs-attr">build:</span><br>      <span class="hljs-attr">context:</span> <span class="hljs-string">./ruoyi/modules/gen</span><br>    <span class="hljs-attr">ports:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;9202:9202&quot;</span><br>    <span class="hljs-attr">depends_on:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">ruoyi-mysql</span><br>    <span class="hljs-attr">links:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">ruoyi-mysql</span><br>  <span class="hljs-attr">ruoyi-modules-job:</span><br>    <span class="hljs-attr">container_name:</span> <span class="hljs-string">ruoyi-modules-job</span><br>    <span class="hljs-attr">build:</span><br>      <span class="hljs-attr">context:</span> <span class="hljs-string">./ruoyi/modules/job</span><br>    <span class="hljs-attr">ports:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;9203:9203&quot;</span><br>    <span class="hljs-attr">depends_on:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">ruoyi-mysql</span><br>    <span class="hljs-attr">links:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">ruoyi-mysql</span><br>  <span class="hljs-attr">ruoyi-modules-file:</span><br>    <span class="hljs-attr">container_name:</span> <span class="hljs-string">ruoyi-modules-file</span><br>    <span class="hljs-attr">build:</span><br>      <span class="hljs-attr">context:</span> <span class="hljs-string">./ruoyi/modules/file</span><br>    <span class="hljs-attr">ports:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;9300:9300&quot;</span><br>    <span class="hljs-attr">volumes:</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-string">./ruoyi/uploadPath:/home/ruoyi/uploadPath</span><br>  <span class="hljs-attr">ruoyi-visual-monitor:</span><br>    <span class="hljs-attr">container_name:</span> <span class="hljs-string">ruoyi-visual-monitor</span><br>    <span class="hljs-attr">build:</span><br>      <span class="hljs-attr">context:</span> <span class="hljs-string">./ruoyi/visual/monitor</span><br>    <span class="hljs-attr">ports:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;9100:9100&quot;</span><br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Container</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Docker</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Docker实战</title>
    <link href="/2022/03/28/Container/Docker%E5%AE%9E%E6%88%98/"/>
    <url>/2022/03/28/Container/Docker%E5%AE%9E%E6%88%98/</url>
    
    <content type="html"><![CDATA[<h2 id="Nacos-amp-Seata"><a href="#Nacos-amp-Seata" class="headerlink" title="Nacos &amp; Seata"></a>Nacos &amp; Seata</h2><figure class="highlight bash"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></div></td><td class="code"><pre><code class="hljs Bash">docker run --name nacos-quick -v /Users/hanzhiguo/docker/nacos/logs:/home/nacos/logs -v /Users/hanzhiguo/docker/nacos/conf:/home/nacos/conf -e MODE=standalone -p 8848:8848 --privileged=<span class="hljs-literal">true</span> --restart=always -d nacos/nacos-server:2.0.0<br><br>docker run --name seata-server \<br>        -v /Users/hanzhiguo/docker/seata/logs:/seata-server/logs -v /Users/hanzhiguo/docker/seata/conf:/seata-server/resources \<br>        -p 8091:8091 \<br>        -e SEATA_IP=172.16.237.63 \<br>        -d seataio/seata-server:1.4.2<br></code></pre></td></tr></table></figure><h2 id="ElasticSearch-amp-Kibana"><a href="#ElasticSearch-amp-Kibana" class="headerlink" title="ElasticSearch &amp; Kibana"></a>ElasticSearch &amp; Kibana</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs Bash"><span class="hljs-comment"># 创建自定义的网络(用于连接到连接到同一网络的其他服务(例如Kibana))</span><br>docker network create somenetwork <br><br><span class="hljs-comment"># es 暴露的端口很多</span><br><span class="hljs-comment"># es 运行占用的内存超级大</span><br><span class="hljs-comment"># es 的数据一般需要放置到安全目录！挂载</span><br><span class="hljs-comment"># 启动 elasticsearch</span><br>docker run -d --name elasticsearch --net somenetwork -p 9200:9200 -p 9300:9300 -e <span class="hljs-string">&quot;discovery.type=single-node&quot;</span> elasticsearch<br><br><span class="hljs-comment"># 查看docker状态</span><br>docker stats<br><br><span class="hljs-comment"># 限制ES内存 修改配置文件 -e 环境配置修改</span><br>docker run -d --name elasticsearch --net somenetwork -p 9200:9200 -p 9300:9300 -v /Users/hanzhiguo/docker/elasticsearch/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml  -e <span class="hljs-string">&quot;discovery.type=single-node&quot;</span> -e ES\_JAVA\_OPTS=<span class="hljs-string">&quot;-Xms64M -Xmx512M&quot;</span> elasticsearch:6.4.3<br><br><span class="hljs-comment"># 运行 Kibana</span><br>docker run -d --name kibana --net somenetwork -p 5601:5601 kibana<br></code></pre></td></tr></table></figure><h2 id="Redis"><a href="#Redis" class="headerlink" title="Redis"></a>Redis</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs Bash">docker run \<br>-p 6379:6379 \<br>-v /Users/hanzhiguo/docker/redis/data:/data \<br>-v /Users/hanzhiguo/docker/redis/conf/redis.conf:/etc/redis/redis.conf \<br>--privileged=<span class="hljs-literal">true</span> \<br>--name myredis \<br>-d redis:5.0.9-alpine3.11 redis-server /etc/redis/redis.conf<br></code></pre></td></tr></table></figure><h2 id="loveaeen-x2F-Centos7"><a href="#loveaeen-x2F-Centos7" class="headerlink" title="loveaeen&#x2F;Centos7"></a>loveaeen&#x2F;Centos7</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs Bash"><span class="hljs-comment"># docker run</span><br>docker run -itd --privileged --hostname=master --name centos7-master loveaeen/centos-docker:1.0 /usr/sbin/init<br><br>docker run -itd --privileged --hostname=minio1 --name centos7-minio1 loveaeen/centos-docker:1.0 /usr/sbin/init<br><br>docker run -itd --privileged --hostname=minio2 --name centos7-minio2 loveaeen/centos-docker:1.0 /usr/sbin/init<br><br>docker run -itd --privileged --hostname=minio3 --name centos7-minio3 loveaeen/centos-docker:1.0 /usr/sbin/init<br><br><span class="hljs-comment"># modify hostname</span><br><span class="hljs-comment"># hostnamectl set-hostname master</span><br></code></pre></td></tr></table></figure><h2 id="Ubuntu-amp-Tomcat8-amp-JDK8"><a href="#Ubuntu-amp-Tomcat8-amp-JDK8" class="headerlink" title="Ubuntu &amp; Tomcat8 &amp; JDK8"></a>Ubuntu &amp; Tomcat8 &amp; JDK8</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs Bash"><span class="hljs-comment"># 创建dockerfile文件</span><br>FROM         ubuntu:14.10<br>MAINTAINER    linx<br><br><span class="hljs-comment"># 把java与tomcat添加到容器中</span><br>ADD jdk-8u261-linux-x64.tar.gz /usr/local/<br>ADD apache-tomcat-8.5.57.tar.gz /usr/local/<br><br><span class="hljs-comment"># 配置java与tomcat环境变量</span><br>ENV JAVA\_HOME /usr/local/jdk1.8.0\_261<br>ENV CLASSPATH <span class="hljs-variable">$JAVA</span>\_HOME/lib/dt.jar:<span class="hljs-variable">$JAVA</span>\_HOME/lib/tools.jar<br>ENV CATALINA\_HOME /usr/local/apache-tomcat-8.5.57<br>ENV CATALINA\_BASE /usr/local/apache-tomcat-8.5.57<br>ENV PATH <span class="hljs-variable">$PATH</span>:<span class="hljs-variable">$JAVA</span>\_HOME/bin:<span class="hljs-variable">$CATALINA</span>\_HOME/lib:<span class="hljs-variable">$CATALINA</span>\_HOME/bin<br><br><span class="hljs-comment"># 容器运行时监听的端口</span><br>EXPOSE  8080<br><br><span class="hljs-comment"># 使用dockerfile</span><br>docker build -t name .<br><br><span class="hljs-comment"># tomcat启动并挂载</span><br>docker run -i -t -p 8084:8080 -v /Users/hanzhiguo/docker/tomcat:/usr/local/apache-tomcat-8.5.57/webapps --name shys\_tomcat shys\_tomcat<br></code></pre></td></tr></table></figure><h2 id="Mysql"><a href="#Mysql" class="headerlink" title="Mysql"></a>Mysql</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs Bash">docker run --name mysql -p 3306:3306 -e MYSQL\_ROOT\_PASSWORD=root -d  mysql --lower\_case\_table\_names=1<br><br><span class="hljs-comment"># 若mysql版本为8以上。有些工具无法连接 需要修改用户密码的验证方式</span><br>ALTER USER <span class="hljs-string">&#x27;root&#x27;</span>@<span class="hljs-string">&#x27;localhost&#x27;</span> IDENTIFIED WITH mysql\_native\_password BY <span class="hljs-string">&#x27;yourpassword&#x27;</span><br></code></pre></td></tr></table></figure><h2 id="Prometheus-amp-Grafana监控Springboot-amp-Mysql"><a href="#Prometheus-amp-Grafana监控Springboot-amp-Mysql" class="headerlink" title="Prometheus &amp; Grafana监控Springboot &amp; Mysql"></a>Prometheus &amp; Grafana监控Springboot &amp; Mysql</h2><h3 id="1-需要在springboot项目中加入依赖"><a href="#1-需要在springboot项目中加入依赖" class="headerlink" title="1. 需要在springboot项目中加入依赖"></a>1. 需要在springboot项目中加入依赖</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs Bash">&amp;lt;!-- 为prometheus暴露采集端点 --&amp;gt;<br>        &amp;lt;dependency&amp;gt;<br>            &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;<br>            &amp;lt;artifactId&amp;gt;spring-boot-starter-actuator&amp;lt;/artifactId&amp;gt;<br>        &amp;lt;/dependency&amp;gt;<br><br>        &amp;lt;!-- prometheus支持 --&amp;gt;<br>        &amp;lt;dependency&amp;gt;<br>            &amp;lt;groupId&amp;gt;io.micrometer&amp;lt;/groupId&amp;gt;<br>            &amp;lt;artifactId&amp;gt;micrometer-registry-prometheus&amp;lt;/artifactId&amp;gt;<br>        &amp;lt;/dependency&amp;gt;<br></code></pre></td></tr></table></figure><h3 id="2-yml文件中开放地址"><a href="#2-yml文件中开放地址" class="headerlink" title="2. yml文件中开放地址"></a>2. yml文件中开放地址</h3><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs YAML"><span class="hljs-attr">management:</span><br>  <span class="hljs-attr">endpoints:</span><br>  <span class="hljs-attr">web:</span><br>    <span class="hljs-attr">exposure:</span><br>      <span class="hljs-attr">include:</span> <span class="hljs-string">&quot;*&quot;</span><br></code></pre></td></tr></table></figure><h3 id="3-创建一个prometheus-yml文件"><a href="#3-创建一个prometheus-yml文件" class="headerlink" title="3.创建一个prometheus.yml文件"></a>3.创建一个prometheus.yml文件</h3><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs YAML"><span class="hljs-comment"># 全局配置</span><br><span class="hljs-attr">lobal:</span><br> <span class="hljs-attr">scrape_interval:</span>     <span class="hljs-string">15s</span> <span class="hljs-comment"># 多久 收集 一次数据</span><br> <span class="hljs-attr">evaluation_interval:</span> <span class="hljs-string">15s</span> <span class="hljs-comment"># 多久评估一次 规则</span><br> <span class="hljs-attr">scrape_timeout:</span>      <span class="hljs-string">10s</span>   <span class="hljs-comment"># 每次 收集数据的 超时时间</span><br><br> <span class="hljs-string">监控预警配置.未启用</span><br><span class="hljs-attr">lerting:</span><br> <span class="hljs-attr">alertmanagers:</span><br> <span class="hljs-bullet">-</span> <span class="hljs-attr">static_configs:</span><br>   <span class="hljs-bullet">-</span> <span class="hljs-attr">targets:</span><br>     <span class="hljs-comment"># - alertmanager:9093</span><br><br> <span class="hljs-comment"># 规则文件, 可以使用通配符. 未启用</span><br><span class="hljs-attr">ule_files:</span><br> <span class="hljs-comment"># - &quot;first_rules.yml&quot;</span><br> <span class="hljs-comment"># - &quot;second_rules.yml&quot;</span><br><br> <span class="hljs-string">prometheus服务配置</span><br><span class="hljs-attr">crape_configs:</span><br> <span class="hljs-bullet">-</span> <span class="hljs-attr">job_name:</span> <span class="hljs-string">&#x27;prometheus&#x27;</span><br>   <span class="hljs-attr">static_configs:</span><br>   <span class="hljs-bullet">-</span> <span class="hljs-attr">targets:</span> [<span class="hljs-string">&#x27;localhost:9090&#x27;</span>]<br><br> <span class="hljs-string">SpringBoot应用配置</span><br> <span class="hljs-bullet">-</span> <span class="hljs-attr">job_name:</span> <span class="hljs-string">&#x27;SpringBootPrometheus&#x27;</span><br>   <span class="hljs-attr">scrape_interval:</span> <span class="hljs-string">5s</span><br>   <span class="hljs-attr">metrics_path:</span> <span class="hljs-string">&#x27;/actuator/prometheus&#x27;</span><br>   <span class="hljs-attr">static_configs:</span><br>     <span class="hljs-bullet">-</span> <span class="hljs-attr">targets:</span> [<span class="hljs-string">&#x27;192.168.1.145:81&#x27;</span>]<br><br> <span class="hljs-string">mysql配置</span><br> <span class="hljs-bullet">-</span> <span class="hljs-attr">job_name:</span> <span class="hljs-string">&#x27;mysql&#x27;</span><br>   <span class="hljs-attr">static_configs:</span><br>     <span class="hljs-bullet">-</span> <span class="hljs-attr">targets:</span> [<span class="hljs-string">&#x27;192.168.1.145:9104&#x27;</span>]<br></code></pre></td></tr></table></figure><h3 id="4-docker启动prometheus-通过配置文件挂载-及grafana"><a href="#4-docker启动prometheus-通过配置文件挂载-及grafana" class="headerlink" title="4.docker启动prometheus(通过配置文件挂载)及grafana"></a>4.docker启动prometheus(通过配置文件挂载)及grafana</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs Bash"><span class="hljs-comment"># 需要先创建一个配置文件。用于挂载</span><br>docker run  -d \<br>  -p 9090:9090 \<br>  --name prometheus \<br>  -v /Users/hanzhiguo/docker/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml  \<br>  prom/prometheus<br><br><span class="hljs-comment"># 启动Grafana</span><br>docker run -d \<br>  -p 3000:3000 \<br>  --name=grafana \<br>  -v /Users/hanzhiguo/docker/grafana-storage:/var/lib/grafana \<br>  grafana/grafana<br></code></pre></td></tr></table></figure><h3 id="5-安装mysql-exporter监控mysql"><a href="#5-安装mysql-exporter监控mysql" class="headerlink" title="5.安装mysql-exporter监控mysql"></a>5.安装mysql-exporter监控mysql</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs Bash"><span class="hljs-comment"># 创建一个监控账户</span><br>CREATE USER <span class="hljs-string">&#x27;exporter&#x27;</span>@<span class="hljs-string">&#x27;localhost&#x27;</span> IDENTIFIED BY <span class="hljs-string">&#x27;XXXXXXXX&#x27;</span> WITH MAX\_USER\_CONNECTIONS 10;<br>GRANT PROCESS, REPLICATION CLIENT, SELECT ON *.* TO <span class="hljs-string">&#x27;exporter&#x27;</span>@<span class="hljs-string">&#x27;localhost&#x27;</span>;<br><span class="hljs-comment"># 启动mysql-exporter</span><br>docker run -d \<br>  -p 9104:9104 \<br>  -e DATA\_SOURCE\_NAME=<span class="hljs-string">&quot;exporter:exporter@(192.168.1.145:3306)/&quot;</span> \<br>  prom/mysqld-exporter<br><br><span class="hljs-comment"># 结束后使用mrbird的mysql监控json</span><br></code></pre></td></tr></table></figure><h2 id="BackUp-amp-Transfer"><a href="#BackUp-amp-Transfer" class="headerlink" title="BackUp &amp; Transfer"></a>BackUp &amp; Transfer</h2><h3 id="BackUp"><a href="#BackUp" class="headerlink" title="BackUp"></a>BackUp</h3><ul><li>运行一个 Ubuntu 的容器，挂载mongo容器的所有 volume，映射宿主机的 backup 目录到容器里面的 &#x2F;backup 目录，然后运行 tar 命令将data目录下的所有文件打包到backup.tar中 <code>docker run --rm --volumes-from mongo -v d:/backup:/backup ubuntu tar cvf /backup/backup.tar /data/</code></li><li>这样宿主机的backup目录就有了mongo容器的备份压缩包了</li></ul><h3 id="Transfer"><a href="#Transfer" class="headerlink" title="Transfer"></a>Transfer</h3><ul><li>运行一个 ubuntu 容器，挂载 mongo 容器的所有 volumes，然后读取 &#x2F;backup 目录中的备份文件，解压到 &#x2F;data&#x2F; 目录 <code>docker run --rm --volumes-from mongo -v d:/backup:/backup ubuntu bash -c &quot;cd /data/ &amp;&amp; tar xvf /backup/backup.tar --strip 1&quot;</code></li><li>strip 1 表示解压时去掉前面1层目录，因为压缩时包含了绝对路径</li></ul><h2 id="Push-amp-Pull"><a href="#Push-amp-Pull" class="headerlink" title="Push &amp; Pull"></a>Push &amp; Pull</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs Bash"><span class="hljs-comment"># docker login your account</span><br><span class="hljs-comment"># input your loginname &amp; password</span><br>docker login<br><br><span class="hljs-comment"># tag the image</span><br>docker tag image:1.0 loveaee/image:1.0<br><br><span class="hljs-comment"># push your images to Docker Hub</span><br>docker push loveaee/image:1.0<br><br><span class="hljs-comment"># delete local image</span><br>docker rmi imageId<br><br><span class="hljs-comment"># pull image from docker hub</span><br>docker pull loveaee/image:1.0<br></code></pre></td></tr></table></figure><h2 id="Offline"><a href="#Offline" class="headerlink" title="Offline"></a>Offline</h2><p>在内网模式下，我们可以让Docker接入内网仓库harbor来管理所有的镜像文件。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs Bash">vim /etc/docker/daemon.json<br><br><span class="hljs-string">&quot;insecure-registries&quot;</span>: [<span class="hljs-string">&quot;172.17.0.3&quot;</span>]<br><br>systemctl restart docker<br></code></pre></td></tr></table></figure><p>也可以使用ftp的方式来使用离线版镜像。</p><figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs livecodeserver"><span class="hljs-comment"># save image to disk</span><br><span class="hljs-comment"># -o : Write to a file</span><br>docker save image -o image.tar<br><br><span class="hljs-comment"># load image from disk</span><br><span class="hljs-comment"># -i : Read from tar archive file</span><br>docker <span class="hljs-built_in">load</span> -i image.tar<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Container</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Docker</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Seata</title>
    <link href="/2022/03/28/Distributed%20System/Seata/"/>
    <url>/2022/03/28/Distributed%20System/Seata/</url>
    
    <content type="html"><![CDATA[<p>Seata 是一款开源的分布式事务解决方案，致力于提供高性能和简单易用的分布式事务服务. Seata 将为用户提供了 AT、TCC、SAGA 和 XA 事务模式，为用户打造一站式的分布式解决方案</p><p><strong>Seata 实现分布式事务，设计了一个关键角色 UNDO_LOG （回滚日志记录表），我们在每个应用分布式事务的业务库中创建这张表，这个表的核心作用就是，将业务数据在更新前后的数据镜像组织成回滚日志，备份在 UNDO_LOG 表中，以便业务异常能随时回滚。</strong></p><h2 id="Component"><a href="#Component" class="headerlink" title="Component"></a>Component</h2><p>Transaction Coordinator (TC)： 事务协调器，维护全局事务的运行状态，负责协调并驱动全局事务的提交或回滚；</p><p>Transaction Manager (TM)： 控制全局事务的边界，负责开启一个全局事务，并最终发起全局提交或全局回滚的决议；</p><p>Resource Manager (RM)： 控制分支事务，负责分支注册、状态汇报，并接收事务协调器的指令，驱动分支（本地）事务的提交和回滚。</p><p><strong>事务开启过程</strong></p><ul><li><p>TM 向 TC 申请开启一个全局事务，全局事务创建成功并生成一个全局唯一的 <code>XID</code>；</p></li><li><p><code>XID</code> 在微服务调用链路的上下文中传播；</p></li><li><p>RM 向 TC 注册分支事务，将其纳入 <code>XID</code> 对应全局事务的管辖；</p></li><li><p>TM 向 TC 发起针对 <code>XID</code> 的全局提交或回滚决议；</p></li><li><p>TC 调度 <code>XID</code> 下管辖的全部分支事务完成提交或回滚请求。</p></li></ul><h2 id="AT模式"><a href="#AT模式" class="headerlink" title="AT模式"></a><a href="https://seata.io/zh-cn/docs/dev/mode/at-mode.html">AT模式</a></h2><p>AT模式是一种无侵入的, 基于 2PC 的分布式事务解决方案，但他并不是完美的，为了解决事务的补偿与全局事务一致性的问题，它加入了before image与after image，并会插入undo log表中用于事务回滚，而且还有少不了的RPC同步通信。组件的额外加入必然增加了不少的开销，想一想每一个sql的执行都会有如此多的额外开销，项目的分布式事务性能必然会大幅度降低。业内也有一种思路，通过数据库binlog还原镜像前后的SQL，省去了undo log生成记录的同步，降低了性能损失，同时零业务入侵，个人觉得是更好的方法。</p><p>除开性能方面，AT模式在「全局事务」与「本地事务」之间会产生脏写和脏读问题，为此，我们需要使用<code>@GlobalLock</code>的方式，让「本地事务」也去竞争全局锁。但是该方式也牺牲了不少的性能。</p><p>但是我们不能否认AT模式是最常见也是相对优异的方案，阿里为了改善及解决AT模式的弊端问题，优化了二阶段时全局锁的持有，并让二阶段提交&#x2F;回滚采用了异步进行的方式。而且在保证一致性的方面，使用了更为高性能的Redis来解决，虽然这可能会因为Redis的非事务支持导致一致性的降低，但凡事没有完美，不是吗？</p><p><strong>一阶段</strong>：Seata 会拦截 “业务 SQL” ，首先解析 SQL 语义，找到 “业务 SQL” 要更新的业务数据，在业务数据被更新前，将其保存成 “before image”，然后执行 “业务 SQL” 更新业务数据，在业务数据更新之后，再将其保存成 “after image” ，提交前申请全局锁，再将业务数据的更新和前面步骤中生成的 UNDO LOG 一并进行本地提交。然后释放本地锁。</p><p>一阶段提交后，若有其他本地非分布式事务操作该条数据，则会发生脏写&#x2F;脏读问题。</p><p><img src="/image/Seata/v2-c2df76b462cd22fcc1b1435113e82e49_1440w.jpg" alt="img"></p><p><strong>二阶段提交</strong>: 因为“业务 SQL”在一阶段已经提交至数据库, 所以 Seata 框架只需异步将一阶段保存的快照数据和行锁删掉，完成数据清理并释放全局锁。</p><p><img src="/image/Seata/v2-75048a7c0f655654032213658742b7d5_1440w.jpg" alt="img"></p><p><strong>二阶段回滚</strong>：Seata 就需要回滚一阶段已经执行的“业务 SQL”，还原业务数据。回滚方式便是用 “before image” 还原业务数据. 但在还原前要首先要校验脏写, 对比 “数据库当前业务数据” 和 “after image”，如果两份数据完全一致就说明没有脏写，可以还原业务数据，如果不一致就说明有脏写，出现脏写就需要转人工处理。</p><p>二阶段回滚时，我们需要注意，此时该该分布式事务依然持有全局锁，但是缺少了本地锁，所以需要申请。假如在二阶段回滚前，有其他本地事务操作了该数据，则会发生脏写&#x2F;脏读问题。</p><p><img src="/image/Seata/v2-12a2fb645ded74b2ace2728d052a7bff_1440w.jpg" alt="img"></p><h2 id="TCC"><a href="#TCC" class="headerlink" title="TCC"></a>TCC</h2><p>关于原理我们在**[分布式事务]**一文中已经做过解答。在此类目下，我们是对于Seata下的TCC模式来做讨论。</p><p>在Seata中，不管是任何模式，我们都无法绕开TC，TM，RM三大组件。在AT模式中，我们详解了全局锁在其中充当的隔离性作用，而在TCC模式中，完全不需要全局锁的存在，而且性能相比AT模式更为优异。那我们如何保证数据的隔离性呢？核心就在于TCC接口的设计，用户在接入TCC模式时，大部分工作都集中如何实现TCC服务上。相对于普通的事务操作而言，在TCC的认知上我们需要懂得预留资源的概念。在Try接口中，我们需要对资源进行冻结保留。并在Confirm&#x2F;Cancel接口对该冻结资源做对应处理。Try接口的操作，其实就是预留资源的操作，我们在二阶段做的提交&#x2F;回滚操作，都是处理该资源。如果出现并发问题，这样每一个TCC模型都只操作属于自己的预留资源。</p><p>关于TCC模式，我们也不免的需要了解空回滚、防悬挂、幂等性的三个难题。归功于今日互联网的技术分享，我们可以很轻松的解决这三类难题，其中最普遍的做法就是增加一张本地事务控制表。</p><p><strong>空回滚：</strong>空回滚的意思就是因为网络等问题，Try接口没有接收到该事务信息，直接触发了回滚操作。为了解决该问题，我们可以在Try阶段时，往事务控制表中增加一条记录，表示第一阶段执行完毕，标记初始化状态。Cancel 接口里读取该记录，如果该记录存在，则正常回滚；如果该记录不存在，则是空回滚。</p><p><strong>防悬挂：</strong>防悬挂的意思是是 Try 由于网络拥堵而超时，Cancel 比 Try 接口先执行。我们可以在Cancel阶段时，先检查事务控制表是否存在记录，判断是不是空回滚了，如果没有相关记录，则往事务控制表中插入一条记录，标识已回滚状态，如果Try延时执行，那么检查事务控制表的内容，发现已经回滚，那么不执行任何操作</p><p><strong>幂等性：</strong>和上面两种方案一致，采用事务控制表的方式来解决，当出现二阶段重复执行时，检查表内分支事务的信息，如果存在了，则不做操作。</p><h2 id="Saga"><a href="#Saga" class="headerlink" title="Saga"></a><a href="http://seata.io/zh-cn/docs/user/saga.html">Saga</a></h2><p>Saga模式是一种长事务解决方案，在Saga模式中，业务流程中每个参与者都提交本地事务，当出现某一个参与者失败则补偿前面已经成功的参与者。他的性能很高，甚至在状态机定义时支持异步调用，但是缺点也很明显, 不保证 <strong>隔离性</strong>。事务会根据json配置的state来执行，如果前一个state的正向服务执行成功，那么就路由到下一个state并执行下一个state的正向服务，如果执行失败，那么基于CompensateState属性执行补偿服务。但是由于一阶段已经提交本地数据库事务，且没有进行”预留”动作，所以不能保证隔离性。</p><p>目前互联网中常用的解决隔离性的方案是在业务流程设计时遵循“宁可长款, 不可短款”的原则, <strong>长款意思是客户少了钱机构多了钱, 以机构信誉可以给客户退款, 反之则是短款, 少的钱可能追不回来了</strong>。所以在业务流程设计上一定是先扣款。有些业务场景可以允许让业务最终成功, 在回滚不了的情况下可以继续重试完成后面的流程, 所以状态机引擎除了提供“回滚”能力还需要提供“向前”恢复上下文继续执行的能力, 让业务最终执行成功, 达到最终一致性的目的。</p><h2 id="XA"><a href="#XA" class="headerlink" title="XA"></a><a href="http://seata.io/zh-cn/docs/dev/mode/xa-mode.html">XA</a></h2><p>XA模式是基于数据库的XA协议而来，他与AT模式相仿，但是他的锁机制更为严苛，并且不允许资源的重入。我了解的也很有限，因为在互联网公式中，该模式的使用率偏低。</p>]]></content>
    
    
    <categories>
      
      <category>Distributed System</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>分布式事务</title>
    <link href="/2022/03/28/Distributed%20System/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/"/>
    <url>/2022/03/28/Distributed%20System/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/</url>
    
    <content type="html"><![CDATA[<p>若对本地事务不甚了解的读者，请在了解分布式事务之前，先阅读这篇文章<a href="https://icyfenix.cn/architect-perspective/general-architecture/transaction/local.html">本地事务</a></p><p>当我们的项目庞大以后, 为了性能的优化, 我们首先需要拆分项目模块, 使之变成分布式项目. 数据库也要进行模块切割. 在传统的单体架构下, 我们只会在一个数据库中进行事务操作, 这种事务的控制非常简单. 但在分布式架构下，一个请求调用链可能会经过多个服务，操作多个数据库。这种情况下，事务被分散到了各个子系统中，分布式架构事务（下面简称分布式事务）问题显得尤为重要，特别是在金融电商领域，如果分布式事务没控制好，损失的就是是真金白银</p><p>数据库数据一致性的强度可以分为三种：</p><ul><li>强一致性：要求数据库中更新后的数据能立即对外可见；</li><li>弱一致性：能够容忍数据库中部分更新后的数据，对外不可见；</li><li>最终一致性：要求数据库中更新后的数据在一段时间后 (这个时间区间的长度主要受网络通信延迟, 系统负载等因素影响) 对外可见</li></ul><p><img src="/image/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/format,png-20220328161219693.png" alt="img"></p><h2 id="2PC"><a href="#2PC" class="headerlink" title="2PC"></a><a href="https://icyfenix.cn/architect-perspective/general-architecture/transaction/global.html">2PC</a></h2><p>2PC 是基于 <code>XA</code> 协议实现的分布式事务. <code>XA</code> 协议分为两个部分 : 事务管理器和本地资源管理器. 其中本地资源管理器通常由数据库实现, 比如 Oracle、Mysql. 而事务管理器则作为一个全局的调度者.</p><p>2PC 对业务侵入很小, 它最大的优势就是对使用方透明, 用户可以像使用本地事务一样使用基于 <code>XA</code> 协议的分布式事务，能够严格保障事务 ACID 特性</p><p>2PC 的缺点也很明显, 它是一个强一致性的同步阻塞协议，事务执⾏过程中需要将所需资源全部锁定，也就是俗称的 <code>刚性事务</code>。所以它比较适⽤于执⾏时间确定的短事务，整体性能比较差</p><p><strong>大致的流程 :</strong></p><p><img src="https://img-blog.csdnimg.cn/20201118174832330.png#pic_center" alt="img"></p><p>第一阶段（prepare）：事务管理器向所有本地资源管理器发起请求，询问是否是 ready 状态，所有参与者都将本事务能否成功的信息反馈发给协调者</p><p><img src="https://img-blog.csdnimg.cn/20201118174947450.png#pic_center" alt="img"></p><p>第二阶段 (commit&#x2F;rollback)：事务管理器根据所有本地资源管理器的反馈，通知所有本地资源管理器，步调一致地在所有分支上提交或者回滚。</p><p><strong>存在的问题 :</strong></p><ul><li>同步阻塞：当参与事务者存在占用公共资源的情况，其中一个占用了资源，其他事务参与者就只能阻塞等待资源释放，处于阻塞状态。</li><li>单点故障：一旦事务管理器出现故障，整个系统不可用</li><li>数据不一致：在阶段二，如果事务管理器只发送了部分 commit 消息，此时网络发生异常，那么只有部分参与者接收到 commit 消息，也就是说只有部分参与者提交了事务，使得系统数据不一致。</li><li>不确定性：当协事务管理器发送 commit 之后，并且此时只有一个参与者收到了 commit，那么当该参与者与事务管理器同时宕机之后，重新选举的事务管理器无法确定该条消息是否提交成功。</li></ul><h2 id="3PC"><a href="#3PC" class="headerlink" title="3PC"></a><a href="https://icyfenix.cn/architect-perspective/general-architecture/transaction/global.html#:~:text=%E4%B8%8D%E4%B8%80%E8%87%B4%E7%9A%84%E9%97%AE%E9%A2%98%E3%80%82-,%E4%B8%BA%E4%BA%86,-%E7%BC%93%E8%A7%A3%E4%B8%A4%E6%AE%B5%E5%BC%8F%E6%8F%90%E4%BA%A4"><strong>3PC</strong></a></h2><p>3PC 是 2PC 的一种改进版本, 为解决两阶段提交协议的<strong>阻塞问题</strong>, 上边提到两段提交, 当协调者崩溃时, 参与者不能做出最后的选择，就会一直保持阻塞锁定资源</p><p>2PC 中只有协调者有超时机制，3PC 在协调者和参与者中都引入了超时机制，协调者出现故障后，参与者就不会一直阻塞。</p><p>而且在第一阶段和第二阶段中又插入了一个准备阶段（如下图，看着有点啰嗦），保证了在最后提交阶段之前各参与节点的状态是一致的</p><p><img src="/image/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/20201119154252414.png" alt="img"></p><p>虽然 3PC 用超时机制，解决了协调者故障后参与者的阻塞问题，但与此同时却多了一次网络通信，性能上反而变得更差，也不太推荐。</p><h2 id="TCC"><a href="#TCC" class="headerlink" title="TCC"></a><a href="https://icyfenix.cn/architect-perspective/general-architecture/transaction/distributed.html#tcc-%E4%BA%8B%E5%8A%A1"><strong>TCC</strong></a></h2><p>TCC 也是一种两阶段提交协议，可以看作 2PC&#x2F;XA 的一种变种，但是不会长时间持有资源锁。虽然对代码侵入很大，但是性能非常优异。</p><p>关于 TCC（Try-Confirm-Cancel）的概念，最早是由 Pat Helland 于 2007 年发表的一篇名为《Life beyond Distributed Transactions:an Apostate’s Opinion》的论文提出。 TCC 事务机制相比于上面介绍的 XA，解决了其几个缺点：</p><ul><li>解决了协调者单点，由主业务方发起并完成这个业务活动。业务活动管理器也变成多点，引入集群。</li><li>同步阻塞：引入超时，超时后进行补偿，并且不会锁定整个资源，将资源转换为业务逻辑形式，粒度变小。</li><li>数据一致性，有了补偿机制之后，由业务活动管理器控制一致性</li></ul><p><strong>Try :</strong> 尝试执行，完成所有业务检查（一致性）, 预留必须业务资源（准隔离性），如冻结金额。</p><p><strong>Confirm :</strong> 确认执行真正执行业务，不作任何业务检查，只使用 Try 阶段预留的业务资源，Confirm 操作满足幂等性。要求具备幂等设计，Confirm 失败后需要进行重试。</p><p><strong>Cancel :</strong> 取消执行，释放 Try 阶段预留的业务资源 Cancel 操作满足幂等性 Cancel 阶段的异常和 Confirm 阶段异常处理方案基本上一致。</p><p>在 Try 阶段，是对业务系统进行检查及资源预览，比如订单和存储操作，需要检查库存剩余数量是否够用，并进行预留，预留操作的话就是新建一个可用库存数量字段，Try 阶段操作是对这个可用库存数量进行操作。</p><p>基于 TCC 实现分布式事务，会将原来只需要一个接口就可以实现的逻辑拆分为 Try、Confirm、Cancel 三个接口，所以代码实现复杂度相对较高。</p><h3 id="三个问题"><a href="#三个问题" class="headerlink" title="三个问题"></a>三个问题</h3><p><strong>空回滚</strong></p><ul><li>Cancel 接口设计时需要允许空回滚。在 Try 接口因为丢包时没有收到，事务管理器会触发回滚，这时会触发 Cancel 接口，这时 Cancel 执行时发现没有对应的事务 xid 或主键时，需要返回回滚成功。让事务服务管理器认为已回滚，否则会不断重试，而 Cancel 又没有对应的业务数据可以进行回滚</li></ul><p><strong>防悬挂</strong></p><ul><li>悬挂的意思是：Cancel 比 Try 接口先执行，出现的原因是 Try 由于网络拥堵而超时，事务管理器生成回滚，触发 Cancel 接口，而最终又收到了 Try 接口调用，但是 Cancel 比 Try 先到。按照前面允许空回滚的逻辑，回滚会返回成功，事务管理器认为事务已回滚成功，则此时的 Try 接口不应该执行，否则会产生数据不一致，所以我们在 Cancel 空回滚返回成功之前先记录该条事务 xid 或业务主键，标识这条记录已经回滚过，Try 接口先检查这条事务xid或业务主键如果已经标记为回滚成功过，则不执行 Try 的业务操作</li></ul><p><strong>幂等控制</strong></p><ul><li>幂等性的意思是：对同一个系统，使用同样的条件，一次请求和重复的多次请求对系统资源的影响是一致的。因为网络抖动或拥堵可能会超时，事务管理器会对资源进行重试操作，所以很可能一个业务操作会被重复调用，为了不因为重复调用而多次占用资源，需要对服务设计时进行幂等控制，通常我们可以用事务 xid 或业务主键判重来控制</li></ul><h2 id="最终一致性"><a href="#最终一致性" class="headerlink" title="最终一致性"></a>最终一致性</h2><p>消息对列+本地事务表+定时器的方式主要是用于最终一致性的场合，牺牲强一致性，提升性能</p><h3 id="消息队列事务"><a href="#消息队列事务" class="headerlink" title="消息队列事务"></a><a href="https://icyfenix.cn/architect-perspective/general-architecture/transaction/distributed.html#%E5%8F%AF%E9%9D%A0%E4%BA%8B%E4%BB%B6%E9%98%9F%E5%88%97">消息队列事务</a></h3><ul><li>基于消息中间件的 2PC 方案，通常用在高并发场景下使用，牺牲数据的强一致性换取性能的大幅提升，不过实现这种方式的成本和复杂度是比较高的，还要看实际业务情况</li><li>消息队列的方案无法非常优秀的解决下游事务失败后, 让上游进行数据回滚. 因为两者是完全解耦的, 复杂度太高. 推荐的做法是记录异常信息并进行人工处理</li></ul><p><img src="/image/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/362411093-5d882d3d41c8d_articlex.png" alt="img"></p><h3 id="本地消息表"><a href="#本地消息表" class="headerlink" title="本地消息表"></a><del>本地消息表</del></h3><p><font color='red'>如果你的消息队列不支持事务消息的情况下, 并且担心 Mq 会丢失消息的话. 可以使用该方案, 但是会额外占据数据库负载</font></p><ol><li>系统收到用户下单请求，将订单业务数据写入订单表中，同时把该订单对应的消息数据写入本地消息表中，订单表与本地消息表为同一个数据库，更新订单和存储消息为同一个本地事务，数据库事务处理，要么都成功，要么都失败。</li><li>订单服务发送消息到消息队列，库存服务收到消息，进行库存业务操作，更新库存数据</li><li>返回业务处理结果，订单服务收到结果后，将本地消息表中的数据设置完成状态或者删除数据。</li><li>另起定时任务，定时扫描本地消息表，看是否有未完成的任务，有则重试。</li></ol><p><img src="/image/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/ded2a136db5d41b781f5d1ec9e1fed83.png" alt="img"></p><h3 id="最大努力通知"><a href="#最大努力通知" class="headerlink" title="最大努力通知"></a><strong>最大努力通知</strong></h3><p><font color='gray'>第三方使用支付宝付款，支付宝成功后发送结果回调给第三方，这个结果就需要最大努力通知的机制来处理。</font></p><p>最大努力通知是最简单的一种柔性事务，适用于一些最终一致性时间敏感度低的业务，且被动方处理结果 不影响主动方的处理结果。</p><p>这个方案的大致意思就是：</p><ul><li>系统 A 本地事务执行完之后，发送个消息到 MQ；</li><li>这里会有个专门消费 MQ 的服务，这个服务会消费 MQ 并调用系统 B 的接口；</li><li>要是系统 B 执行成功就 ok 了；要是系统 B 执行失败了，那么最大努力通知服务就定时尝试重新调用系统 B, 反复 N 次，最后还是不行就放弃。</li></ul><h2 id="扩展延伸"><a href="#扩展延伸" class="headerlink" title="扩展延伸"></a>扩展延伸</h2><p><a href="/2022/03/28/Distributed%20System/Seata/">Seata</a></p>]]></content>
    
    
    <categories>
      
      <category>Distributed System</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>负载均衡策略</title>
    <link href="/2022/03/28/Distributed%20System/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%AD%96%E7%95%A5/"/>
    <url>/2022/03/28/Distributed%20System/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%AD%96%E7%95%A5/</url>
    
    <content type="html"><![CDATA[<h2 id="随机调用"><a href="#随机调用" class="headerlink" title="随机调用"></a>随机调用</h2><ul><li>顾名思义，就是全随机的，无法控制。</li></ul><h2 id="顺序轮询"><a href="#顺序轮询" class="headerlink" title="顺序轮询"></a>顺序轮询</h2><ul><li>获取到服务消费者列表后，按照顺序循环调用。</li></ul><h2 id="随机权重"><a href="#随机权重" class="headerlink" title="随机权重"></a>随机权重</h2><ul><li>可以对 provider 不同实例设置不同的权重，会按照权重来负载均衡，权重越大分配流量越高。</li><li>算法思想很简单。假设有一组服务器 servers &#x3D; [A, B, C]，他们对应的权重为 weights &#x3D; [5, 3, 2]，权重总和为 10。现在把这些权重值平铺在一维坐标值上，[0, 5) 区间属于服务器 A，[5, 8) 区间属于服务器 B，[8, 10) 区间属于服务器 C。接下来通过随机数生成器生成一个范围在 [0, 10) 之间的随机数，然后计算这个随机数会落到哪个区间上。比如数字 3 会落到服务器 A 对应的区间上，此时返回服务器 A 即可。权重越大的机器，在坐标轴上对应的区间范围就越大，因此随机数生成器生成的数字就会有更大的概率落到此区间内。只要随机数生成器产生的随机数分布性很好，在经过多次选择后，每个服务器被选中的次数比例接近其权重比例。比如，经过一万次选择后，服务器 A 被选中的次数大约为 5000 次，服务器 B 被选中的次数约为 3000 次，服务器 C 被选中的次数约为 2000 次。</li></ul><h2 id="轮询权重-加权轮询"><a href="#轮询权重-加权轮询" class="headerlink" title="轮询权重(加权轮询)"></a>轮询权重(加权轮询)</h2><ul><li>生成一个服务器序列，该序列中包含n个服务器。n是所有服务器的权重之和。在该序列中，每个服务器的出现的次数，等于其权重值。并且，生成的序列中，服务器的分布应该尽可能的均匀。比如序列{a, a, a, a, a, b, c}中，前五个请求都会分配给服务器a，这就是一种不均匀的分配方法，更好的序列应该是：{a, a, b, a, c, a, a}。</li></ul><h2 id="平滑加权轮询"><a href="#平滑加权轮询" class="headerlink" title="平滑加权轮询"></a>平滑加权轮询</h2><p><img src="/image/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%AD%96%E7%95%A5/iShot2021-09-03%2011.19.39.png" alt="img"></p><ul><li>以A举例，初始化为5</li><li><ol><li>当前权重默认值为每个服务器的权重值，每次请求获取最大的一个。</li></ol></li><li><ol><li>服务器请求结束后，将选择的服务器的权重改为权重&#x3D;当前权重-总权重和。5-5-1-1&#x3D;-2</li></ol></li><li><ol><li>在每次请求前，将他们的默认权重值加进当前权重值中。-2+5&#x3D;3</li></ol></li></ul><h2 id="最小活跃数"><a href="#最小活跃数" class="headerlink" title="最小活跃数"></a>最小活跃数</h2><ul><li>每个服务提供者会对应着一个活跃数 active。初始情况下，所有服务提供者的 active 均为 0。每当收到一个请求，对应的服务提供者的 active 会加 1，处理完请求后，active 会减 1。所以，如果服务提供者性能较好，处理请求的效率就越高，那么 active 也会下降的越快。因此可以给这样的服务提供者优先分配请求。</li><li>当然，除了最小活跃数，<code>LeastActiveLoadBalance</code> 在实现上还引入了权重值。所以准确的来说，<code>LeastActiveLoadBalance</code> 是基于加权最小活跃数算法实现的。</li></ul><h2 id="一致性HASH算法"><a href="#一致性HASH算法" class="headerlink" title="一致性HASH算法"></a>一致性HASH算法</h2><ul><li>一致性 Hash 算法，相同参数的请求一定分发到一个 provider 上去，provider 挂掉的时候，会基于虚拟节点均匀分配剩余的流量，抖动不会太大。如果你需要的不是随机负载均衡，是要一类请求都到一个节点，那就走这个一致性 Hash 策略。</li></ul>]]></content>
    
    
    <categories>
      
      <category>Distributed System</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>ConfigServer动态配置</title>
    <link href="/2022/03/28/Spring/ConfigServer%E5%8A%A8%E6%80%81%E9%85%8D%E7%BD%AE/"/>
    <url>/2022/03/28/Spring/ConfigServer%E5%8A%A8%E6%80%81%E9%85%8D%E7%BD%AE/</url>
    
    <content type="html"><![CDATA[<p>Spring Cloud Bus会向外提供一个http接口，即图中的&#x2F;bus&#x2F;refresh。我们将这个接口配置到远程的git的webhook上，当git上的文件内容发生变动时，就会自动调用&#x2F;bus-refresh接口。Bus就会通知config-server，config-server会发布更新消息到消息总线的消息队列中，其他服务订阅到该消息就会信息刷新，从而实现整个微服务进行自动刷新。</p><p><strong>配置中心承担配置刷新的职责</strong></p><p><img src="/image/ConfigServer%E5%8A%A8%E6%80%81%E9%85%8D%E7%BD%AE/28815AD5-AE1B-46D5-84DE-B3BD2A9B1862_2.jpeg" alt="Image"></p><ol><li>提交配置触发post调用客户端A的bus&#x2F;refresh接口</li><li>客户端A接收到请求从Server端更新配置并且发送给Spring Cloud Bus总线</li><li>Spring Cloud bus接到消息并通知给其它连接在总线上的客户端，所有总线上的客户端均能收到消息</li><li>其它客户端接收到通知，请求Server端获取最新配置</li><li>全部客户端均获取到最新的配置</li></ol>]]></content>
    
    
    <categories>
      
      <category>Spring Cloud</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Nacos注册与配置</title>
    <link href="/2022/03/28/Spring/Nacos%E6%B3%A8%E5%86%8C%E4%B8%8E%E9%85%8D%E7%BD%AE/"/>
    <url>/2022/03/28/Spring/Nacos%E6%B3%A8%E5%86%8C%E4%B8%8E%E9%85%8D%E7%BD%AE/</url>
    
    <content type="html"><![CDATA[<h2 id="注册"><a href="#注册" class="headerlink" title="注册"></a>注册</h2><p>Nacos - NacosNamingService初始化中提到NacosNamingService初始化会初始化EventDispatcher、NamingProxy、BeatReactor、HostReactor。其中EventDispatcher已经说了，NamingProxy的定时任务主要是默认每30毫秒更新服务器地址、默认每5毫秒登录获取token等信息</p><p>HostReactor的建立任务包括每5秒检测是否开启故障转移，若是开启，则把文件数据读入serviceMap、天天把服务信息写入本地、检测本地缓存文件，若是没有则建立缓存文件、监听UDP请求</p><p>在restTemplates &#x2F; feign采用服务名调用的时候, 进入<code>excute</code>的深层方法, 会走到<code>AbstractLoadBalancerRule</code>抽象类, nacos对他进行了实现, 并通过<code>HostReactor</code>获取所有的服务信息, 并进行负载均衡</p><h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><p>Nacos 服务端创建了相关的配置项后，客户端就可以进行监听了。客户端是通过一个定时任务来检查自己监听的配置项的数据的，<strong>一旦服务端的数据发生变化时，客户端将会获取到最新的数据</strong>，并将最新的数据保存在一个 CacheData 对象中，然后会重新计算 CacheData 的 md5 属性的值，此时就会对该 CacheData 所绑定的 Listener 触发 receiveConfigInfo 回调。</p><p>考虑到服务端故障的问题，客户端将最新数据获取后会保存在本地的 snapshot 文件中，以后会优先从文件中获取配置信息的值。</p><h3 id="那么客户端如何感知到数据发生变化的呢？"><a href="#那么客户端如何感知到数据发生变化的呢？" class="headerlink" title="那么客户端如何感知到数据发生变化的呢？"></a>那么客户端如何感知到数据发生变化的呢？</h3><p>我们知道客户端会有一个长轮训的任务去检查服务器端的配置是否发生了变化，如果发生了变更，那么客户端会拿到变更的 groupKey 再根据 groupKey 去获取配置项的最新值更新到本地的缓存以及文件中，那么这种每次都靠客户端去请求，那请求的时间间隔设置多少合适呢？</p><p><strong>长轮训的概念：</strong></p><p>客户端发起一个请求到服务端，服务端收到客户端的请求后，并不会立刻响应给客户端，而是先把这个请求hold住，然后服务端会在hold住的这段时间检查数据是否有更新，如果有，则响应给客户端，如果一直没有数据变更，则达到一定的时间（长轮训时间间隔）才返回。</p><p><img src="/image/Nacos%E6%B3%A8%E5%86%8C%E4%B8%8E%E9%85%8D%E7%BD%AE/2CF311CF-60DC-4520-82CA-75FBC68679E2_2.jpeg" alt="img"></p><p>timeout是在init这个方法中赋值的，默认情况下是30秒，可以通过configLongPollTimeout进行修改，但是源码中delayTime字段用于作为结束监听返回数据的时间间隔，所以等待的时间一般是略小于30秒。</p><p><img src="/image/Nacos%E6%B3%A8%E5%86%8C%E4%B8%8E%E9%85%8D%E7%BD%AE/B1C9C3BA-7663-4D94-A57C-E4ED013ED484_2.jpeg" alt="img"></p><p>ClientLongPolling 被提交给 scheduler 执行之后，实际执行的内容可以拆分成以下四个步骤：</p><ul><li>1.创建一个调度的任务，调度的延时时间为 29.5s</li><li>2.将该 ClientLongPolling 自身的实例添加到一个 allSubs 中去</li><li>3.延时时间到了之后，首先将该 ClientLongPolling 自身的实例从 allSubs 中移除</li><li>4.获取服务端中保存的对应客户端请求的 groupKeys 是否发生变更，将结果写入 response 返回给客户端</li></ul><p><strong>在过程中总共分两种情况，第一种在监听过程中发生变化，第二种就是超时之后执行检测后返回</strong></p>]]></content>
    
    
    <categories>
      
      <category>Spring Cloud</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Mysql</title>
    <link href="/2022/03/28/DataBase/Mysql/"/>
    <url>/2022/03/28/DataBase/Mysql/</url>
    
    <content type="html"><![CDATA[<p>Mysql是目前主流的数据库之一, 跟<strong>Oracle</strong>相比, 他更轻量, 并且互联网上关于对他的插件扩展也更多. 他的索引页, 数据页, 缓存页, 都是我们需要掌握并了解的. 当你掌握了这些知识以后, 你对Mysql性能调优会更有把握, 并且与人交谈时, 会显示你的资本积累无比深厚, 自然显得技术高强些. 当然, 光看文字也是不行的, 你也需要搭配一些图例来让脑海中的知识更加清晰化。</p><p>首先我们如果需要了解Mysql, 首当其冲的就是<strong>Buffer pool</strong>概念. 我们知道Mysql是将数据插入至磁盘的, 但是我们不能一直和磁盘打交道. 这样会让我们的读&#x2F;写速度都很慢. 所以Mysql会将一些数据放入到内存中, 优先和内存数据交互</p><h2 id="Buffer-pool"><a href="#Buffer-pool" class="headerlink" title="Buffer pool"></a>Buffer pool</h2><p>缓冲池默认是 <strong>128Mb</strong> , 存储的全都是<strong>数据页</strong><sup id="fnref:1" class="footnote-ref"><a href="#fn:1" rel="footnote"><span class="hint--top hint--rounded" aria-label="Mysql的数据虽然是一行一行的, 但是这些数据会最终存储在数据页里面. 当用户查询&#x2F;更新某一条数据时, 会将该数据的当前页以及相邻页全部放入到缓冲池里面.">[1]</span></a></sup>的信息. 数据页会存储在磁盘和缓存中. 但是如果存储在缓存的话, 我们一般称之为<strong>缓存页</strong>. 既然学习到数据页的概念, 那么我们也要简单看一下数据页长什么样子. 除了数据页本身, 缓冲池里面还会记录每一个数据页的<strong>描述信息</strong><sup id="fnref:2" class="footnote-ref"><a href="#fn:2" rel="footnote"><span class="hint--top hint--rounded" aria-label="描述信息是数据页所属的表空间, 数据页的编号, 在缓冲池中的地址以及一些额外信息. 描述文件大约占据缓冲池的5%容量. 比如你创建的是128Mb的缓冲池. 那么加上描述信息, 实际上在130+左右的大小. ">[2]</span></a></sup></p><p>缓冲池初始化时并不是空的, 它会默认用空缓存页填充自己. 类似于占位符一样的形式. 所以需要使用free链表来判断哪些缓存页是可以存入的.</p><p>那么如果某个缓存页被用户读取了之后, 用户修改了这个缓存页怎么办, 那不就跟磁盘数据不一致了吗? 于是乎, flush链表出现了.</p><p>缓存页可以让我们加速数据处理, 但缓冲池的空间是固定的, 以前旧的不常用的缓存页怎么删除, 腾出空间给新的缓存页呢? LRU链表</p><p>缓冲池是用户主要打交道的组件, 那么磁盘数据是如何放到缓冲池里面的呢? 数据页何时被缓存</p><p>既然我们有了这么多的链表结构, 那么会不会定时清理一些不用的缓存页呢? 定期清理缓存链表</p><h3 id="Free链表"><a href="#Free链表" class="headerlink" title="Free链表"></a>Free链表</h3><p>因为缓冲池里面缓存页都是占位形式, 所以我们不知道哪些缓存页是空闲状态. 于是Mysql增加了双向链表来判断. 首先当数据库初始化的时候, 缓存页全部都是空的, 那么这些缓存页的描述信息都会存入到链表里面来. 只要有缓存页需要被存入, 那么就会把链表里对应的描述信息删除.</p><h3 id="Flush链表"><a href="#Flush链表" class="headerlink" title="Flush链表"></a>Flush链表</h3><p>当用户修改了缓存页的信息时, 磁盘数据页并没有被刷新, 这时候就被称之为[脏页] 所以Mysql规定了, 如果当用户修改了缓存页信息, 则会把缓存页的描述信息块存放到flush链表里来. 后续是要被flush到磁盘里的</p><h3 id="LRU链表"><a href="#LRU链表" class="headerlink" title="LRU链表"></a>LRU链表</h3><p>为了在有限的空间内, 尽量让热点数据存储进来, 于是出现了LRU链表. 但是Mysql的LRU链表并不是我们认为的那种, 他是两部分链表, 分为[<strong>热数据</strong> , <strong>冷数据</strong>] [[LRU链表图]]. 当一个数据页被存入缓冲池中时, LRU链表就会将该条缓存页的描述信息加载到<strong>冷数据链表</strong>的头部.</p><blockquote><p> 那么什么时候<strong>冷数据</strong>会转移到<strong>热数据</strong>中呢?</p></blockquote><p>Mysql定义了一个配置<code>innodb_old_blocks_time</code> 默认值是1000 毫秒. 意思就是当一个数据页被加载到缓存页的1秒后, 你又一次对他进行了访问. 那么这条数据页就会被缓存到<strong>热数据</strong>链表的头部.</p><p>如果你访问的是<strong>热数据</strong>链表的数据, 那么根据规则, 如果你访问的区域是后3&#x2F;4的缓存页, 那么Mysql会将该缓存页移动至链表头部, 但是如果访问的是前1&#x2F;4区域的话. 这些数据页的位置是不动的</p><h3 id="数据页缓存时机"><a href="#数据页缓存时机" class="headerlink" title="数据页缓存时机"></a>数据页缓存时机</h3><p>当我们执行CRUD的时候, 首先会去缓冲池查数据所在的数据页是否被缓存了. 如果已经有了缓存, 那么我们直接就将缓存拿出来用. 如果数据页没被缓存, 那么我们就去free链表找到一个空闲的缓存页. 然后从磁盘上读取该数据页. 写入描述数据, 并从free链表中删删除这个描述数据块.</p><p>但是我们怎么能快速找到某个数据页是否被缓存了呢? 所以其实在数据库中, 维护了一个哈希表结构的数据. 里面是<strong>表空间号+数据页号</strong>为key, <strong>缓存页地址</strong>为value的这么一个表. 当用户需要使用某个数据页的时候. 通过该表进行查找, 就能快速定位到该数据页是否被缓存了.</p><h3 id="定期清理缓存"><a href="#定期清理缓存" class="headerlink" title="定期清理缓存"></a>定期清理缓存</h3><ol><li><p>定时将flush链表的缓存页都刷入到磁盘中, 解决[<strong>脏页</strong>]问题</p></li><li><p>定时将LRU链表中<strong>冷数据</strong>尾部的缓存页清除, 并增加free链表</p></li></ol><h2 id="TableSpace-amp-DataArea"><a href="#TableSpace-amp-DataArea" class="headerlink" title="TableSpace &amp; DataArea"></a>TableSpace &amp; DataArea</h2><p>当了解完了内存知识以后, 就该将目标转向磁盘了. 平时, 我们会在Mysql中创建一个表, 表本身有一个表空间的概念. 在磁盘中命名为<strong>表名.ibd</strong>文件.</p><p>而数据是存储在数据页中的, 但是数据页默认是16kb而已, 一个表空间有太多的16kb了, 特别不方便管理, 所以Mysql引入了<strong>数据区</strong>的概念.</p><p>一个数据区对应着连续的64个数据页, 每个数据页是16kb, 所以一个数据区正好是1mb. 然后256个数据区被称为<strong>组</strong></p><p>在每组数据区的第一个数据区的前三页, 里面存放的是<strong>描述性数据</strong></p><h2 id="RedoLog"><a href="#RedoLog" class="headerlink" title="RedoLog"></a>RedoLog</h2><p>RedoLog文件我们应该都有听说过. 其实就是事务记录文件, 但是他不是在事务提交时才会记录, 而是在数据修改时就会记录, 记录为 <strong>Prepare</strong> 状态，当用户提交时，更新状态为 <strong>Commit</strong>. Mysql默认会创建2个RedoLog文件, 事务记录会循环交替的在两个文件内写入覆盖. 如果想深入研究的话, 可以看一看RedoLog文件到底存储了什么样的修改信息.</p><p>虽然RedoLog是磁盘顺序写, 这样的写入速度很快, 但是还不够快! 我们依然要增加内存机制来提高它的写入速度!</p><ul><li><strong>RedoLog buffer</strong>会在Mysql启动时, 创建出来. <strong>默认[16mb]</strong> 类似于<strong>Buffer pool</strong> . 他会申请一片连续的内存空间, 里面划分出N多个空的RedoLog block<sup id="fnref:3" class="footnote-ref"><a href="#fn:3" rel="footnote"><span class="hint--top hint--rounded" aria-label="Mysql的数据存储在了数据页里面, 同样的, RedoLog日志信息也存储在了Block中. block大小为512byte. 分为三个部分head body trailer">[3]</span></a></sup></li></ul><p>那么内存中的RedoLog什么时候刷入磁盘呢?</p><ul><li>如果写入的RedoLog buffer日志已经占据总容量的一半了. 也就是大约8mb, 于是就会将日志刷入磁盘.</li><li>事务提交的时候, 会将他对应的RedoLog所在的RedoLog block刷入到磁盘中<sup id="fnref:4" class="footnote-ref"><a href="#fn:4" rel="footnote"><span class="hint--top hint--rounded" aria-label="因为存在OS cache的情况, 所以实际上并不是直接刷入到磁盘中, 而是从内存进入到OS cache里. 之后由操作系统进行文件写入. Mysql有参数可以直接将日志刷入磁盘, 不走OS cache">[4]</span></a></sup></li><li>定时线程每隔一秒会将block数据刷入磁盘</li><li>Mysql关闭时, 会将block数据刷入磁盘</li></ul><h2 id="UndoLog"><a href="#UndoLog" class="headerlink" title="UndoLog"></a>UndoLog</h2><p>中文意 [回滚日志] , 看名字就知道是专门用于事务提交失败或Mysql突然宕机时用于数据回滚的. 它记录的内容非常简单, 比如你insert了一条数据. 那么在日志里, 就会记录一条delete id的回滚数据. 所以当你执行事务期间, 你的DML语句不止会写入RedoLog, 也会写入UndoLog</p><p>而UndoLog还有其他的作用, 就是Mysql的最重要的隔离级别控制，这块内容容我稍后再说。</p><h2 id="BinLog"><a href="#BinLog" class="headerlink" title="BinLog"></a>BinLog</h2><p>BinLog不是默认开启的, 需要人为手动开启. 它记录了对Mysql执行<strong>提交后</strong>的所有操作. 但是相比RedoLog而言, 他记录的信息没有那么全面, 仅仅记录的对应的sql语句. 但是不要觉得只记录sql有什么不好, 正因为有BinLog我们才可以通过<strong>Canal</strong>来对数据库做监控与数据sql转发.</p><p>但是BinLog有一点不友好, 他的文件是不停增多的. 并不是循环覆盖的原则, 替我们省磁盘空间. 我们还需要设置Mysql的BinLog过期时间, 让Mysql帮我们删除旧文件</p><h2 id="MVCC"><a href="#MVCC" class="headerlink" title="MVCC"></a>MVCC</h2><p>简单的来说, 在Mysql中的每一行数据都是有三个隐藏字段的 <code>rowid</code> <code> trx_id</code>  <code>roll_pointer</code> <code>rowid</code>我们就不多说了, <code>trx_id</code>就是这条数据最近的一次事务id. <code>roll_pointer</code>则是指向了这次事务之前的UndoLog 接下来我们举个例子</p><h3 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h3><p>假如我们开启了事务A, 在这个事务里, 我们插入了一条数据, 这次事务的id为50, 此时版本链的隐藏字段为下图所示.</p><p><img src="/image/Mysql/imgs%252Fapp%252FRoamWeb%252Fw6_LOfove7.jpeg" alt="img"></p><p>接着事务B开启了, 他修改了这一条数据. 事务B的id为58, 那么版本链就产生了</p><p><img src="/image/Mysql/imgs%252Fapp%252FRoamWeb%252FtfTQCQAYPl.jpeg" alt="img"></p><p>接着又来了一个事务C, 他也耐不住寂寞, 也来改了一下这条数据</p><p><img src="/image/Mysql/imgs%252Fapp%252FRoamWeb%252FOJDLEbzw8d.jpeg" alt="img"></p><p>以上就是多版本控制的简述, 其实不难理解. 但是多版本控制只是一个辅助功能, 它主要是为了与<strong>ReadView读视图</strong>搭配, 用于管理隔离级别</p><h2 id="ReadView"><a href="#ReadView" class="headerlink" title="ReadView"></a>ReadView</h2><p>ReadView是Mysql对于控制隔离级别的一个重要概念, 简单来说, 就是你在执行一个事务的时候, 会生成一个ReadView. 里面比较关键的有四个部分</p><ul><li><code>m_ids</code> : 此时有哪些事务在Mysql执行还没有提交的</li><li><code>min_trx_id</code> : 就是m_ids里面最小的值</li><li><code>max_trx_id</code> : 就是Mysql下一个要生成的事务id, 就是最大的事务id</li><li><code>creator_trx_id</code> : 当前的事务id</li></ul><p>这四个部分在简单非并发查询时并没有太大的作用，他们存在的意义是解决并发查询时出现的隔离级别问题。</p><h3 id="Example-1"><a href="#Example-1" class="headerlink" title="Example"></a>Example</h3><blockquote><p>并发事务查询, 大致分为下列三种情况, 我们给出一个前提条件. 查询的事务A(id&#x3D;45) | 并发更新的事务B(id&#x3D;59) | 操作的数据(trx_id &#x3D; 32)</p></blockquote><ol><li><p>数据的<code>trx_id</code>小于当前执行事务id</p><p>当事务A查询数据的时候, 他会判断一下, 看一下这条数据的trx_id是否小于ReadView中的min_trx_id. 判断后发现是小于的. 那么直接就可以查询这条数据的信息, 不用去找版本链了</p></li><li><p>数据的<code>trx_id</code>大于当前执行事务id</p><p>在上面的事务A查询完后, 事务B修改了这条数据, 数据的<code>trx_id</code>变成了59. 然后事务A又进行了一次查询. 他会发现数据的trx_id是大于min_trx_id, 同时小于max_trx_id. 这时候他就明白了, 有并发事务修改了这条数据. 然后看一下m_ids是否存在这条数据的trx_id, 果然存在! 那么我们就不能查询这条数据的当前信息了. 只能通过版本链回滚查询到小于等于自己事务id的数据信息</p></li><li><p>数据的<code>trx_id</code>等于当前执行事务id</p><p>这条没啥好说的, 数据的事务id都跟自己的事务id一样了, 还要判断啥呢, 肯定是自己改的啊. 直接查!</p></li></ol><h3 id="RC"><a href="#RC" class="headerlink" title="RC"></a>RC</h3><p>当设置了RC隔离级别时, 每一次的查询都会生成一个ReadView. 如果数据的<code>trx_id</code>在m_ids中的话, 就不允许被读取, 必须去版本链找≤自己事务id的数据出来. 如果反之的话, 那就直接读取该条数据.</p><h3 id="RR"><a href="#RR" class="headerlink" title="RR"></a>RR</h3><p>与RC不一样的是, 一个事务只会开启一次ReadView. 所以这就会导致, 事务内后续的查询时, 其他的并发事务已经提交了, 但是ReadView中的m_ids还是保存了这些并发事务信息, 于是就只能去找版本链的数据.</p><h2 id="Data-Page"><a href="#Data-Page" class="headerlink" title="Data Page"></a>Data Page</h2><p>我们知道, 一行一行的数据是存储在<strong>数据页</strong>中的 ,索引也是存储在数据页中. 每一个数据页都会有他自己的页目录. 我们也知道, InnoDB 引擎默认是必须存在主键的, 这也就保证了每张表都会存在主键索引, 既然有了索引, 那么所有的数据都需要按照主键顺序排列, 如果主键是中英文混杂的话, 我们还需要对他做转换, 保证可以比较大小. 所以中英文主键的查询速度是会比纯数字的速度较慢一些.</p><p>那么如果是按照顺序的话, 我先增加了一条id为10的数据, 我又增加了一条id为2的数据. 实际上会怎么存储呢? 于是Mysql页分裂<sup id="fnref:5" class="footnote-ref"><a href="#fn:5" rel="footnote"><span class="hint--top hint--rounded" aria-label="页分裂的概念是当存在后一个数据页的部分数据主键比前一个数据页中的主键小时, Mysql会自动帮你调整主键大小, 他会保证这两个数据页中的主键值一定是按照从小到大的顺序排列">[5]</span></a></sup>出现了, 他能帮我们解决主键顺序问题.</p><p>既然我们知道了数据页的一些简单概念, 那么Mysql是如何查询的呢?</p><ul><li><p>单数据页查询</p><p>假如我们查询的一张表中, 压根没多少数据, 也就一个数据页的大小. 那么Mysql就会直接到数据页的页目录中根据主键进行二分查找. 快速定位到主键的槽位, 然后遍历槽位的每一行数据, 找到主键对应的数据为止. 因为一个槽位可能存储了一组数据, 所以需要在槽位里遍历查找.</p></li><li><p>多数据页查询</p><p>如果是多数据页的话，我们需要一个新知识来帮我们快速定位到指定的数据页中，然后才能用单数据页的方式来查询，稍后我再来说索引页相关内容。</p></li></ul><h3 id="Page-directory"><a href="#Page-directory" class="headerlink" title="Page directory"></a>Page directory</h3><p><a href="https://blog.csdn.net/jy02268879/article/details/105652206">深入研究Mysql页结构</a></p><p>现在我们了解了记录在页中按照主键值由小到大顺序串联成一个单链表，那如果我们想根据主键值查找页中的某条记录该咋办呢？</p><p>设计InnoDB的大叔们为我们的记录也制作了一个类似的目录，他们的制作过程是这样的：</p><ul><li>将所有正常的记录（包括最大和最小记录，不包括标记为已删除的记录）划分为几个组。</li><li>每个组的最后一条记录（也就是组内最大的那条记录）的头信息中的n_owned属性表示该记录拥有多少条记录，也就是该组内共有几条记录</li><li>将每个组的最后一条记录的地址偏移量单独提取出来，用作查找。</li></ul><p>注意：这个页目录是为主键服务的。</p><p><img src="/image/Mysql/format,png.png" alt="img"></p><p>对于最小记录所在的分组只能有 1 条记录，最大记录所在的分组拥有的记录条数只能在 1-8 条之间，剩下的分组中记录的条数范围只能在是 4-8 条之间。</p><p>分组是按照下边的步骤进行：</p><ul><li>初始情况下一个数据页里只有最小记录和最大记录两条记录，它们分属于两个分组。</li><li>之后每插入一条记录，都会从页目录中找到主键值比本记录的主键值大并且差值最小的槽，然后把该槽对应的记录的n_owned值加1，表示本组内又添加了一条记录，直到该组中的记录数等于8个。</li><li>在一个组中的记录数等于8个后再插入一条记录时，会将组中的记录拆分成两个组，一个组中4条记录，另一个5条记录。这个过程会在页目录中新增一个槽来记录这个新增分组中最大的那条记录的偏移量。</li></ul><p>我们再添加12条记录看看效果：</p><p><img src="/image/Mysql/format,png-20220328150555793.png" alt="img"></p><p>因为把16条记录的全部信息都画在一张图里太占地方，让人眼花缭乱的，所以只保留了用户记录头信息中的n_owned和next_record属性。</p><p>因为各个槽代表的记录的主键值都是从小到大排序的，所以我们可以使用所谓的二分法来进行快速查找。</p><p>所以在一个数据页中查找指定主键值的记录的过程分为两步：</p><ul><li>通过二分法确定该记录所在的槽，并找到该槽所在分组中主键值最大的那条记录。</li><li>通过记录的next_record属性遍历该槽所在的组中的各个记录。</li></ul><p>比方说我们想找主键值为6的记录，过程是这样的：</p><p>计算中间槽的位置：(0+4)&#x2F;2&#x3D;2，所以查看槽2对应记录的主键值为8，又因为8 &gt; 6，所以设置high&#x3D;2，low保持不变。</p><p>重新计算中间槽的位置：(0+2)&#x2F;2&#x3D;1，所以查看槽1对应的主键值为4，又因为4 &lt; 6，所以设置low&#x3D;1，high保持不变。</p><p>因为high - low的值为1，所以确定主键值为6的记录在槽2对应的组中。</p><p>我们可以很轻易的拿到槽1对应的记录（主键值为4），该条记录的下一条记录就是槽2中主键值最小的记录，该记录的主键值为5。所以我们可以从这条主键值为5的记录出发，遍历槽2中的各条记录</p><p>注意：若查到数据在槽2的分组中，由于槽2是指向最后一个记录，所以需要向上找一个槽位，定位到上一个槽位最后一行，然后再向下找。</p><h2 id="Index-Page"><a href="#Index-Page" class="headerlink" title="Index Page"></a>Index Page</h2><p>索引页也又称**[主键目录]. <strong>简单来说就是如果一张表数据很大的话, 那么自然会有很多的数据页出现. 因为你的索引也是存储在里面的, 所以会出现</strong>索引页**. 而索引页中存储的就是多个数据页中最小的主键id与数据页号.</p><p><font color='red'>B+树中的非叶子节点存储的是索引页，索引页里面存储的是下方非叶子节点的索引页最小ID，在最底层的非叶子节点的索引页里面存储的是数据页的最小主键id，而叶子节点存储的就是数据页信息。</font></p><p><img src="/image/Mysql/iShot2022-02-17%2015.14.10.png" alt="img"></p><p>但是如果数据真的比较庞大, 索引页出来很多呢? 我们怎么快速定位到我们想要的索引页? 于是一个全新的概念产生了索引B+树</p><p>对于 InnoDB 来说，所有的数据都是以键值对的方式存储的，主键索引和辅助索引在存储数据时会将 id 和 index 作为键，将所有列和 id 作为键对应的值. 在 B+ 树中, 所有的非叶子节点都是存储的索引值, 只有叶子节点才会存储数据.</p><ul><li>但是因为辅助索引存储的是 id 的原因, 所以需要二次回表查询.</li></ul><p>一个 B+ 树构建出来以后, 我们以主键索引为例. 当我们查询数据时, 首先就会从 B+ 数的顶层开始二分查找, 一直找到我们需要的叶子节点, 叶子节点存储的不是实际的数据, 而是<strong>数据页</strong>. 所以我们需要再通过数据页知识来结束查询。</p><h3 id="Union-Index"><a href="#Union-Index" class="headerlink" title="Union Index"></a>Union Index</h3><p>在这里我们单独将「联合索引」的结构拿出来记录，网络上对于该存储结构有两种不同的观点论述。</p><p>其一是索引树的非叶子节点上存储的是最左侧列的值，通过该值进行后续的依次查找。</p><p><font color='red'>其二是索引树的非叶子节点上存储的是所有列的值，然后根据各个值进行依次查找。</font></p><p>经过查找与阅读书籍，我更倾向于多列组合存储的方式。其实不管如何存储，本质上查找数据都是需要一项项的查找，这也就出现了我们熟知的「最左匹配」问题。</p><p>我们可以将联合索引想像成电话簿，通过最左匹配的「姓」，我们可以很快速的找到后续的「中间字+末尾字」。但是如果没有最左项，我们肯定只能扫描全部项进行全表查询。</p><p>若我们的条件只有「姓+末尾字」，缺少了「中间字」，那么我们根据原则，只能用到复合索引中的「姓」索引，无法继续采用后续的索引。</p><h2 id="Master-amp-Slave"><a href="#Master-amp-Slave" class="headerlink" title="Master &amp; Slave"></a>Master &amp; Slave</h2><p>因为以我目前接触的项目体重, 使用到 Mysql 集群的可能性微乎其微, 所以在这里只是简单记录一下. 当我们创建了集群时, Mysql 集群并不会保证高可用. 这需要我们自己通过第三方插件实现. 比如<strong>MHA</strong>. 他会部署一台 Manager 节点, 然后在每一台 Mysql 服务器上部署 Node 节点. 如果某个 Master 节点宕机, 那么他就会将 Slave 提升上去.</p><p>但是高可用也有个缺点. 如果你的某个服务器变成了主节点, 那么 java 项目如果动态更改主库地址呢? 需要研究一下这个问题</p><h3 id="Mode"><a href="#Mode" class="headerlink" title="Mode"></a>Mode</h3><p><strong>普通日志复制(5.6 before)：</strong>MySQL最早支持的复制技术，BUG相对较少，对SQL查询没什么限制，故障处理比较弱容易，但是在主节点挂掉，由从节点选举后可能会造成信息丢失问题</p><p><strong>GTID全局事务ID复制(5.6 after)：</strong>很方便的支持高可用，但是不支持非事务引擎，不支持 <code>sql_slave_skip_counter</code> (一般用这个来跳过基于binlog主从复制出现的问题)。也不支持<code>create table … select</code> 以及 <code>create temporary table</code></p><h3 id="Principle"><a href="#Principle" class="headerlink" title="Principle"></a>Principle</h3><p>主库将变更写入 binlog 日志，然后从库连接到主库之后，从库有一个 IO 线程，将主库的 binlog 日志拷贝到自己本地，写入一个 relay 中继日志中。接着从库中有一个 SQL 线程会从中继日志读取 binlog，然后执行 binlog 日志中的内容，也就是在自己本地再次执行一遍 SQL，这样就可以保证自己跟主库的数据是一样的.</p><p>这里有一个非常重要的一点，就是从库同步主库数据的过程是串行化的，也就是说主库上并行的操作，在从库上会串行执行。所以这就是一个非常重要的点了，由于从库从主库拷贝日志以及串行执行 SQL 的特点，在高并发场景下，从库的数据一定会比主库慢一些，是<strong>有延时</strong>的. 所以经常出现，刚写入主库的数据可能是读不到的，要过几十毫秒，甚至几百毫秒才能读取到</p><ul><li><p><strong>同步复制：</strong>最没用的复制方式</p><p>指当主库执行完一个事务，所有的从库都执行了该事务才返回给客户端。因为需要等待所有从库执行完该事务才能返回，所以全同步复制的性能必然会收到严重的影响。</p></li><li><p><strong>异步复制(默认)：</strong>提供了主从方案，降低了单节点运行数据库的风险</p><p>主库执行完事务后立即响应客户端，不理会从库是否接收到自己的信息。这个方式可靠性很差，容易丢失数据，但是响应速度很快。如果主服务器崩溃，它已提交的事务可能不会传输到任何从服务器。因此，在这种情况下，从主服务器故障转移到从服务器可能会导致故障转移到缺少与主服务器相关的事务的服务器。异步复制提供了较低的写入延迟，因为写入在写入从属之前由主机本地确认。它非常适合读取扩展，因为添加更多副本不会影响复制延迟。异步复制的良好用例包括为读取扩展部署只读副本、用于灾难恢复和分析&#x2F;报告的实时备份副本。</p></li><li><p><strong>增强半同步复制(优化)：</strong>异步主从复制的加强，解决了数据丢失的风险，但是依然存在网络延迟，切换麻烦的问题(例如10个节点，1主9从，主节点宕机，当把一个从节点提升为主节点后，其它节点需要手动修改master)</p><p>也叫 <code>semi-sync</code> 复制，指的就是主库写入 binlog 日志之后，就会将<strong>强制</strong>此时立即将数据同步到从库，从库将日志写入自己本地的 relay log 之后，接着会返回一个 ack 给主库，主库接收到<strong>至少一个从库</strong>的 ack 之后才会认为写操作完成了。要启用半同步复制，需要额外的插件安装步骤，并且必须在指定的 MySQL master 和 slave 上启用。</p></li><li><p><strong>组复制(MGR)：</strong>拥有了自动故障转移failover的能力，当主节点发生故障(单主模式才需考虑)时，组内部会自动选择主节点。</p><p>是一种主从复制的<strong>高可用</strong>技术，分为<strong>单主模式</strong>和<strong>多主模式</strong>。与上述复制不同的是，所有读写事务仅在获得组批准后才提交。</p></li></ul><h3 id="Parallel"><a href="#Parallel" class="headerlink" title="Parallel"></a>Parallel</h3><p>主备延迟的主要原因在于，master A 上产生 binlog 的速度大于slave B 处理 binlog 的速度。数据的积压就在于 <code>sql_thread</code> 处理的速度. 为了要减少延迟, 我找到了以下几种方式</p><ol><li><p>并行复制</p><p>Mysql 5.6版本只支持 schema 级别的并行复制. 也就是主库有两个 schema 分别是 jiedu , wlry. 从库也是这两个, 那么进行数据同步时, 最小级别也是 schema 级别. 不会提升单库多表的速度</p><p>Mysql 5.7 版本支持了<strong>基于组提交的并行复制</strong>. 说起来比较复杂, 就是跟全局事务 ID 有关. 但是这种复制方式支持到了表级别.更适合单库多表!</p><p>Mysql 8.0 版本支持 WriteSet 复制方式.</p></li><li><p>主从库拆分. 将写压力进行分散. 提高从库的执行速度</p></li><li><p>通过 ShardingSphere 来控制插入数据之后, 查询主库数据, 而不走从库查询. 直接不让用户感知到任何延迟.</p></li></ol><h3 id="High-Availability"><a href="#High-Availability" class="headerlink" title="High Availability"></a>High Availability</h3><h4 id="MHA"><a href="#MHA" class="headerlink" title="MHA"></a>MHA</h4><p><strong>MHA</strong>由两部分组成：<strong>MHA Manager</strong>（管理节点）和<strong>MHA Node</strong>（数据节点）。MHA Manager可以单独部署在一台独立的机器上管理多个master-slave集群，也可以部署在一台slave节点上，生产环境中多数单独部署。 MHA Node运行在每个MySQL服务器上，MHA Manager会定时探测集群中的master节点，当master出现故障时，它可以自动将判断最新数据的slave提升为新的master，并将所有其他的slave重新指向新的master。但是需要注意MHA是不会管Slave是否宕机的，如果Slave宕机，应用程序依然会错误的向其发起请求。</p><p>在一个Master node CRASH时，MHA 负责Master-Slave Auto-failover，默认情况下，MySQL复制是异步的。MHA试图从宕机的主服务器上保存二进制日志，通过ssh补齐日志，所以需要root用户，同时负载启停VIP. 如果主服务器崩溃，则它已提交的事务可能尚未传输到任何从服务器。因此，在这种情况下从主服务器到从服务器的故障转移可能导致事务丢失，所以通常还需要使用半同步替代异步，与半同步复制相结合，可以降低由于主硬件故障导致数据丢失的风险。</p><p><a href="https://juejin.cn/post/6844904099075325960#heading-10">简单搭建请点击这里🔗</a></p><p>生产环境中最常用的还是采用MHA方案，并且网络上有使用master_ip_failover_script脚本创建Zookeeper节点的方式，再由Java监听后让ShardingSphere动态切换主库的高可用方案，但是没找到具体实现，而且这套架构无法实现检测从库是否正常，所以我们可以再引入HAProxy组件，对所有slave节点进行负载均衡。</p><h4 id="MGR"><a href="#MGR" class="headerlink" title="MGR"></a>MGR</h4><p>MGR是Mysql内置的高可用组件，需要Mysql开启GTID方案才能使用。这个方式是Oracle公司推荐的，并且可以与ShardingSphere相结合实现动态转移 (目前只支持单主模式)。</p><h4 id="HAProxy"><a href="#HAProxy" class="headerlink" title="HAProxy"></a>HAProxy</h4><p>HAProxy 代表 High Availability Proxy，是一款出色的基于软件的 TCP&#x2F;HTTP 负载均衡器。 它在一组服务器之间分配工作负载，以最大限度地提高性能并优化资源使用。 HAProxy 使用复杂且可定制的健康检查方法构建，允许在单个运行实例中实现多个服务的负载平衡。</p><p>HAProxy通过配置文件中可以配置Mysql、Tcp、Http三种检测方式，若某个节点异常，HAProxy将忽略该节点的负载均衡。</p><p>但是HAProxy本身是单点的，我们为了解决单点故障的问题，可以加入Keepalived等组件解决这个问题。</p><p><a href="https://blog.csdn.net/qq_34556414/article/details/105143584">HAProxy的简易单主多从实现</a></p><h4 id="Mycat"><a href="#Mycat" class="headerlink" title="Mycat"></a>Mycat</h4><p>看了一下Mycat官方文档，对于MGR、MHA等都有非常好的兼容模式，可以实现动态数据源更改，但是使用似乎不太广泛。</p><hr><section class="footnotes"><div class="footnote-list"><ol><li><span id="fn:1" class="footnote-text"><span>Mysql的数据虽然是一行一行的, 但是这些数据会最终存储在数据页里面. 当用户查询&#x2F;更新某一条数据时, 会将该数据的当前页以及相邻页全部放入到缓冲池里面.<a href="#fnref:1" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:2" class="footnote-text"><span>描述信息是数据页所属的表空间, 数据页的编号, 在缓冲池中的地址以及一些额外信息. 描述文件大约占据缓冲池的5%容量. 比如你创建的是128Mb的缓冲池. 那么加上描述信息, 实际上在130+左右的大小.<a href="#fnref:2" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:3" class="footnote-text"><span>Mysql的数据存储在了数据页里面, 同样的, RedoLog日志信息也存储在了Block中. block大小为512byte. 分为三个部分head body trailer<a href="#fnref:3" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:4" class="footnote-text"><span>因为存在OS cache的情况, 所以实际上并不是直接刷入到磁盘中, 而是从内存进入到OS cache里. 之后由操作系统进行文件写入. Mysql有参数可以直接将日志刷入磁盘, 不走OS cache<a href="#fnref:4" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:5" class="footnote-text"><span>页分裂的概念是当存在后一个数据页的部分数据主键比前一个数据页中的主键小时, Mysql会自动帮你调整主键大小, 他会保证这两个数据页中的主键值一定是按照从小到大的顺序排列<a href="#fnref:5" rev="footnote" class="footnote-backref"> ↩</a></span></span></li></ol></div></section>]]></content>
    
    
    <categories>
      
      <category>DataBase</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>SSO单点登录</title>
    <link href="/2022/03/28/Distributed%20System/SSO%E5%8D%95%E7%82%B9%E7%99%BB%E5%BD%95/"/>
    <url>/2022/03/28/Distributed%20System/SSO%E5%8D%95%E7%82%B9%E7%99%BB%E5%BD%95/</url>
    
    <content type="html"><![CDATA[<h2 id="同域名方式"><a href="#同域名方式" class="headerlink" title="同域名方式"></a>同域名方式</h2><ol><li><p><strong>使用共享Cookie来解决Token共享问题。</strong></p><p>所谓共享Cookie，就是Cookie设置为顶域名，然后就可以在二级域名下的共享，举个例子：写在父域名stp.com下的Cookie，<a href="http://在s1.stp.com/">在s1.stp.com</a>、s2.stp.com等子域名都是可以共享访问的。</p></li><li><p><strong>使用Redis来解决Session共享问题。</strong></p><p>Cookie的问题解决了，我们再来看看session的问题。我们在sso系统登录了，这时再访问app1，Cookie也带到了app1的服务端（Server），app1的服务端怎么找到这个Cookie对应的Session呢？这里就要把 3 个系统的Session共享，采用Redis来实现。</p></li></ol><h3 id="Shiro-Session模式"><a href="#Shiro-Session模式" class="headerlink" title="Shiro Session模式"></a>Shiro Session模式</h3><p>Shiro标准模式是基于Session来做的，SessionID存储在Cookie里。也就意味着如果我们多个系统都采用Shiro框架认证。</p><p>那么当我们删除了Redis的Session后，所有系统都会全部注销。</p><h3 id="Sa-Token"><a href="#Sa-Token" class="headerlink" title="Sa-Token"></a>Sa-Token</h3><p>用户登录成功，会创建多个Session对象（其实就是Map集合之类的）存储到Redis里面，再返回浏览器一个Token标识，后续请求服务器检验该Cookie中的Token。</p><p>该Token里面存储了用户信息，是否登录等。</p><p>用户访问其他系统时，网关拦截校验Cookie中的Token是否正确，是否登录，然后再交由后续登录方法给用户加权限信息。</p><p>当用户点击某系统的注销后，先删除Cookie，再删除Redis里的Session信息。</p><h3 id="JWT"><a href="#JWT" class="headerlink" title="JWT"></a>JWT</h3><p>JWT存入到Cookie里面，A系统首先登录，然后JWT存入到顶级域名的Cookie里面，B系统网关拦截后，重定向到SSO服务器，服务器获取Cookie是否存在并验证，成功后返回给B系统。</p><h2 id="不同域的CAS方式"><a href="#不同域的CAS方式" class="headerlink" title="不同域的CAS方式"></a>不同域的CAS方式</h2><blockquote><p>Spring Security有与<a href="https://github.com/apereo/cas">CAS</a>集成的便捷写法, 研发者只需要配置地址, 不需要关心如何统一认证.</p></blockquote><p>CAS （Central Authentication Service）中央认证服务</p><ol><li><p>A系统登录并重定向SSO 首先，用户想要访问系统A <a href="http://www.java3y.com受限的资源(比如说购物车功能，购物车功能需要登录后才能访问)，系统Awww.java3y.com发现用户并没有登录，于是重定向到sso认证中心，并将自己的地址作为参数。请求的地址如下：">www.java3y.com受限的资源(比如说购物车功能，购物车功能需要登录后才能访问)，系统Awww.java3y.com发现用户并没有登录，于是重定向到sso认证中心，并将自己的地址作为参数。请求的地址如下：</a></p><p><a href="http://www.sso.com/?service=www.java3y.com">http://www.sso.com?service=www.java3y.com</a></p></li><li><p>SSO进行认证并设置SSO域的Token，并重定向给A系统 sso认证中心发现用户未登录，将用户引导至登录页面，用户进行输入用户名和密码进行登录，用户与认证中心建立全局会话（生成一份Token，写到Cookie中，保存在浏览器上）</p><p>随后，认证中心重定向回系统A，并把Token携带过去给系统A，重定向的地址如下：</p><p><a href="http://www.java3y.com/?token=xxxxxxx">http://www.java3y.com?token=xxxxxxx</a></p></li><li><p>A系统携带Token去SSO验证，并确认登录 接着，系统A去sso认证中心验证这个Token是否正确，如果正确，则系统A和用户建立局部会话（创建Session）。到此，系统A和用户已经是登录状态了。</p></li><li><p>用户登录B系统，重定向到SSO，SSO检测Cookie里是否存在Token并验证 此时，用户想要访问系统B<a href="http://www.java4y.com受限的资源(比如说订单功能,订单功能需要登录后才能访问),系统b/">www.java4y.com受限的资源(比如说订单功能，订单功能需要登录后才能访问)，系统B</a> <a href="http://www.java4y.com发现用户并没有登录，于是重定向到sso认证中心，并将自己的地址作为参数。请求的地址如下：">www.java4y.com发现用户并没有登录，于是重定向到sso认证中心，并将自己的地址作为参数。请求的地址如下：</a></p><p><a href="http://www.sso.com/?service=www.java4y.com">http://www.sso.com?service=www.java4y.com</a></p></li><li><p>SSO发现用户已登录，将Token重定向B系统 注意，因为之前用户与认证中心<a href="http://www.sso.com已经建立了全局会话(当时已经把cookie保存到浏览器上了),所以这次系统b重定向到认证中心www.sso.com是可以带上cookie的./">www.sso.com已经建立了全局会话（当时已经把Cookie保存到浏览器上了），所以这次系统B重定向到认证中心www.sso.com是可以带上Cookie的。</a> 认证中心根据带过来的Cookie发现已经与用户建立了全局会话了，认证中心重定向回系统B，并把Token携带过去给系统B，重定向的地址如下：</p><p><a href="http://www.java4y.com/?token=xxxxxxx">http://www.java4y.com?token=xxxxxxx</a></p></li><li><p>B系统携带Token去SSO验证，并确认登录 接着，系统B去sso认证中心验证这个Token是否正确，如果正确，则系统B和用户建立局部会话（创建Session）。到此，系统B和用户已经是登录状态了。</p></li></ol><h3 id="票据模式"><a href="#票据模式" class="headerlink" title="票据模式"></a>票据模式</h3><p>在CAS标准中，用户登录认证的操作如下。</p><ol><li>用户访问A系统，重定向SSO，并携带当前系统地址。</li><li>SSO进行登录，并生成 key &#x3D; CASTGC, value &#x3D; ${TGC}的Cookie，以及key &#x3D; ${TGC}, value &#x3D; ${TGT}的Session。</li><li>SSO分发ST给A系统，A系统携带ST去SSO验证，验证通过，A系统正常登录。</li><li>用户访问B系统，重定向SSO</li><li>SSO发现Cookie中有CASTGC的Cookie，获取到TGC的值去Session查找TGT是否存在，找到的话就说明登录过了。</li><li>SSO分发ST给B系统，B系统携带ST去SSO验证，验证通过，B系统正常登录。</li></ol><h3 id="一次注销，全端下线"><a href="#一次注销，全端下线" class="headerlink" title="一次注销，全端下线"></a>一次注销，全端下线</h3><p>SSO在被重定向过来时，将业务系统的项目地址存入到用户相关的Set集合里。</p><p>当某个系统点击注销按钮，将该请求发送至SSO中，让SSO遍历Set集合对地址后追加注销字符串，进行逐一下线操作，然后再注销SSO。</p><h3 id="本地服务"><a href="#本地服务" class="headerlink" title="本地服务"></a>本地服务</h3><h4 id="认证"><a href="#认证" class="headerlink" title="认证"></a>认证</h4><ol><li>用户访问&#x2F;business&#x2F;index , 因为没登录, 被配置的<code>authenticationEntryPoint</code>发送SSO登录请求重定向至&#x2F;sso&#x2F;code?redirectUrl</li><li>SSO服务的默认未认证拦截器拦截到该请求, 重定向至SSO登录页面.</li><li>用户登录成功后, 交由研发人员实现SSO服务中的successHandler类进行处理, <code>authenticationDetailsSource.buildDetails(request)</code>设置details信息到Authentication里面, 记录日志等, 并根据savedRequest重定向到业务的index 或者 SSO的index</li><li>再次访问&#x2F;business&#x2F;index , 还是因为没登录, 被配置的<code>authenticationEntryPoint</code>发送SSO登录请求重定向至&#x2F;sso&#x2F;code?redirectUrl</li><li>这一次SSO通过已经存在的session发现认证了, 不再拦截, 进入code方法, 查询具体的客户端信息, 根据session中的用户信息与查询的客户端信息存入map, key&#x3D;code, value&#x3D;authentication, 再根据redirectUrl返回重定向至业务的post登录请求(&#x2F;ssoLogin)</li><li>这一次请求地址是&#x2F;ssoLogin, 该地址是子类构造器中定义的, 所以被<code>AbstractAuthenticationProcessingFilter</code>过滤器匹配到. 根据code参数, new一个Authentication, 并authenticationDetailsSource.buildDetails(request)设置details信息到Authentication里面, 并创建一个当前session并传入. 检查code参数是否存在, 不存在就重新去获取code, 存在就进入自定义认证逻辑<code>SsoAuthenticationProvider</code></li><li>该认证方法中进行远程调用&#x2F;sso&#x2F;verify方法, 通过code参数从map中删除该key并获取authentication对象, 然后返回user信息对象, 里面包含SSO的sessionid, 将他也放入authentication对象里面, 然后返回authentication <strong>在这一步中, 如果项目之间允许共享Redis, 则不需要将用户信息通过http的方式同步</strong></li><li>进入业务的登录成功successHandler类进行处理,将SSO的sessionid与当前业务的sessionid绑定放入域中, 获取savedRequest并重定向</li></ol><h4 id="登出"><a href="#登出" class="headerlink" title="登出"></a>登出</h4><ol><li>用户调用当前业务的登出方法, 该方法重定向到SSO登出方法</li><li>SSO登出方法根据配置好的所有业务模块信息, 循环获取所有的登出地址, 传入SSO的sessionId并进行调用</li><li>每一个业务登出方法处理都需要根据SSO的sessionid找到当前业务的sessionId, 然后注销.</li></ol>]]></content>
    
    
    <categories>
      
      <category>Distributed System</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Oauth2</title>
    <link href="/2022/03/28/Distributed%20System/Oauth2/"/>
    <url>/2022/03/28/Distributed%20System/Oauth2/</url>
    
    <content type="html"><![CDATA[<h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><hr><p>简单说，OAuth 就是一种授权机制。数据的所有者告诉系统，同意授权第三方应用进入系统，获取这些数据。系统从而产生一个短期的进入令牌（token），用来代替密码，供第三方应用使用。</p><p>令牌（token）与密码（password）的作用是一样的，都可以进入系统，但是有三点差异。</p><ol><li>令牌是短期的，到期会自动失效，用户自己无法修改。密码一般长期有效，用户不修改，就不会发生变化。</li><li>令牌可以被数据所有者撤销，会立即失效。</li><li>令牌有权限范围（scope），对于网络服务来说，只读令牌就比读写令牌更安全。密码一般是完整权限。</li></ol><h2 id="角色"><a href="#角色" class="headerlink" title="角色"></a>角色</h2><hr><ul><li>Resource owner (资源拥有者) ：拥有该资源的最终用户，他有访问资源的账号密码（微信用户）</li><li>Resource server (资源服务器) ：拥有受保护资源的服务器，如果请求包含正确的访问令牌，可以访问资源（微信服务器）</li><li>Client (客户端) ：访问资源的客户端，会使用访问令牌去获取资源服务器的资源，可以是浏览器、移动设备或者服务器（戒毒网站）</li><li>Authentication server (认证服务器) ：用于认证用户的服务器，如果客户端认证通过，发放访问资源服务器的令牌（微信认证服务）</li></ul><h2 id="授权模式"><a href="#授权模式" class="headerlink" title="授权模式"></a>授权模式</h2><h3 id="授权码"><a href="#授权码" class="headerlink" title="授权码"></a>授权码</h3><p>授权码（authorization code）方式，指的是第三方应用先申请一个授权码，然后再用该码获取令牌。这种方式是最常用的流程，安全性也最高，它适用于那些有后端的 Web 应用。</p><ol><li>A 网站提供一个链接，用户点击后就会跳转到 B 网站，授权用户数据给 A 网站使用。下面就是 A 网站跳转 B 网站的一个示意链接。 <em><strong>在这一步请求时, 如果检测到scope参数, 一般会弹出具体的授权页面, 用户确定授权才会往下走, 这也是为什么需要authorize, 而不是直接请求token的原因</strong></em></li></ol><figure class="highlight java"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></div></td><td class="code"><pre><code class="hljs Java"><span class="hljs-comment">// response_type参数表示要求返回授权码（code）</span><br><span class="hljs-comment">// client_id参数让 B 知道是谁在请求, 一个应用一个id</span><br><span class="hljs-comment">// redirect_uri参数是 B 接受或拒绝请求后的跳转网址</span><br><br>**<span class="hljs-comment">// scope：参数表示要求的授权范围（这里是只读）, 也可以不传</span><br><span class="hljs-comment">// scope：如果传了, 服务端需要检查去数据库该应用的scope是否与之吻合, 不符合直接返回错误信息</span><br><span class="hljs-comment">// scope：如果不传, 则表示静默授权, 不返回任何权限scope, 只表明登录了, 所以也不能获取任何信息, 当然你也可以去查询该用户的所有scope, 后续返回给他**</span><br>**<span class="hljs-comment">// secret：一开始不传是因为后面有重定向，重定向是可感知的，有可能被其他网站拿到**</span><br>https:<span class="hljs-comment">//b.com/oauth/authorize?</span><br>  response_type=code&amp;<br>  client_id=CLIENT_ID&amp;<br>  redirect_uri=CALLBACK_URL&amp;<br>  scope=read<br></code></pre></td></tr></table></figure><ol><li>用户跳转后，B 网站会要求用户登录，然后询问是否同意给予 A 网站授权。用户表示同意，这时 B 网站就会跳回redirect_uri参数指定的网址。跳转时，会传回一个授权码，就像下面这样。</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs Java"><span class="hljs-comment">// code参数就是授权码, 需要设置过期时间, 可以放在redis里面</span><br><span class="hljs-comment">// 正常使用一次以后, 就要被销毁, 不允许第二次使用</span><br>https:<span class="hljs-comment">//a.com/callback?code=AUTHORIZATION_CODE</span><br></code></pre></td></tr></table></figure><ol><li>A 网站拿到授权码以后，就可以在后端，向 B 网站请求令牌。</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs Java">**<span class="hljs-comment">// client_id参数让 B 知道是谁在请求, 一个应用一个id</span><br><span class="hljs-comment">// client_secret参数用来让B确认A的身份, 是应用的保密秘钥, 可以让服务器分发一个加密秘钥, 然后服务器有解密的算法**</span><br><br>**<span class="hljs-comment">// 有些应用在让第三方请求时, 会有一个前置接口, 让第三方公司输入应用名称等信息, 然后返回给client_id和client_secret**</span><br>**<span class="hljs-comment">// 如果是自己的应用, 那么自己约定好这两个信息, 让客户端及服务端都能知晓就可以了**</span><br><br><span class="hljs-comment">// grant_type参数的值是AUTHORIZATION_CODE, 表示采用的授权方式是授权码</span><br><span class="hljs-comment">// code参数是上一步拿到的授权码</span><br><span class="hljs-comment">// redirect_uri参数是令牌颁发后的回调网址</span><br>https:<span class="hljs-comment">//b.com/oauth/token?</span><br> client_id=CLIENT_ID&amp;<br> client_secret=CLIENT_SECRET&amp;<br> grant_type=authorization_code&amp;<br> code=AUTHORIZATION_CODE&amp;<br> redirect_uri=CALLBACK_URL<br></code></pre></td></tr></table></figure><ol><li>B 网站收到请求以后，就会颁发令牌。具体做法是向redirect_uri指定的网址，发送一段 JSON 数据。</li></ol><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs JSON"><span class="hljs-punctuation">&#123;</span>    <br>  <span class="hljs-attr">&quot;access_token&quot;</span><span class="hljs-punctuation">:</span><span class="hljs-string">&quot;ONWVJzfOv1XidEdeBAdqPxYGL60toIzhzHRwp1ySPHMEKWFbp5FIp3FuaQ3g&quot;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;token_type&quot;</span><span class="hljs-punctuation">:</span><span class="hljs-string">&quot;bearer&quot;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;expires_in&quot;</span><span class="hljs-punctuation">:</span><span class="hljs-number">2592000</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;refresh_token&quot;</span><span class="hljs-punctuation">:</span><span class="hljs-string">&quot;REFRESH_TOKEN&quot;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;scope&quot;</span><span class="hljs-punctuation">:</span><span class="hljs-string">&quot;read&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-comment">// Set集合</span><br>  <span class="hljs-attr">&quot;uid&quot;</span><span class="hljs-punctuation">:</span><span class="hljs-number">100101</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;info&quot;</span><span class="hljs-punctuation">:</span><span class="hljs-punctuation">&#123;</span>...<span class="hljs-punctuation">&#125;</span><br><span class="hljs-punctuation">&#125;</span><br><span class="hljs-comment">// 或者</span><br><span class="hljs-punctuation">&#123;</span><br>  <span class="hljs-attr">&quot;access_token&quot;</span><span class="hljs-punctuation">:</span><span class="hljs-string">&quot;ONWVJzfOv1XidEdeBAdqPxYGL60toIzhzHRwp1ySPHMEKWFbp5FIp3FuaQ3g&quot;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;refresh_token&quot;</span><span class="hljs-punctuation">:</span><span class="hljs-string">&quot;SshGOiUl4w9UIePixwQzvXjlnddMi52xgviM8S4RPm26m1bBgJInpSXC4AND&quot;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;expires_in&quot;</span><span class="hljs-punctuation">:</span><span class="hljs-number">7199</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;refresh_expires_in&quot;</span><span class="hljs-punctuation">:</span><span class="hljs-number">2591999</span><span class="hljs-punctuation">,</span> <span class="hljs-comment">// 刷新令牌的失效时间</span><br>  <span class="hljs-attr">&quot;client_id&quot;</span><span class="hljs-punctuation">:</span><span class="hljs-number">1001</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;uid&quot;</span><span class="hljs-punctuation">:</span><span class="hljs-number">10001</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;scope&quot;</span><span class="hljs-punctuation">:</span><span class="hljs-string">&quot;&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-comment">// Set集合</span><br>  <span class="hljs-attr">&quot;openid&quot;</span><span class="hljs-punctuation">:</span><span class="hljs-string">&quot;gr_SwoIN0MC1ewxHX_vfCW3BothWDZMMtx__&quot;</span> <span class="hljs-comment">// JWT</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><h4 id="答疑"><a href="#答疑" class="headerlink" title="答疑"></a>答疑</h4><ul><li><strong>会不会有其他应用冒充第三方应用骗取授权？</strong> ClientID 代表一个第三方应用的“用户名”，这项信息是可以完全公开的。但 ClientSecret 应当只有应用自己才知道，这个代表了第三方应用的“密码”。在第 5 步发放令牌时，调用者必须能够提供 ClientSecret 才能成功完成。只要第三方应用妥善保管好 ClientSecret，就没有人能够冒充它。</li><li><strong>为什么要先发放授权码，再用授权码换令牌？</strong> 这是因为客户端转向（通常就是一次 HTTP 302 重定向）对于用户是可见的，换而言之，授权码可能会暴露给用户以及用户机器上的其他程序，但由于用户并没有 ClientSecret，光有授权码也是无法换取到令牌的，所以避免了令牌在传输转向过程中被泄漏的风险。</li><li><strong>为什么要设计一个时限较长的刷新令牌和时限较短的访问令牌？不能直接把访问令牌的时间调长吗？</strong> 这是为了缓解 OAuth2 在实际应用中的一个主要缺陷，通常访问令牌一旦发放，除非超过了令牌中的有效期，否则很难（需要付出较大代价）有其他方式让它失效，所以访问令牌的时效性一般设计的比较短，譬如几个小时，如果还需要继续用，那就定期用刷新令牌去更新，授权服务器就可以在更新过程中决定是否还要继续给予授权。</li></ul><h3 id="密码式"><a href="#密码式" class="headerlink" title="密码式"></a>密码式</h3><p>如果你高度信任某个应用，<strong>RFC 6749</strong> 也允许用户把用户名和密码，直接告诉该应用。该应用就使用你的密码，申请令牌，这种方式称为”密码式”（password）。</p><ol><li>A 网站要求用户提供 B 网站的用户名和密码。拿到以后，A 就直接向 B 请求令牌。</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs Java"><span class="hljs-comment">// client_id参数让 B 知道是谁在请求, 一个应用一个id</span><br><span class="hljs-comment">// client_secret参数用来让B确认A的身份, 是应用的保密秘钥, 自己配一个</span><br><span class="hljs-comment">// grant_type参数的值是password, 表示采用的授权方式是密码式</span><br><span class="hljs-comment">// username和password是 B 的用户名和密码。</span><br>https:<span class="hljs-comment">//oauth.b.com/oauth/token?</span><br>  grant_type=password&amp;<br>  username=USERNAME&amp;<br>  password=PASSWORD&amp;<br>  client_secret=CLIENT_SECRET&amp;<br>  client_id=CLIENT_ID&amp;<br>  scope=scope<br></code></pre></td></tr></table></figure><ol><li>B 网站验证身份通过后，直接给出令牌。注意，这时不需要跳转，而是把令牌放在 JSON 数据里面，作为 HTTP 回应，A 因此拿到令牌。</li></ol><p>这种方式需要用户给出自己的用户名&#x2F;密码，显然风险很大，因此只适用于其他授权方式都无法采用的情况，而且必须是用户高度信任的应用。</p><h3 id="隐藏式"><a href="#隐藏式" class="headerlink" title="隐藏式"></a><strong>隐藏式</strong></h3><p>有些 Web 应用是纯前端应用，没有后端。这时就不能用上面的方式了，必须将令牌储存在前端。**RFC 6749 **就规定了第二种方式，允许直接向前端颁发令牌。这种方式没有授权码这个中间步骤，所以称为（授权码）”隐藏式”（implicit）。</p><ol><li>A 网站提供一个链接，要求用户跳转到 B 网站，授权用户数据给 A 网站使用。</li></ol><figure class="highlight http"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs Http">https://b.com/oauth/authorize?<br>  response_type=token&amp;<br>  client_id=CLIENT_ID&amp;<br>  redirect_uri=CALLBACK_URL&amp;<br>  scope=read<br>上面 URL 中，`response_type`参数为`token`，表示要求直接返回令牌。<br></code></pre></td></tr></table></figure><ol><li>用户跳转到 B 网站，登录后同意给予 A 网站授权。这时，B 网站就会跳回redirect_uri参数指定的跳转网址，并且把令牌作为 URL 参数，传给 A 网站。</li></ol><figure class="highlight http"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs Http">https://a.com/callback#token=ACCESS_TOKEN<br>上面 URL 中，`token`参数就是令牌，A 网站因此直接在前端拿到令牌。<br></code></pre></td></tr></table></figure><h3 id="凭证式"><a href="#凭证式" class="headerlink" title="凭证式"></a><strong>凭证式</strong></h3><p>最后一种方式是凭证式（client credentials），适用于没有前端的命令行应用，即在命令行下请求令牌。</p><ol><li>A 应用在命令行向 B 发出请求。</li></ol><figure class="highlight http"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs Http">https://oauth.b.com/token?<br>  grant_type=client_credentials&amp;<br>  client_id=CLIENT_ID&amp;<br>  client_secret=CLIENT_SECRET<br>上面 URL 中，`grant_type`参数等于`client_credentials`表示采用凭证式，`client_id`和`client_secret`用来让 B 确认 A 的身份。<br></code></pre></td></tr></table></figure><ol><li><p>B 网站验证通过以后，直接返回令牌。</p><p>这种方式给出的令牌，是针对第三方应用的，而不是针对用户的，即有可能多个用户共享同一个令牌。</p></li></ol><h2 id="令牌的使用"><a href="#令牌的使用" class="headerlink" title="令牌的使用"></a>令牌的使用</h2><hr><p>A 网站拿到令牌以后，就可以向 B 网站的 API 请求数据了。</p><p>此时，每个发到 API 的请求，都必须带有令牌。具体做法是在请求的头信息，加上一个Authorization字段，令牌就放在这个字段里面。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs Bash">curl -H <span class="hljs-string">&quot;Authorization: Bearer ACCESS_TOKEN&quot;</span> \<br><span class="hljs-string">&quot;https://api.b.com&quot;</span><br></code></pre></td></tr></table></figure><p>上面命令中，ACCESS_TOKEN就是拿到的令牌。</p><h2 id="更新令牌"><a href="#更新令牌" class="headerlink" title="更新令牌"></a>更新令牌</h2><hr><p>令牌的有效期到了，如果让用户重新走一遍上面的流程，再申请一个新的令牌，很可能体验不好，而且也没有必要。OAuth 2.0 允许用户自动更新令牌。</p><p>具体方法是，B 网站颁发令牌的时候，一次性颁发两个令牌，一个用于获取数据，另一个用于获取新的令牌（refresh token 字段）。令牌到期前，用户使用 refresh token 发一个请求，去更新令牌。</p><p>B 网站验证通过以后，就会颁发新的令牌。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs Java"><span class="hljs-comment">// grant_type参数为refresh_token表示要求更新令牌</span><br><span class="hljs-comment">// client_id参数和client_secret参数用于确认身份</span><br><span class="hljs-comment">// refresh_token参数就是用于更新令牌的令牌。</span><br>https:<span class="hljs-comment">//b.com/oauth/token?</span><br>  grant_type=refresh_token&amp;<br>  client_id=CLIENT_ID&amp;<br>  client_secret=CLIENT_SECRET&amp;<br>  refresh_token=REFRESH_TOKEN<br></code></pre></td></tr></table></figure><h2 id="第三方登录原理"><a href="#第三方登录原理" class="headerlink" title="第三方登录原理"></a>第三方登录原理</h2><hr><p>所谓第三方登录，实质就是 OAuth 授权。用户想要登录 A 网站，A 网站让用户提供第三方网站的数据，证明自己的身份。获取第三方网站的身份数据，就需要 OAuth 授权。</p><p>举例来说，A 网站允许 GitHub 登录，背后就是下面的流程。</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs text">**Authorize**<br>1. A 网站让用户跳转到 GitHub。<br><br>2. GitHub 要求用户登录，然后询问&quot;A 网站要求获得 xx 权限，你是否同意？&quot;<br><br>3. 用户同意，GitHub 就会重定向回 A 网站，同时发回一个授权码。<br><br>**Token**<br>4. A 网站使用授权码，向 GitHub 请求令牌。<br><br>5. GitHub 返回令牌.<br><br>6. A 网站使用令牌，向 GitHub 请求用户数据。<br></code></pre></td></tr></table></figure><h3 id="应用登记"><a href="#应用登记" class="headerlink" title="应用登记"></a>应用登记</h3><p>一个应用要求 OAuth 授权，必须先到对方网站登记，让对方知道是谁在请求。</p><p>所以，你要先去 GitHub 登记一下。当然，我已经登记过了，你使用我的登记信息也可以，但为了完整走一遍流程，还是建议大家自己登记。这是免费的。</p><p>访问这个网址，填写登记表。</p><p><img src="/image/Oauth2/WX20220328-114828@2x.png" alt="img"></p><p>应用的名称随便填，主页 URL 填写<code>http://localhost:8080</code>。</p><p>跳转网址填写 <code>http://localhost:8080/oauth/redirect</code>。</p><p>提交表单以后，GitHub 应该会返回客户端 ID（client ID）和客户端密钥（client secret），这就是应用的身份识别码。</p><h3 id="跳转授权"><a href="#跳转授权" class="headerlink" title="跳转授权"></a>跳转授权</h3><p>在你自己搭建的Web网站中，对Github进行授权访问。</p><figure class="highlight http"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs Http">https://github.com/login/oauth/authorize?<br>  client_id=7e015d8ce32370079895&amp;<br>  redirect_uri=http://localhost:8080/oauth/redirect<br></code></pre></td></tr></table></figure><p>这个 URL 指向 GitHub 的 OAuth 授权网址，带有两个参数：<code>client_id</code>告诉 GitHub 谁在请求，<code>redirect_uri</code>是稍后跳转回来的网址。</p><p>用户点击到了 GitHub，GitHub 会要求用户登录，确保是本人在操作。</p><h3 id="获取授权码"><a href="#获取授权码" class="headerlink" title="获取授权码"></a>获取授权码</h3><p>登录后，GitHub 询问用户，该应用正在请求数据，你是否同意授权。</p><p><img src="/image/Oauth2/WX20220328-114914@2x.png" alt="img"></p><p>用户同意授权， GitHub 就会跳转到<code>redirect_uri</code>指定的跳转网址，并且带上授权码，跳转回来的 URL 就是下面的样子。</p><figure class="highlight http"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs Http">http://localhost:8080/oauth/redirect?<br>  code=859310e7cecc9196f4af<br></code></pre></td></tr></table></figure><p>后端收到这个请求以后，就拿到了授权码（code参数）。</p><h3 id="获取令牌"><a href="#获取令牌" class="headerlink" title="获取令牌"></a>获取令牌</h3><p>后端使用这个授权码，向 GitHub 请求令牌。</p><figure class="highlight http"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs Http">https://github.com/login/oauth/access_token?<br>    client_id=$&#123;clientID&#125;&amp;<br>    client_secret=$&#123;clientSecret&#125;&amp;<br>    code=$&#123;requestToken&#125;<br></code></pre></td></tr></table></figure><p>上面代码中，GitHub 的令牌接口<code>https://github.com/login/oauth/access_token</code>需要提供三个参数。</p><figure class="highlight http"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs Http">client_id：客户端的 ID<br><br>client_secret：客户端的密钥<br><br>code：授权码<br></code></pre></td></tr></table></figure><p>作为回应，GitHub 会返回一段 JSON 数据，里面包含了令牌accessToken。</p><h3 id="API数据"><a href="#API数据" class="headerlink" title="API数据"></a>API数据</h3><p>有了令牌以后，就可以向 API 请求数据了。</p><figure class="highlight http"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs Http">https://api.github.com/user,<br>  headers: &#123;<br>    accept: &#x27;application/json&#x27;,<br>    Authorization: &#x27;Bearer $&#123;accessToken&#125;&#x27;<br>  &#125;<br></code></pre></td></tr></table></figure><p>上面代码中，GitHub API 的地址是<code>https://api.github.com/user</code>，请求的时候必须在 HTTP 头信息里面带上令牌<code>Authorization: token 361507da</code>。</p><p>然后，就可以拿到用户数据，得到用户的身份。</p>]]></content>
    
    
    <categories>
      
      <category>Distributed System</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>OpenResty</title>
    <link href="/2022/03/28/Distributed%20System/OpenResty/"/>
    <url>/2022/03/28/Distributed%20System/OpenResty/</url>
    
    <content type="html"><![CDATA[<h2 id="OpenResty"><a href="#OpenResty" class="headerlink" title="OpenResty"></a><a href="https://openresty.org/cn/">OpenResty</a></h2><p>OpenResty® 是一个基于 Nginx 与 Lua 的高性能 Web 平台，其内部集成了大量精良的 Lua 库、第三方模块以及大多数的依赖项。用于方便地搭建能够处理超高并发、扩展性极高的动态 Web 应用、Web 服务和动态网关。</p><p>OpenResty® 通过汇聚各种设计精良的 Nginx 模块（主要由 OpenResty 团队自主开发），从而将 Nginx 有效地变成一个强大的通用 Web 应用平台。这样，Web 开发人员和系统工程师可以使用 Lua 脚本语言调动 Nginx 支持的各种 C 以及 Lua 模块，快速构造出足以胜任 10K 乃至 1000K 以上单机并发连接的高性能 Web 应用系统。</p><p>OpenResty® 的目标是让你的Web服务直接跑在 Nginx 服务内部，充分利用 Nginx 的非阻塞 I&#x2F;O 模型，不仅仅对 HTTP 客户端请求,甚至于对远程后端诸如 MySQL、PostgreSQL、Memcached 以及 Redis 等都进行一致的高性能响应。</p>]]></content>
    
    
    <categories>
      
      <category>Distributed System</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Canal</title>
    <link href="/2022/03/28/Spring/Canal/"/>
    <url>/2022/03/28/Spring/Canal/</url>
    
    <content type="html"><![CDATA[<h2 id="What-is-Canal"><a href="#What-is-Canal" class="headerlink" title="What is Canal?"></a>What is Canal?</h2><p>Canal is a high performance data synchronization system based on MySQL binary log. Canal is widely used in Alibaba group (including <a href="https://www.taobao.com/">https://www.taobao.com</a>) to provide reliable low latency incremental data pipeline.</p><p>Canal是一个基于 MySQL 二进制日志的高性能数据同步系统。Canal 在阿里巴巴集团(包括 <a href="https://www.taobao.com/">https://www.taobao.com</a> )中被广泛应用，以提供可靠的低延迟增量数据流水线。</p><p>Canal Server is capable of parsing MySQL binlog and subscribe to the data change, while Canal Client can be implemented to broadcast the change to anywhere, e.g. database and Apache Kafka.</p><p>Canal Server能够解析 MySQL binlog 并订阅数据更改，而 Canal Client 可以实现将更改广播到任何地方，例如数据库和 Apache Kafka。</p><h2 id="Component"><a href="#Component" class="headerlink" title="Component"></a>Component</h2><h3 id="Admin"><a href="#Admin" class="headerlink" title="Admin"></a>Admin</h3><p>canal-admin设计上是为canal提供整体配置管理、节点运维等面向运维的功能，提供相对友好的WebUI操作界面，方便更多用户快速和安全的操作。</p><h3 id="Adapter"><a href="#Adapter" class="headerlink" title="Adapter"></a>Adapter</h3><p>canal-adapter是为了让研发人员方便快速的将增量数据发送到ElasticSearch等Nosql中，减少Java代码的编写。</p><h3 id="Deployer"><a href="#Deployer" class="headerlink" title="Deployer"></a>Deployer</h3><p>canal-deployer是一个模仿Mysql备机的小型服务，用于获取数据库日志抓取数据。</p><h2 id="Use"><a href="#Use" class="headerlink" title="Use"></a>Use</h2><h3 id="1-Schedule"><a href="#1-Schedule" class="headerlink" title="1. Schedule"></a>1. Schedule</h3><p>使用Springboot定时器，定时抓取Canal中的增量数据，并解析，然后发送到自己想去的地方。官方中也是使用此做法。</p><figure class="highlight awk"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></div></td><td class="code"><pre><code class="hljs awk">Get <span class="hljs-regexp">/knowledge/</span>_search<br>&#123;<br>  <span class="hljs-string">&quot;query&quot;</span>:&#123;<br>    <span class="hljs-string">&quot;term&quot;</span>:&#123;<br>      <span class="hljs-string">&quot;searchTypeId.keyword&quot;</span>:<span class="hljs-string">&quot;3&quot;</span><br>    &#125;<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Spring Cloud</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CDC</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Feign</title>
    <link href="/2022/03/28/Spring/Feign/"/>
    <url>/2022/03/28/Spring/Feign/</url>
    
    <content type="html"><![CDATA[<p>SpringCloud feign 对Netflix feign进行了包装和增强，本文从源码角度梳理一个请求链路中参与的各个组件及其它们如何配合交互完成请求。组件包括feign、ribbon、hystrix、sleuth等</p><h2 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h2><h3 id="EnableFeignClients"><a href="#EnableFeignClients" class="headerlink" title="@EnableFeignClients"></a>@EnableFeignClients</h3><p>该注解通过import方式，引入FeignClientsRegistrar。先注册默认配置，再注册所有的feignClient BeanDefinition。</p><p>扫描到所有@FeignClient的BeanDefinition后，包装成FeignClientFactoryBean，然后注册到spring上下文中。</p><h3 id="FeignClientFactoryBean"><a href="#FeignClientFactoryBean" class="headerlink" title="FeignClientFactoryBean"></a>FeignClientFactoryBean</h3><p>完成了调用前的所有准备工作，如FeignContext，Feign.builder的创建、判断是否需要负载均衡及设置及Feign的代理类的创建等。</p><p>Feign 的动态代理创建完成，并交由Spring容器管理。第二阶段的初始化阶段至此结束。http请求发生时，创建的代理对象最终聚合ribbon、hystrix、sleuth的功能完成整个调用链路的增强或跟踪。</p><h2 id="Log"><a href="#Log" class="headerlink" title="Log"></a>Log</h2><ul><li>NONE：默认的，不显示任何日志；</li><li>BASIC：仅记录请求方法、URL、响应状态码及执行时间；</li><li>HEADERS：除了BASIC中定义的信息之外，还有请求和响应的头信息；</li><li>FULL：除了HEADERS中定义的信息之外，还有请求和响应的正文及元数据。</li></ul><figure class="highlight java"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></div></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * Created by macro on 2019/9/5.</span><br><span class="hljs-comment"> */</span><br><span class="hljs-meta">@Configuration</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">FeignConfig</span> &#123;<br>  <span class="hljs-meta">@Bean</span><br>  Logger.Level <span class="hljs-title function_">feignLoggerLevel</span><span class="hljs-params">()</span> &#123;<br>    <span class="hljs-keyword">return</span> Logger.Level.FULL;<br>  &#125;<br>&#125;<br><br></code></pre></td></tr></table></figure><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">logging:</span><br>  <span class="hljs-attr">level:</span><br>  <span class="hljs-attr">com.macro.cloud.service.UserService:</span> <span class="hljs-string">debug</span><br><br></code></pre></td></tr></table></figure><h2 id="Used-Config"><a href="#Used-Config" class="headerlink" title="Used Config"></a>Used Config</h2><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">feign:</span><br>  <span class="hljs-attr">hystrix:</span><br>  <span class="hljs-attr">enabled:</span> <span class="hljs-literal">true</span> <span class="hljs-comment">#在Feign中开启Hystrix</span><br>  <span class="hljs-attr">compression:</span><br>  <span class="hljs-attr">request:</span><br>    <span class="hljs-attr">enabled:</span> <span class="hljs-literal">false</span> <span class="hljs-comment">#是否对请求进行GZIP压缩</span><br>    <span class="hljs-attr">mime-types:</span> <span class="hljs-string">text/xml,application/xml,application/json</span> <span class="hljs-comment">#指定压缩的请求数据类型</span><br>    <span class="hljs-attr">min-request-size:</span> <span class="hljs-number">2048</span> <span class="hljs-comment">#超过该大小的请求会被压缩</span><br>  <span class="hljs-attr">response:</span><br>    <span class="hljs-attr">enabled:</span> <span class="hljs-literal">false</span> <span class="hljs-comment">#是否对响应进行GZIP压缩</span><br><span class="hljs-attr">logging:</span><br>  <span class="hljs-attr">level:</span> <span class="hljs-comment">#修改日志级别</span><br>  <span class="hljs-attr">com.macro.cloud.service.UserService:</span> <span class="hljs-string">debug</span><br><br></code></pre></td></tr></table></figure><h2 id="调用"><a href="#调用" class="headerlink" title="调用"></a>调用</h2><p>在初始化的最后，创建了InvocationHandler，在请求发生时invoke()方法将被调用。如果引入了hystrix，那么就是调用HystrixInvocationHandler，该方法内部调用了HystrixCommand。</p><p>在run()方法中，调用对应的methodHandler的invoke()方法。在这里有获取URL，封装ribbon请求，负载均衡，并最终执行httpclient调用。</p><h2 id="源码解读"><a href="#源码解读" class="headerlink" title="源码解读"></a>源码解读</h2><p><a href="https://www.jianshu.com/p/769081fe8d95">Feign 调用过程分析</a></p>]]></content>
    
    
    <categories>
      
      <category>Spring Cloud</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>GateWay</title>
    <link href="/2022/03/28/Spring/GateWay/"/>
    <url>/2022/03/28/Spring/GateWay/</url>
    
    <content type="html"><![CDATA[<h3 id="过滤器"><a href="#过滤器" class="headerlink" title="过滤器"></a>过滤器</h3><h4 id="GlobalFilter"><a href="#GlobalFilter" class="headerlink" title="GlobalFilter"></a>GlobalFilter</h4><p>全局过滤器，不需要在配置文件中配置，作用在所有的路由上，最终通过GatewayFilterAdapter包装成GatewayFilterChain可识别的过滤器，它为请求业务以及路由的URI转换为真实业务服务的请求地址的核心过滤器，不需要配置，系统初始化时加载，并作用在每个路由上。</p><ul><li><strong>可以实现此过滤器来完成鉴权功能, 比如ruoyi-cloud项目的AuthFilter</strong>  <figure class="highlight java"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br></pre></div></td><td class="code"><pre><code class="hljs Java"><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * 网关鉴权</span><br><span class="hljs-comment"> * </span><br><span class="hljs-comment"> * <span class="hljs-doctag">@author</span> ruoyi</span><br><span class="hljs-comment"> */</span><br><span class="hljs-meta">@Component</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">AuthFilter</span> <span class="hljs-keyword">implements</span> <span class="hljs-title class_">GlobalFilter</span>, Ordered<br>&#123;<br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-type">Logger</span> <span class="hljs-variable">log</span> <span class="hljs-operator">=</span> LoggerFactory.getLogger(AuthFilter.class);<br><br>    <span class="hljs-comment">// 排除过滤的 uri 地址，nacos自行添加</span><br>    <span class="hljs-meta">@Autowired</span><br>    <span class="hljs-keyword">private</span> IgnoreWhiteProperties ignoreWhite;<br><br>    <span class="hljs-meta">@Autowired</span><br>    <span class="hljs-keyword">private</span> RedisService redisService;<br><br><br>    <span class="hljs-meta">@Override</span><br>    <span class="hljs-keyword">public</span> Mono&lt;Void&gt; <span class="hljs-title function_">filter</span><span class="hljs-params">(ServerWebExchange exchange, GatewayFilterChain chain)</span><br>    &#123;<br>        <span class="hljs-type">ServerHttpRequest</span> <span class="hljs-variable">request</span> <span class="hljs-operator">=</span> exchange.getRequest();<br>        ServerHttpRequest.<span class="hljs-type">Builder</span> <span class="hljs-variable">mutate</span> <span class="hljs-operator">=</span> request.mutate();<br><br>        <span class="hljs-type">String</span> <span class="hljs-variable">url</span> <span class="hljs-operator">=</span> request.getURI().getPath();<br>        <span class="hljs-comment">// 跳过不需要验证的路径</span><br>        <span class="hljs-keyword">if</span> (StringUtils.matches(url, ignoreWhite.getWhites()))<br>        &#123;<br>            <span class="hljs-keyword">return</span> chain.filter(exchange);<br>        &#125;<br>        <span class="hljs-type">String</span> <span class="hljs-variable">token</span> <span class="hljs-operator">=</span> getToken(request);<br>        <span class="hljs-keyword">if</span> (StringUtils.isEmpty(token))<br>        &#123;<br>            <span class="hljs-keyword">return</span> unauthorizedResponse(exchange, <span class="hljs-string">&quot;令牌不能为空&quot;</span>);<br>        &#125;<br>        <span class="hljs-type">Claims</span> <span class="hljs-variable">claims</span> <span class="hljs-operator">=</span> JwtUtils.parseToken(token);<br>        <span class="hljs-keyword">if</span> (claims == <span class="hljs-literal">null</span>)<br>        &#123;<br>            <span class="hljs-keyword">return</span> unauthorizedResponse(exchange, <span class="hljs-string">&quot;令牌已过期或验证不正确！&quot;</span>);<br>        &#125;<br>        <span class="hljs-type">String</span> <span class="hljs-variable">userkey</span> <span class="hljs-operator">=</span> JwtUtils.getUserKey(claims);<br>        <span class="hljs-type">boolean</span> <span class="hljs-variable">islogin</span> <span class="hljs-operator">=</span> redisService.hasKey(getTokenKey(userkey));<br>        <span class="hljs-keyword">if</span> (!islogin)<br>        &#123;<br>            <span class="hljs-keyword">return</span> unauthorizedResponse(exchange, <span class="hljs-string">&quot;登录状态已过期&quot;</span>);<br>        &#125;<br>        <span class="hljs-type">String</span> <span class="hljs-variable">userid</span> <span class="hljs-operator">=</span> JwtUtils.getUserId(claims);<br>        <span class="hljs-type">String</span> <span class="hljs-variable">username</span> <span class="hljs-operator">=</span> JwtUtils.getUserName(claims);<br>        <span class="hljs-keyword">if</span> (StringUtils.isEmpty(userid) || StringUtils.isEmpty(username))<br>        &#123;<br>            <span class="hljs-keyword">return</span> unauthorizedResponse(exchange, <span class="hljs-string">&quot;令牌验证失败&quot;</span>);<br>        &#125;<br><br>        <span class="hljs-comment">// 设置用户信息到请求</span><br>        addHeader(mutate, SecurityConstants.USER_KEY, userkey);<br>        addHeader(mutate, SecurityConstants.DETAILS_USER_ID, userid);<br>        addHeader(mutate, SecurityConstants.DETAILS_USERNAME, username);<br>        <span class="hljs-comment">// 内部请求来源参数清除</span><br>        removeHeader(mutate, SecurityConstants.FROM_SOURCE);<br>        <span class="hljs-keyword">return</span> chain.filter(exchange.mutate().request(mutate.build()).build());<br>    &#125;<br><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">addHeader</span><span class="hljs-params">(ServerHttpRequest.Builder mutate, String name, Object value)</span><br>    &#123;<br>        <span class="hljs-keyword">if</span> (value == <span class="hljs-literal">null</span>)<br>        &#123;<br>            <span class="hljs-keyword">return</span>;<br>        &#125;<br>        <span class="hljs-type">String</span> <span class="hljs-variable">valueStr</span> <span class="hljs-operator">=</span> value.toString();<br>        <span class="hljs-type">String</span> <span class="hljs-variable">valueEncode</span> <span class="hljs-operator">=</span> ServletUtils.urlEncode(valueStr);<br>        mutate.header(name, valueEncode);<br>    &#125;<br><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">removeHeader</span><span class="hljs-params">(ServerHttpRequest.Builder mutate, String name)</span><br>    &#123;<br>        mutate.headers(httpHeaders -&gt; httpHeaders.remove(name)).build();<br>    &#125;<br><br>    <span class="hljs-keyword">private</span> Mono&lt;Void&gt; <span class="hljs-title function_">unauthorizedResponse</span><span class="hljs-params">(ServerWebExchange exchange, String msg)</span><br>    &#123;<br>        log.error(<span class="hljs-string">&quot;[鉴权异常处理]请求路径:&#123;&#125;&quot;</span>, exchange.getRequest().getPath());<br>        <span class="hljs-keyword">return</span> ServletUtils.webFluxResponseWriter(exchange.getResponse(), msg, HttpStatus.UNAUTHORIZED);<br>    &#125;<br><br>    <span class="hljs-comment">/**</span><br><span class="hljs-comment">     * 获取缓存key</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-keyword">private</span> String <span class="hljs-title function_">getTokenKey</span><span class="hljs-params">(String token)</span><br>    &#123;<br>        <span class="hljs-keyword">return</span> CacheConstants.LOGIN_TOKEN_KEY + token;<br>    &#125;<br><br>    <span class="hljs-comment">/**</span><br><span class="hljs-comment">     * 获取请求token</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-keyword">private</span> String <span class="hljs-title function_">getToken</span><span class="hljs-params">(ServerHttpRequest request)</span><br>    &#123;<br>        <span class="hljs-type">String</span> <span class="hljs-variable">token</span> <span class="hljs-operator">=</span> request.getHeaders().getFirst(TokenConstants.AUTHENTICATION);<br>        <span class="hljs-comment">// 如果前端设置了令牌前缀，则裁剪掉前缀</span><br>        <span class="hljs-keyword">if</span> (StringUtils.isNotEmpty(token) &amp;&amp; token.startsWith(TokenConstants.PREFIX))<br>        &#123;<br>            token = token.replaceFirst(TokenConstants.PREFIX, StringUtils.EMPTY);<br>        &#125;<br>        <span class="hljs-keyword">return</span> token;<br>    &#125;<br><br>    <span class="hljs-meta">@Override</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-type">int</span> <span class="hljs-title function_">getOrder</span><span class="hljs-params">()</span><br>    &#123;<br>        <span class="hljs-keyword">return</span> -<span class="hljs-number">200</span>;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure></li></ul><h4 id="GatewayFilter"><a href="#GatewayFilter" class="headerlink" title="GatewayFilter"></a>GatewayFilter</h4><p>需要通过 <code>spring.cloud.routes.filters</code> 配置在<strong>具体路由</strong>下，只作用在当前路由上或通过spring.cloud.default-filters配置在全局，作用在所有路由上。</p><h4 id="Hystrix-GatewayFilter"><a href="#Hystrix-GatewayFilter" class="headerlink" title="Hystrix GatewayFilter"></a>Hystrix GatewayFilter</h4><p>Hystrix 过滤器允许你将断路器功能添加到<strong>具体的网关路由</strong>中，使你的服务免受级联故障的影响，并提供服务降级处理。</p><ul><li><p>要开启断路器功能，我们需要在pom.xml中添加Hystrix的相关依赖：</p>  <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.springframework.cloud<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>spring-cloud-starter-netflix-hystrix<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br></code></pre></td></tr></table></figure></li><li><p>然后添加相关服务降级的处理类：</p>  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * Created by macro on 2019/9/25.</span><br><span class="hljs-comment"> */</span><br><span class="hljs-meta">@RestController</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">FallbackController</span> &#123;<br><br>    <span class="hljs-meta">@GetMapping(&quot;/fallback&quot;)</span><br>    <span class="hljs-keyword">public</span> Object <span class="hljs-title function_">fallback</span><span class="hljs-params">()</span> &#123;<br>        Map&lt;String,Object&gt; result = <span class="hljs-keyword">new</span> <span class="hljs-title class_">HashMap</span>&lt;&gt;();<br>        result.put(<span class="hljs-string">&quot;data&quot;</span>,<span class="hljs-literal">null</span>);<br>        result.put(<span class="hljs-string">&quot;message&quot;</span>,<span class="hljs-string">&quot;Get request fallback!&quot;</span>);<br>        result.put(<span class="hljs-string">&quot;code&quot;</span>,<span class="hljs-number">500</span>);<br>        <span class="hljs-keyword">return</span> result;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure></li><li><p>在application-filter.yml中添加相关配置，当路由出错时会转发到服务降级处理的控制器上：</p>  <figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">spring:</span><br>  <span class="hljs-attr">cloud:</span><br>    <span class="hljs-attr">gateway:</span><br>      <span class="hljs-attr">routes:</span><br>        <span class="hljs-bullet">-</span> <span class="hljs-attr">id:</span> <span class="hljs-string">hystrix_route</span><br>          <span class="hljs-attr">uri:</span> <span class="hljs-string">http://localhost:8201</span><br>          <span class="hljs-attr">predicates:</span><br>            <span class="hljs-bullet">-</span> <span class="hljs-string">Method=GET</span><br>          <span class="hljs-attr">filters:</span><br>            <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">Hystrix</span><br>              <span class="hljs-attr">args:</span><br>                <span class="hljs-attr">name:</span> <span class="hljs-string">fallbackcmd</span><br>                <span class="hljs-attr">fallbackUri:</span> <span class="hljs-string">forward:/fallback</span><br></code></pre></td></tr></table></figure></li><li><p>关闭user-service，调用该地址进行测试：<a href="http://localhost:9201/user/1">http://localhost:9201/user/1</a> ，发现已经返回了服务降级的处理信息。</p></li></ul><p><img src="http://www.macrozheng.com/images/springcloud_gateway_03.png" title="image"></p><h3 id="异常拦截器"><a href="#异常拦截器" class="headerlink" title="异常拦截器"></a>异常拦截器</h3><h4 id="WebExceptionHandler"><a href="#WebExceptionHandler" class="headerlink" title="WebExceptionHandler"></a>WebExceptionHandler</h4><p>在该异常处理中, 可以对 <code>服务未找到</code> 或者<code>sentinel</code>的相关异常 (BlockException) 进行判断拦截, 并返回对应错误信息, 告知用户</p><p>具体可查看<strong>ruoyi</strong>项目的相关代码, 写的比较完全</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><code class="hljs Java"><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * 网关统一异常处理</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * <span class="hljs-doctag">@author</span> ruoyi</span><br><span class="hljs-comment"> */</span><br><span class="hljs-meta">@Order(-1)</span> <span class="hljs-comment">//优先级一定要小于内置ResponseStatusExceptionHandler, 经过它处理的获取对应错误类的 响应码</span><br><span class="hljs-meta">@Configuration</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">GatewayExceptionHandler</span> <span class="hljs-keyword">implements</span> <span class="hljs-title class_">ErrorWebExceptionHandler</span><br>&#123;<br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-type">Logger</span> <span class="hljs-variable">log</span> <span class="hljs-operator">=</span> LoggerFactory.getLogger(GatewayExceptionHandler.class);<br><br>    <span class="hljs-meta">@Override</span><br>    <span class="hljs-keyword">public</span> Mono&lt;Void&gt; <span class="hljs-title function_">handle</span><span class="hljs-params">(ServerWebExchange exchange, Throwable ex)</span><br>    &#123;<br>        <span class="hljs-type">ServerHttpResponse</span> <span class="hljs-variable">response</span> <span class="hljs-operator">=</span> exchange.getResponse();<br><br>        <span class="hljs-keyword">if</span> (exchange.getResponse().isCommitted())<br>        &#123;<br>            <span class="hljs-keyword">return</span> Mono.error(ex);<br>        &#125;<br><br>        String msg;<br><br>        <span class="hljs-keyword">if</span> (ex <span class="hljs-keyword">instanceof</span> NotFoundException)<br>        &#123;<br>            msg = <span class="hljs-string">&quot;服务未找到&quot;</span>;<br>        &#125;<br>        <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (ex <span class="hljs-keyword">instanceof</span> ResponseStatusException)<br>        &#123;<br>            <span class="hljs-type">ResponseStatusException</span> <span class="hljs-variable">responseStatusException</span> <span class="hljs-operator">=</span> (ResponseStatusException) ex;<br>            msg = responseStatusException.getMessage();<br>        &#125;<br>        <span class="hljs-keyword">else</span><br>        &#123;<br>            msg = <span class="hljs-string">&quot;内部服务器错误&quot;</span>;<br>        &#125;<br><br>        log.error(<span class="hljs-string">&quot;[网关异常处理]请求路径:&#123;&#125;,异常信息:&#123;&#125;&quot;</span>, exchange.getRequest().getPath(), ex.getMessage());<br><br>        <span class="hljs-keyword">return</span> ServletUtils.webFluxResponseWriter(response, msg);<br>    &#125;<br>&#125;<br><br><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * 自定义限流异常处理</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * <span class="hljs-doctag">@author</span> ruoyi</span><br><span class="hljs-comment"> */</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">SentinelFallbackHandler</span> <span class="hljs-keyword">implements</span> <span class="hljs-title class_">WebExceptionHandler</span><br>&#123;<br>    <span class="hljs-keyword">private</span> Mono&lt;Void&gt; <span class="hljs-title function_">writeResponse</span><span class="hljs-params">(ServerResponse response, ServerWebExchange exchange)</span><br>    &#123;<br>        <span class="hljs-keyword">return</span> ServletUtils.webFluxResponseWriter(exchange.getResponse(), <span class="hljs-string">&quot;请求超过最大数，请稍候再试&quot;</span>);<br>    &#125;<br><br>    <span class="hljs-meta">@Override</span><br>    <span class="hljs-keyword">public</span> Mono&lt;Void&gt; <span class="hljs-title function_">handle</span><span class="hljs-params">(ServerWebExchange exchange, Throwable ex)</span><br>    &#123;<br>        <span class="hljs-keyword">if</span> (exchange.getResponse().isCommitted())<br>        &#123;<br>            <span class="hljs-keyword">return</span> Mono.error(ex);<br>        &#125;<br>        <span class="hljs-keyword">if</span> (!BlockException.isBlockException(ex))<br>        &#123;<br>            <span class="hljs-keyword">return</span> Mono.error(ex);<br>        &#125;<br>        <span class="hljs-keyword">return</span> handleBlockedRequest(exchange, ex).flatMap(response -&gt; writeResponse(response, exchange));<br>    &#125;<br><br>    <span class="hljs-keyword">private</span> Mono&lt;ServerResponse&gt; <span class="hljs-title function_">handleBlockedRequest</span><span class="hljs-params">(ServerWebExchange exchange, Throwable throwable)</span><br>    &#123;<br>        <span class="hljs-keyword">return</span> GatewayCallbackManager.getBlockHandler().handleRequest(exchange, throwable);<br>    &#125;<br>&#125;<br><br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Spring Cloud</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Hikari</title>
    <link href="/2022/03/28/Spring/Hikari/"/>
    <url>/2022/03/28/Spring/Hikari/</url>
    
    <content type="html"><![CDATA[<p>Hikari是Spring在2.0之后的默认jdbc连接工具, 相比于常用的Druid, 他的连接速度加快, 字节码精简, 并发读写效率提高</p><p>但是Druid有强大的Sql监控特性以及额外的扩展功能</p><h2 id="主要构件"><a href="#主要构件" class="headerlink" title="主要构件"></a>主要构件</h2><ul><li>HikariDataSource<br>是一切的入口, 用于获取连接的主要类</li><li>HikariConfig<br>配置类</li><li>HikariPool<br>持有连接池, 延时maxlifetime任务, 定时keepalive清理任务的控制类</li><li>ConcurrentBag<br>连接池, 内部持有了连接对象的集合, 用于获取 , 删除, 增加连接</li><li>PoolEntry<br>具体的连接对象, 持有实际的物理连接Connection</li><li>PoolBase<br>主要用于生产一个DriverDataSource类, 给new PoolEntry()时使用</li></ul><h2 id="源码解读"><a href="#源码解读" class="headerlink" title="源码解读"></a>源码解读</h2><p><a href="https://juejin.cn/post/6986812265357901860">HikariCP源码流程</a></p>]]></content>
    
    
    <categories>
      
      <category>Spring Cloud</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Database</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hystrix</title>
    <link href="/2022/03/28/Spring/Hystrix/"/>
    <url>/2022/03/28/Spring/Hystrix/</url>
    
    <content type="html"><![CDATA[<blockquote><p>在微服务架构中，服务与服务之间通过远程调用的方式进行通信，一旦某个被调用的服务发生了故障，其依赖服务也会发生故障，此时就会发生故障的蔓延，最终导致系统瘫痪。Hystrix实现了断路器模式，当某个服务发生故障时，通过断路器的监控，给调用方返回一个错误响应，而不是长时间的等待，这样就不会使得调用方由于长时间得不到响应而占用线程，从而防止故障的蔓延。Hystrix具备服务降级、服务熔断、线程隔离、请求缓存、请求合并及服务监控等强大功能。</p></blockquote><h4 id="Used-Parameters"><a href="#Used-Parameters" class="headerlink" title="Used Parameters"></a>Used Parameters</h4><ul><li>fallbackMethod：指定服务降级处理方法；</li><li>ignoreExceptions：忽略某些异常，不发生服务降级；</li><li>commandKey：命令名称，用于区分不同的命令；</li><li>groupKey：分组名称，Hystrix会根据不同的分组来统计命令的告警及仪表盘信息；</li><li>threadPoolKey：线程池名称，用于划分线程池。</li></ul><h3 id="资源隔离"><a href="#资源隔离" class="headerlink" title="资源隔离"></a>资源隔离</h3><p><img src="https://res.craft.do/user/full/2c016c68-2ea0-5513-42ea-5813d216a654/doc/64F8465D-ECA0-4FC5-8B4D-195A84183BDB/AE24F0F6-D141-4924-8387-28C3C3D9AF70_2" title="image"></p><p><strong>适用场景</strong>：</p><ul><li><strong>线程池技术</strong>，适合绝大多数场景，比如说我们对依赖服务的网络请求的调用和访问、需要对调用的 timeout 进行控制（捕捉 timeout 超时异常）。</li><li><strong>信号量技术</strong>，适合说你的访问不是对外部依赖的访问，而是对内部的一些比较复杂的业务逻辑的访问，并且系统内部的代码，其实不涉及任何的网络请求，那么只要做信号量的普通限流就可以了，因为不需要去捕获 timeout 类似的问题。</li></ul><h3 id="Request-Cache"><a href="#Request-Cache" class="headerlink" title="Request Cache"></a>Request Cache</h3><p>在一次请求上下文中，如果有多个 command，参数都是一样的，调用的接口也是一样的，而结果可以认为也是一样的。那么这个时候，我们可以让第一个 command 执行返回的结果缓存在内存中，然后这个请求上下文后续的其它对这个依赖的调用全部从内存中取出缓存结果就可以了。</p><p>这样的话，好处在于不用在一次请求上下文中反复多次执行一样的 command，<strong>避免重复执行网络请求，提升整个请求的性能</strong>。</p><figure class="highlight java"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></div></td><td class="code"><pre><code class="hljs java"><span class="hljs-meta">@CacheResult(cacheKeyMethod = &quot;getCacheKey&quot;)</span><br><span class="hljs-meta">@HystrixCommand(fallbackMethod = &quot;getDefaultUser&quot;, commandKey = &quot;getUserCache&quot;)</span><br>    <span class="hljs-keyword">public</span> CommonResult <span class="hljs-title function_">getUserCache</span><span class="hljs-params">(Long id)</span> &#123;<br>    LOGGER.info(<span class="hljs-string">&quot;getUserCache id:&#123;&#125;&quot;</span>, id);<br>    <span class="hljs-keyword">return</span> restTemplate.getForObject(userServiceUrl + <span class="hljs-string">&quot;/user/&#123;1&#125;&quot;</span>, CommonResult.class, id);<br>&#125;<br><br><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * 为缓存生成key的方法</span><br><span class="hljs-comment"> */</span><br><span class="hljs-keyword">public</span> String <span class="hljs-title function_">getCacheKey</span><span class="hljs-params">(Long id)</span> &#123;<br>    <span class="hljs-keyword">return</span> String.valueOf(id);<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="HystrixCollapser-请求合并"><a href="#HystrixCollapser-请求合并" class="headerlink" title="HystrixCollapser 请求合并"></a>HystrixCollapser 请求合并</h3><ul><li>batchMethod：用于设置请求合并的方法；</li><li>collapserProperties：请求合并属性，用于控制实例属性，有很多；</li><li>timerDelayInMilliseconds：collapserProperties中的属性，用于控制每隔多少时间合并一次请求；</li></ul><ol><li>在UserHystrixController中添加testCollapser方法，这里我们先进行两次服务调用，再间隔200ms以后进行第三次服务调用：</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-meta">@GetMapping(&quot;/testCollapser&quot;)</span><br><span class="hljs-keyword">public</span> CommonResult <span class="hljs-title function_">testCollapser</span><span class="hljs-params">()</span> <span class="hljs-keyword">throws</span> ExecutionException, InterruptedException &#123;<br>  Future&lt;User&gt; future1 = userService.getUserFuture(<span class="hljs-number">1L</span>);<br>  Future&lt;User&gt; future2 = userService.getUserFuture(<span class="hljs-number">2L</span>);<br>  future1.get();<br>  future2.get();<br>  ThreadUtil.safeSleep(<span class="hljs-number">200</span>);<br>  Future&lt;User&gt; future3 = userService.getUserFuture(<span class="hljs-number">3L</span>);<br>  future3.get();<br>  <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">CommonResult</span>(<span class="hljs-string">&quot;操作成功&quot;</span>, <span class="hljs-number">200</span>);<br>&#125;<br><br></code></pre></td></tr></table></figure><ol><li>使用@HystrixCollapser实现请求合并，所有对getUserFuture的的多次调用都会转化为对getUserByIds的单次调用：</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-meta">@HystrixCollapser(batchMethod = &quot;getUserByIds&quot;,collapserProperties = &#123;</span><br><span class="hljs-meta">  @HystrixProperty(name = &quot;timerDelayInMilliseconds&quot;, value = &quot;100&quot;)</span><br><span class="hljs-meta">&#125;)</span><br><span class="hljs-keyword">public</span> Future&lt;User&gt; <span class="hljs-title function_">getUserFuture</span><span class="hljs-params">(Long id)</span> &#123;<br>  <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">AsyncResult</span>&lt;User&gt;()&#123;<br>  <span class="hljs-meta">@Override</span><br>  <span class="hljs-keyword">public</span> User <span class="hljs-title function_">invoke</span><span class="hljs-params">()</span> &#123;<br>    <span class="hljs-type">CommonResult</span> <span class="hljs-variable">commonResult</span> <span class="hljs-operator">=</span> restTemplate.getForObject(userServiceUrl + <span class="hljs-string">&quot;/user/&#123;1&#125;&quot;</span>, CommonResult.class, id);<br>    <span class="hljs-type">Map</span> <span class="hljs-variable">data</span> <span class="hljs-operator">=</span> (Map) commonResult.getData();<br>    <span class="hljs-type">User</span> <span class="hljs-variable">user</span> <span class="hljs-operator">=</span> BeanUtil.mapToBean(data,User.class,<span class="hljs-literal">true</span>);<br>    LOGGER.info(<span class="hljs-string">&quot;getUserById username:&#123;&#125;&quot;</span>, user.getUsername());<br>    <span class="hljs-keyword">return</span> user;<br>    &#125;<br>  &#125;;<br>&#125;<br><br><span class="hljs-meta">@HystrixCommand</span><br><span class="hljs-keyword">public</span> List&lt;User&gt; <span class="hljs-title function_">getUserByIds</span><span class="hljs-params">(List&lt;Long&gt; ids)</span> &#123;<br>  LOGGER.info(<span class="hljs-string">&quot;getUserByIds:&#123;&#125;&quot;</span>, ids);<br>  <span class="hljs-type">CommonResult</span> <span class="hljs-variable">commonResult</span> <span class="hljs-operator">=</span> restTemplate.getForObject(userServiceUrl + <span class="hljs-string">&quot;/user/getUserByIds?ids=&#123;1&#125;&quot;</span>, CommonResult.class, CollUtil.join(ids,<span class="hljs-string">&quot;,&quot;</span>));<br>  <span class="hljs-keyword">return</span> (List&lt;User&gt;) commonResult.getData();<br>&#125;<br><br></code></pre></td></tr></table></figure><h3 id="Used-Config"><a href="#Used-Config" class="headerlink" title="Used Config"></a>Used Config</h3><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">hystrix:</span><br>  <span class="hljs-attr">command:</span> <span class="hljs-comment">#用于控制HystrixCommand的行为</span><br>  <span class="hljs-attr">default:</span><br>    <span class="hljs-attr">execution:</span><br>    <span class="hljs-attr">isolation:</span><br>      <span class="hljs-attr">strategy:</span> <span class="hljs-string">THREAD</span> <span class="hljs-comment">#控制HystrixCommand的隔离策略，THREAD-&gt;线程池隔离策略(默认)，SEMAPHORE-&gt;信号量隔离策略</span><br>      <span class="hljs-attr">thread:</span><br>      <span class="hljs-attr">timeoutInMilliseconds:</span> <span class="hljs-number">1000</span> <span class="hljs-comment">#配置HystrixCommand执行的超时时间，执行超过该时间会进行服务降级处理</span><br>      <span class="hljs-attr">interruptOnTimeout:</span> <span class="hljs-literal">true</span> <span class="hljs-comment">#配置HystrixCommand执行超时的时候是否要中断</span><br>      <span class="hljs-attr">interruptOnCancel:</span> <span class="hljs-literal">true</span> <span class="hljs-comment">#配置HystrixCommand执行被取消的时候是否要中断</span><br>      <span class="hljs-attr">timeout:</span><br>      <span class="hljs-attr">enabled:</span> <span class="hljs-literal">true</span> <span class="hljs-comment">#配置HystrixCommand的执行是否启用超时时间</span><br>      <span class="hljs-attr">semaphore:</span><br>      <span class="hljs-attr">maxConcurrentRequests:</span> <span class="hljs-number">10</span> <span class="hljs-comment">#当使用信号量隔离策略时，用来控制并发量的大小，超过该并发量的请求会被拒绝</span><br>    <span class="hljs-attr">fallback:</span><br>    <span class="hljs-attr">enabled:</span> <span class="hljs-literal">true</span> <span class="hljs-comment">#用于控制是否启用服务降级</span><br>    <span class="hljs-attr">circuitBreaker:</span> <span class="hljs-comment">#用于控制HystrixCircuitBreaker的行为</span><br>    <span class="hljs-attr">enabled:</span> <span class="hljs-literal">true</span> <span class="hljs-comment">#用于控制断路器是否跟踪健康状况以及熔断请求</span><br>    <span class="hljs-attr">requestVolumeThreshold:</span> <span class="hljs-number">20</span> <span class="hljs-comment">#超过该请求数的请求会被拒绝</span><br>    <span class="hljs-attr">forceOpen:</span> <span class="hljs-literal">false</span> <span class="hljs-comment">#强制打开断路器，拒绝所有请求</span><br>    <span class="hljs-attr">forceClosed:</span> <span class="hljs-literal">false</span> <span class="hljs-comment">#强制关闭断路器，接收所有请求</span><br>    <span class="hljs-attr">requestCache:</span><br>    <span class="hljs-attr">enabled:</span> <span class="hljs-literal">true</span> <span class="hljs-comment">#用于控制是否开启请求缓存</span><br>  <span class="hljs-attr">collapser:</span> <span class="hljs-comment">#用于控制HystrixCollapser的执行行为</span><br>  <span class="hljs-attr">default:</span><br>    <span class="hljs-attr">maxRequestsInBatch:</span> <span class="hljs-number">100</span> <span class="hljs-comment">#控制一次合并请求合并的最大请求数</span><br>    <span class="hljs-attr">timerDelayinMilliseconds:</span> <span class="hljs-number">10</span> <span class="hljs-comment">#控制多少毫秒内的请求会被合并成一个</span><br>    <span class="hljs-attr">requestCache:</span><br>    <span class="hljs-attr">enabled:</span> <span class="hljs-literal">true</span> <span class="hljs-comment">#控制合并请求是否开启缓存</span><br>  <span class="hljs-attr">threadpool:</span> <span class="hljs-comment">#用于控制HystrixCommand执行所在线程池的行为</span><br>  <span class="hljs-attr">default:</span><br>    <span class="hljs-attr">coreSize:</span> <span class="hljs-number">10</span> <span class="hljs-comment">#线程池的核心线程数</span><br>    <span class="hljs-attr">maximumSize:</span> <span class="hljs-number">10</span> <span class="hljs-comment">#线程池的最大线程数，超过该线程数的请求会被拒绝</span><br>    <span class="hljs-attr">maxQueueSize:</span> <span class="hljs-number">-1</span> <span class="hljs-comment">#用于设置线程池的最大队列大小，-1采用SynchronousQueue，其他正数采用LinkedBlockingQueue</span><br>    <span class="hljs-attr">queueSizeRejectionThreshold:</span> <span class="hljs-number">5</span> <span class="hljs-comment">#用于设置线程池队列的拒绝阀值，由于LinkedBlockingQueue不能动态改版大小，使用时需要用该参数来控制线程数</span><br><br></code></pre></td></tr></table></figure><h3 id="DashBoard"><a href="#DashBoard" class="headerlink" title="DashBoard"></a>DashBoard</h3><p>Hystrix提供了Hystrix Dashboard来实时监控HystrixCommand方法的执行情况。 Hystrix Dashboard可以有效地反映出每个Hystrix实例的运行情况，帮助我们快速发现系统中的问题，从而采取对应措施。</p><p><img src="https://res.craft.do/user/full/2c016c68-2ea0-5513-42ea-5813d216a654/doc/64F8465D-ECA0-4FC5-8B4D-195A84183BDB/7ED0A8F2-1BE6-4284-B09D-A44390CCE9F6_2" title="image"></p>]]></content>
    
    
    <categories>
      
      <category>Spring Cloud</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Mybatis</title>
    <link href="/2022/03/28/Spring/Mybatis/"/>
    <url>/2022/03/28/Spring/Mybatis/</url>
    
    <content type="html"><![CDATA[<h2 id="Primary-components"><a href="#Primary-components" class="headerlink" title="Primary components"></a>Primary components</h2><ul><li>Configuration<br>  MyBatis所有的配置信息都维持在Configuration对象之中。<strong>包含拦截器的动态代理功能</strong><ul><li><code>SqlSessionFactoryBuilder</code>对象通过该配置生成<code>SqlSessionFactory</code>, <code>SqlSessionFactory.openSession()</code>得到<code>SqlSession</code>对象</li><li>Spring集成版本中, 不再采用Builder生成, 而是SqlSessionFactoryBean的工厂bean方式注入到Spring中</li></ul></li><li>SqlSession<br>作为MyBatis工作的主要顶层API，表示和数据库交互的会话，完成必要数据库增删改查功能。</li><li>MappedStatement<br>MappedStatement是维护了某一条&lt;select|update|delete|insert&gt;节点的封装对象。</li><li>Executor<br>MyBatis执行器，是MyBatis 调度的核心，负责SQL语句的生成和查询缓存的维护。</li><li>SqlSource           <br>负责根据用户传递的parameterObject，动态地生成SQL语句，将信息封装到BoundSql对象中，并返回。</li></ul><p><img src="/image/Mybatis/mybatis-y-arch-1.png"></p><ul><li>BoundSql            <br>表示动态生成的SQL语句以及相应的参数信息。</li><li>StatementHandler<br>封装了JDBC Statement操作，负责对JDBC statement 的操作，如设置参数、将Statement结果集转换成List集合。</li><li>ParameterHandler<br>负责对用户传递的参数转换成JDBC Statement 所需要的参数。</li><li>ResultSetHandler <br>负责将JDBC返回的ResultSet结果集对象转换成List类型的集合。</li><li>TypeHandler       <br>负责java数据类型和jdbc数据类型之间的映射和转换。</li><li>DefaultObjectFactory<br>在返回查询结果时, 会调用该类的create方法创建java对象出来, 可以实现该方法自定义新的create方法构造出指定值的对象出来</li></ul><h2 id="源码解读"><a href="#源码解读" class="headerlink" title="源码解读"></a>源码解读</h2><p><a href="https://pdai.tech/md/framework/orm-mybatis/mybatis-overview.html">Java 全栈知识体系-Mybatis详解</a></p>]]></content>
    
    
    <categories>
      
      <category>Spring Cloud</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Database</tag>
      
      <tag>ORM</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Mycat</title>
    <link href="/2022/03/28/Spring/Mycat/"/>
    <url>/2022/03/28/Spring/Mycat/</url>
    
    <content type="html"><![CDATA[<p>看了一下Mycat<a href="https://www.yuque.com/books/share/6606b3b6-3365-4187-94c4-e51116894695/bef923fb8acc57e0f805d45ef7782670">官方文档</a>，对于MGR、MHA等都有非常好的兼容模式，可以实现动态数据源更改，但是使用似乎不太广泛。</p>]]></content>
    
    
    <categories>
      
      <category>DataBase</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Ribbon</title>
    <link href="/2022/03/28/Spring/Ribbon/"/>
    <url>/2022/03/28/Spring/Ribbon/</url>
    
    <content type="html"><![CDATA[<blockquote><p>在微服务架构中，很多服务都会部署多个，其他服务去调用该服务的时候，如何保证负载均衡是个不得不去考虑的问题。负载均衡可以增加系统的可用性和扩展性，当我们使用RestTemplate来调用其他服务时，Ribbon可以很方便的实现负载均衡功能。</p></blockquote><h3 id="RestTemplate"><a href="#RestTemplate" class="headerlink" title="RestTemplate"></a>RestTemplate</h3><p>RestTemplate是一个HTTP客户端，使用它我们可以方便的调用HTTP接口，支持GET、POST、PUT、DELETE等方法。</p><h3 id="LoadBalanced"><a href="#LoadBalanced" class="headerlink" title="LoadBalanced"></a>LoadBalanced</h3><p>使用Ribbon的负载均衡功能非常简单，和直接使用RestTemplate没什么两样，只需给RestTemplate添加一个@LoadBalanced即可。</p><ul><li>com.netflix.loadbalancer.RandomRule：从提供服务的实例中以随机的方式；</li><li>com.netflix.loadbalancer.RoundRobinRule：以线性轮询的方式，就是维护一个计数器，从提供服务的实例中按顺序选取，第一次选第一个，第二次选第二个，以此类推，到最后一个以后再从头来过；</li><li>com.netflix.loadbalancer.RetryRule：在RoundRobinRule的基础上添加重试机制，即在指定的重试时间内，反复使用线性轮询策略来选择可用实例；</li><li>com.netflix.loadbalancer.WeightedResponseTimeRule：对RoundRobinRule的扩展，响应速度越快的实例选择权重越大，越容易被选择；</li><li>com.netflix.loadbalancer.BestAvailableRule：选择并发较小的实例；</li><li>com.netflix.loadbalancer.AvailabilityFilteringRule：先过滤掉故障实例，再选择并发较小的实例；</li><li>com.netflix.loadbalancer.ZoneAwareLoadBalancer：采用双重过滤，同时过滤不是同一区域的实例和故障实例，选择并发较小的实例。</li></ul><h3 id="Used-Config"><a href="#Used-Config" class="headerlink" title="Used Config"></a>Used Config</h3><figure class="highlight yaml"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></div></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">user-service:</span><br>  <span class="hljs-attr">ribbon:</span><br>  <span class="hljs-attr">ConnectTimeout:</span> <span class="hljs-number">1000</span> <span class="hljs-comment">#服务请求连接超时时间（毫秒）</span><br>  <span class="hljs-attr">ReadTimeout:</span> <span class="hljs-number">3000</span> <span class="hljs-comment">#服务请求处理超时时间（毫秒）</span><br>  <span class="hljs-attr">OkToRetryOnAllOperations:</span> <span class="hljs-literal">true</span> <span class="hljs-comment">#对超时请求启用重试机制</span><br>  <span class="hljs-attr">MaxAutoRetriesNextServer:</span> <span class="hljs-number">1</span> <span class="hljs-comment">#切换重试实例的最大个数</span><br>  <span class="hljs-attr">MaxAutoRetries:</span> <span class="hljs-number">1</span> <span class="hljs-comment"># 切换实例后重试最大次数</span><br>  <span class="hljs-attr">NFLoadBalancerRuleClassName:</span> <span class="hljs-string">com.netflix.loadbalancer.RandomRule</span> <span class="hljs-comment">#修改负载均衡算法</span><br><br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Spring Cloud</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Seata</title>
    <link href="/2022/03/28/Spring/Seata/"/>
    <url>/2022/03/28/Spring/Seata/</url>
    
    <content type="html"><![CDATA[<blockquote><p>Seata 是一款开源的分布式事务解决方案，致力于提供高性能和简单易用的分布式事务服务。Seata 将为用户提供了 AT、TCC、SAGA 和 XA 事务模式，为用户打造一站式的分布式解决方案。</p></blockquote><h3 id="Component"><a href="#Component" class="headerlink" title="Component"></a>Component</h3><ul><li>Transaction Coordinator (TC)： 事务协调器，维护全局事务的运行状态，负责协调并驱动全局事务的提交或回滚；</li><li>Transaction Manager (TM)： 控制全局事务的边界，负责开启一个全局事务，并最终发起全局提交或全局回滚的决议；</li><li>Resource Manager (RM)： 控制分支事务，负责分支注册、状态汇报，并接收事务协调器的指令，驱动分支（本地）事务的提交和回滚。</li></ul><h3 id="一个典型的分布式事务过程"><a href="#一个典型的分布式事务过程" class="headerlink" title="一个典型的分布式事务过程"></a>一个典型的分布式事务过程</h3><ul><li>TM 向 TC 申请开启一个全局事务，全局事务创建成功并生成一个全局唯一的 XID；</li><li>XID 在微服务调用链路的上下文中传播；</li><li>RM 向 TC 注册分支事务，将其纳入 XID 对应全局事务的管辖；</li><li>TM 向 TC 发起针对 XID 的全局提交或回滚决议；</li><li>TC 调度 XID 下管辖的全部分支事务完成提交或回滚请求。</li></ul><p><img src="/image/Seata/seata.png"></p><h3 id="Installation-amp-Use"><a href="#Installation-amp-Use" class="headerlink" title="Installation &amp; Use"></a>Installation &amp; Use</h3><h4 id="1-Seata的配置"><a href="#1-Seata的配置" class="headerlink" title="1. Seata的配置"></a>1. Seata的配置</h4><p>解压seata-server安装包到指定目录，修改<code>conf</code>目录下的<code>file.conf</code>配置文件，主要修改自定义事务组名称，事务日志存储模式为<code>db</code>及数据库连接信息</p><figure class="highlight plaintext"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></div></td><td class="code"><pre><code class="hljs Objective-C">service &#123;<br>  #vgroup-&gt;rgroup<br>  vgroup_mapping.fsp_tx_group = &quot;default&quot; #修改事务组名称为：fsp_tx_group，和客户端自定义的名称对应<br>  #only support single node<br>  default.grouplist = &quot;127.0.0.1:8091&quot;<br>  #degrade current not support<br>  enableDegrade = false<br>  #disable<br>  disable = false<br>  #unit ms,s,m,h,d represents milliseconds, seconds, minutes, hours, days, default permanent<br>  max.commit.retry.timeout = &quot;-1&quot;<br>  max.rollback.retry.timeout = &quot;-1&quot;<br>&#125;<br><br>## transaction log store<br>store &#123;<br>  ## store mode: file、db<br>  mode = &quot;db&quot; #修改此处将事务信息存储到数据库中<br><br>  ## database store<br>  db &#123;<br>  ## the implement of javax.sql.DataSource, such as DruidDataSource(druid)/BasicDataSource(dbcp) etc.<br>  datasource = &quot;dbcp&quot;<br>  ## mysql/oracle/h2/oceanbase etc.<br>  db-type = &quot;mysql&quot;<br>  driver-class-name = &quot;com.mysql.jdbc.Driver&quot;<br>  url = &quot;jdbc:mysql://localhost:3306/seat-server&quot; #修改数据库连接地址<br>  user = &quot;root&quot; #修改数据库用户名<br>  password = &quot;root&quot; #修改数据库密码<br>  min-conn = 1<br>  max-conn = 3<br>  global.table = &quot;global_table&quot;<br>  branch.table = &quot;branch_table&quot;<br>  lock-table = &quot;lock_table&quot;<br>  query-limit = 100<br>  &#125;<br>&#125;<br><br></code></pre></td></tr></table></figure><p>修改<code>conf</code>目录下的<code>registry.conf</code>配置文件，指明注册中心为<code>nacos</code>，及修改<code>nacos</code>连接信息即可</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs Objective-C">registry &#123;<br>  # file 、nacos 、eureka、redis、zk、consul、etcd3、sofa<br>  type = &quot;nacos&quot; #改为nacos<br><br>  nacos &#123;<br>  serverAddr = &quot;localhost:8848&quot; #改为nacos的连接地址<br>  namespace = &quot;&quot;<br>  cluster = &quot;default&quot;<br>  &#125;<br>&#125;<br><br></code></pre></td></tr></table></figure><p>先启动Nacos，再使用seata-server中<code>/bin/seata-server.bat</code>文件启动seata-server。</p><h4 id="2-Java如何集成"><a href="#2-Java如何集成" class="headerlink" title="2. Java如何集成"></a>2. Java如何集成</h4><p>为服务创建一个自定义事务组</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">spring:</span><br>  <span class="hljs-attr">cloud:</span><br>  <span class="hljs-attr">alibaba:</span><br>    <span class="hljs-attr">seata:</span><br>    <span class="hljs-attr">tx-service-group:</span> <span class="hljs-string">fsp_tx_group</span> <span class="hljs-comment">#自定义事务组名称需要与seata-server中的对应</span><br><br></code></pre></td></tr></table></figure><p>取消数据源的自动创建</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-meta">@SpringBootApplication(exclude = DataSourceAutoConfiguration.class)</span><br><span class="hljs-meta">@EnableDiscoveryClient</span><br><span class="hljs-meta">@EnableFeignClients</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">SeataOrderServiceApplication</span> &#123;<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">main</span><span class="hljs-params">(String[] args)</span> &#123;<br>        SpringApplication.run(SeataOrderServiceApplication.class, args);<br>    &#125;<br><br>&#125;<br></code></pre></td></tr></table></figure><p>创建配置使用Seata对数据源做代理</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * 使用Seata对数据源进行代理</span><br><span class="hljs-comment"> * Created by macro on 2019/11/11.</span><br><span class="hljs-comment"> */</span><br><span class="hljs-meta">@Configuration</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">DataSourceProxyConfig</span> &#123;<br><br>    <span class="hljs-meta">@Value(&quot;$&#123;mybatis.mapperLocations&#125;&quot;)</span><br>    <span class="hljs-keyword">private</span> String mapperLocations;<br><br>    <span class="hljs-meta">@Bean</span><br>    <span class="hljs-meta">@ConfigurationProperties(prefix = &quot;spring.datasource&quot;)</span><br>    <span class="hljs-keyword">public</span> DataSource <span class="hljs-title function_">druidDataSource</span><span class="hljs-params">()</span>&#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">DruidDataSource</span>();<br>    &#125;<br><br>    <span class="hljs-meta">@Bean</span><br>    <span class="hljs-keyword">public</span> DataSourceProxy <span class="hljs-title function_">dataSourceProxy</span><span class="hljs-params">(DataSource dataSource)</span> &#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">DataSourceProxy</span>(dataSource);<br>    &#125;<br><br>    <span class="hljs-meta">@Bean</span><br>    <span class="hljs-keyword">public</span> SqlSessionFactory <span class="hljs-title function_">sqlSessionFactoryBean</span><span class="hljs-params">(DataSourceProxy dataSourceProxy)</span> <span class="hljs-keyword">throws</span> Exception &#123;<br>        <span class="hljs-type">SqlSessionFactoryBean</span> <span class="hljs-variable">sqlSessionFactoryBean</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">SqlSessionFactoryBean</span>();<br>        sqlSessionFactoryBean.setDataSource(dataSourceProxy);<br>        sqlSessionFactoryBean.setMapperLocations(<span class="hljs-keyword">new</span> <span class="hljs-title class_">PathMatchingResourcePatternResolver</span>()<br>                .getResources(mapperLocations));<br>        sqlSessionFactoryBean.setTransactionFactory(<span class="hljs-keyword">new</span> <span class="hljs-title class_">SpringManagedTransactionFactory</span>());<br>        <span class="hljs-keyword">return</span> sqlSessionFactoryBean.getObject();<br>    &#125;<br><br>&#125;<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Spring Cloud</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Database</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Sentinel</title>
    <link href="/2022/03/28/Spring/Sentinel/"/>
    <url>/2022/03/28/Spring/Sentinel/</url>
    
    <content type="html"><![CDATA[<blockquote><p>随着微服务的流行，服务和服务之间的稳定性变得越来越重要。 Sentinel 以流量为切入点，从流量控制、熔断降级、系统负载保护等多个维度保护服务的稳定性。</p></blockquote><h3 id="Caption"><a href="#Caption" class="headerlink" title="Caption"></a>Caption</h3><ul><li>resource：资源名称；</li><li>limitApp：来源应用；</li><li>grade：阈值类型，0表示线程数，1表示QPS；</li><li>count：单机阈值；</li><li>strategy：流控模式，0表示直接，1表示关联，2表示链路；</li><li>controlBehavior：流控效果，0表示快速失败，1表示Warm Up，2表示排队等待；</li><li>clusterMode：是否集群。</li></ul><p>Sentinel具有如下特性:</p><ul><li>丰富的应用场景：承接了阿里巴巴近 10 年的双十一大促流量的核心场景，例如秒杀，可以实时熔断下游不可用应用；</li><li>完备的实时监控：同时提供实时的监控功能。可以在控制台中看到接入应用的单台机器秒级数据，甚至 500 台以下规模的集群的汇总运行情况；</li><li>广泛的开源生态：提供开箱即用的与其它开源框架&#x2F;库的整合模块，例如与 Spring Cloud、Dubbo、gRPC 的整合；</li><li>完善的 SPI 扩展点：提供简单易用、完善的 SPI 扩展点。您可以通过实现扩展点，快速的定制逻辑。</li></ul><h3 id="实际使用"><a href="#实际使用" class="headerlink" title="实际使用"></a>实际使用</h3><figure class="highlight java"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></div></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * 限流功能</span><br><span class="hljs-comment"> * Created by macro on 2019/11/7.</span><br><span class="hljs-comment"> */</span><br><span class="hljs-meta">@RestController</span><br><span class="hljs-meta">@RequestMapping(&quot;/rateLimit&quot;)</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">RateLimitController</span> &#123;<br><br>  <span class="hljs-comment">/**</span><br><span class="hljs-comment">   * 按资源名称限流，需要指定限流处理逻辑</span><br><span class="hljs-comment">   */</span><br>  <span class="hljs-meta">@GetMapping(&quot;/byResource&quot;)</span><br>  <span class="hljs-meta">@SentinelResource(value = &quot;byResource&quot;,blockHandler = &quot;handleException&quot;)</span><br>  <span class="hljs-keyword">public</span> CommonResult <span class="hljs-title function_">byResource</span><span class="hljs-params">()</span> &#123;<br>    <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">CommonResult</span>(<span class="hljs-string">&quot;按资源名称限流&quot;</span>, <span class="hljs-number">200</span>);<br>  &#125;<br><br>  <span class="hljs-comment">/**</span><br><span class="hljs-comment">   * 按URL限流，有默认的限流处理逻辑</span><br><span class="hljs-comment">   */</span><br>  <span class="hljs-meta">@GetMapping(&quot;/byUrl&quot;)</span><br>  <span class="hljs-meta">@SentinelResource(value = &quot;byUrl&quot;,blockHandler = &quot;handleException&quot;)</span><br>  <span class="hljs-keyword">public</span> CommonResult <span class="hljs-title function_">byUrl</span><span class="hljs-params">()</span> &#123;<br>    <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">CommonResult</span>(<span class="hljs-string">&quot;按url限流&quot;</span>, <span class="hljs-number">200</span>);<br>  &#125;<br><br>  <span class="hljs-keyword">public</span> CommonResult <span class="hljs-title function_">handleException</span><span class="hljs-params">(BlockException exception)</span>&#123;<br>    <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">CommonResult</span>(exception.getClass().getCanonicalName(),<span class="hljs-number">200</span>);<br>  &#125;<br><br>&#125;<br><br></code></pre></td></tr></table></figure><h3 id="Nacos-存储规则"><a href="#Nacos-存储规则" class="headerlink" title="Nacos 存储规则"></a>Nacos 存储规则</h3><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">spring:</span><br>  <span class="hljs-attr">cloud:</span><br>  <span class="hljs-attr">sentinel:</span><br>    <span class="hljs-attr">datasource:</span><br>    <span class="hljs-attr">ds1:</span><br>      <span class="hljs-attr">nacos:</span><br>      <span class="hljs-attr">server-addr:</span> <span class="hljs-string">localhost:8848</span><br>      <span class="hljs-attr">dataId:</span> <span class="hljs-string">$&#123;spring.application.name&#125;-sentinel</span><br>      <span class="hljs-attr">groupId:</span> <span class="hljs-string">DEFAULT_GROUP</span><br>      <span class="hljs-attr">data-type:</span> <span class="hljs-string">json</span><br>      <span class="hljs-attr">rule-type:</span> <span class="hljs-string">flow</span><br><br><br></code></pre></td></tr></table></figure><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">[</span><br>  <span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;resource&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;/rateLimit/byUrl&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;limitApp&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;default&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;grade&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;count&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;strategy&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;controlBehavior&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;clusterMode&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-keyword">false</span><br>  <span class="hljs-punctuation">&#125;</span><br><span class="hljs-punctuation">]</span><br><br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Spring Cloud</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>ShardingJDBC</title>
    <link href="/2022/03/28/Spring/ShardingJDBC/"/>
    <url>/2022/03/28/Spring/ShardingJDBC/</url>
    
    <content type="html"><![CDATA[<h3 id="分片算法"><a href="#分片算法" class="headerlink" title="分片算法"></a><a href="https://shardingsphere.apache.org/document/current/cn/dev-manual/sharding/">分片算法</a></h3><ul><li>精准分片 StandardShardingStrategy</li><li>范围分片 RangeShardingAlgorithm</li><li>行表达式分片 InlineShardingAlgorithm</li><li>复合分片 ComplexShardingStrategy</li><li>Hint分片 HintShardingStrategy</li><li>不分片 NoneShardingStrategy</li></ul><h3 id="如果SQL中没有分片键，但是代码中有怎么办"><a href="#如果SQL中没有分片键，但是代码中有怎么办" class="headerlink" title="如果SQL中没有分片键，但是代码中有怎么办"></a>如果SQL中没有分片键，但是代码中有怎么办</h3><h4 id="动机"><a href="#动机" class="headerlink" title="动机"></a>动机</h4><p>通过解析 SQL 语句提取分片键列与值并进行分片是 Apache ShardingSphere 对 SQL 零侵入的实现方式。若 SQL 语句中没有分片条件，则无法进行分片，需要全路由。</p><p>在一些应用场景中，分片条件并不存在于 SQL，而存在于外部业务逻辑。因此需要提供一种通过外部指定分片结果的方式，在 Apache ShardingSphere 中叫做 Hint。</p><h4 id="机制"><a href="#机制" class="headerlink" title="机制"></a>机制</h4><p>Apache ShardingSphere 使用 <code>ThreadLocal</code> 管理分片键值。可以通过编程的方式向 <code>HintManager</code> 中添加分片条件，该分片条件仅在当前线程内生效。</p><p>除了通过编程的方式使用强制分片路由，Apache ShardingSphere 还计划通过 SQL 中的特殊注释的方式引用 Hint，使开发者可以采用更加透明的方式使用该功能。</p><p>指定了强制分片路由的 SQL 将会无视原有的分片逻辑，直接路由至指定的真实数据节点。</p><h2 id="高可用方案"><a href="#高可用方案" class="headerlink" title="高可用方案"></a>高可用方案</h2><h2 id="主从复制原理"><a href="#主从复制原理" class="headerlink" title="主从复制原理"></a>主从复制原理</h2><h4 id="强制分片路由-Hint"><a href="#强制分片路由-Hint" class="headerlink" title="强制分片路由 Hint"></a>强制分片路由 Hint</h4><figure class="highlight java"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><pre><code class="hljs java"><span class="hljs-type">HintManager</span> <span class="hljs-variable">hintManager</span> <span class="hljs-operator">=</span> HintManager.getInstance() ;<br>hintManager.setMasterRouteOnly();<br></code></pre></td></tr></table></figure><p>比如戒毒系统，更新后需要立即刷新列表。如果采用了主从复制技术的话，可能读取从库会导致暂时性的缺少数据。</p><p>那么我们就可以在更新的方法中添加该代码，代码下方进行更新和查询操作，那么自然就会去读取主库数据。</p><h4 id="等GTID-方案"><a href="#等GTID-方案" class="headerlink" title="等GTID 方案"></a>等GTID 方案</h4><p>MySQL 提供了一条基于 GTID 的命令，用于在从节点上执行，等待从库同步到了对应的 GTID（binlog文件中会包含 GTID），或者超时返回。</p><p>select wait_for_executed_gtid_set(gtid_set, timeout);</p><p>MySQL 在执行完事务后，会将该事务的 GTID 会给客户端，然后客户端可以使用该命令去要执行读操作的从库中执行，等待该 GTID，等待成功后，再执行读操作；如果等待超时，则去主库执行读操作，或者再换一个从库执行上述流程。</p><p>举个例子，原来要执行读操作的 SQL 和添加了前缀的 SQL 如下所示：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">SELECT</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">FROM</span> city; <span class="hljs-keyword">SET</span> <span class="hljs-variable">@maxscale</span>_secret_variable<span class="hljs-operator">=</span>(<span class="hljs-keyword">SELECT</span> <span class="hljs-keyword">CASE</span> <span class="hljs-keyword">WHEN</span> WAIT_FOR_EXECUTED_GTID_SET(<span class="hljs-string">&#x27;232-1-1&#x27;</span>, <span class="hljs-number">10</span>) <span class="hljs-operator">=</span> <span class="hljs-number">0</span> <span class="hljs-keyword">THEN</span> <span class="hljs-number">1</span> <span class="hljs-keyword">ELSE</span> (<span class="hljs-keyword">SELECT</span> <span class="hljs-number">1</span> <span class="hljs-keyword">FROM</span> INFORMATION_SCHEMA.ENGINES) <span class="hljs-keyword">END</span>); <span class="hljs-keyword">SELECT</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">FROM</span> city;<br></code></pre></td></tr></table></figure><p>当 WAIT_FOR_EXECUTED_GTID_SET 执行失败后，原 SQL 就不会再执行，而是将该 SQL 去主节点执行。</p><h4 id="缓存主库查询次数"><a href="#缓存主库查询次数" class="headerlink" title="缓存主库查询次数"></a>缓存主库查询次数</h4><p>概念很简单, 用户新增或修改后, 往Redis中插入一条数据primaryRead:userid为1, 若多次插入, 则进行累加.</p><p>当用户调用查询接口时, 判断用户的查询缓存次数是否存在, 并减一操作后走主库查询. 若不存在或减一后小于0则走从库查询</p>]]></content>
    
    
    <categories>
      
      <category>Spring Cloud</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Database</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Shiro</title>
    <link href="/2022/03/28/Spring/Shiro/"/>
    <url>/2022/03/28/Spring/Shiro/</url>
    
    <content type="html"><![CDATA[<table><thead><tr><th>过滤器简称</th><th>相对应的java类</th></tr></thead><tbody><tr><td>anon</td><td>org.apache.shiro.web.filter.authc.AnonymousFilter</td></tr><tr><td>user</td><td>org.apache.shiro.web.filter.authc.UserFilter</td></tr><tr><td>logout</td><td>org.apache.shiro.web.filter.authc.LogoutFilter</td></tr><tr><td>perms</td><td>org.apache.shiro.web.filter.authz.PermissionsAuthorizationFilter</td></tr><tr><td>authc</td><td>org.apache.shiro.web.filter.authc.FormAuthenticationFilter</td></tr><tr><td>authcBasic</td><td>org.apache.shiro.web.filter.authc.BasicHttpAuthenticationFilter</td></tr><tr><td>port</td><td>org.apache.shiro.web.filter.authz.PortFilter</td></tr><tr><td>rest</td><td>org.apache.shiro.web.filter.authz.HttpMethodPermissionFilter</td></tr><tr><td>roles</td><td>org.apache.shiro.web.filter.authz.RolesAuthorizationFilter</td></tr><tr><td>ssl</td><td>org.apache.shiro.web.filter.authz.SslFilter</td></tr></tbody></table><h2 id="认证"><a href="#认证" class="headerlink" title="认证"></a>认证</h2><h3 id="Session"><a href="#Session" class="headerlink" title="Session"></a>Session</h3><p>从**<code>AbstractShiroFilter</code>**<code>#doFilterInternal</code>进入</p><p><code>DefaultSecurityManager #createSubject</code> 负责返回一个Subject</p><p>内部的<code>#resolveSession</code>方法是获取Session信息, 主要走SessionDao方法获取, 可从缓存或数据库读取, 默认走<code>AbstractSessionDao</code>类, 所以从缓存走</p><p>内部的<code>#resolvePrincipals</code>中从Session获取principals信息, 并在**<code>AbstractShiroFilter</code>**类里进行线程绑定</p><h4 id="创建"><a href="#创建" class="headerlink" title="创建"></a>创建</h4><p>Shiro创建Session交由<code>SessionFactory</code>负责, 我们可以实现该类, 创建一个自定义的Session, 比如有用户的一些属性和操作系统浏览器的属性.</p><p>然后在过滤器触发时, 将登录后的用户信息存入到该Session中</p><h4 id="缓存"><a href="#缓存" class="headerlink" title="缓存"></a>缓存</h4><p>其实在业务上如果需要Redis来管理Session，那么直接继承**<code>AbstractSessionDao</code>**, 该类有3个实现, 但是只有2个是有用的, 一个是cache存取 , 一个是 ConcurrentHashMap存取</p><ul><li>如果只是在单机环境下需要做Session持久化（服务器重启保持Session在线），那么最好继承<code>EnterpriseCacheSessionDAO</code>来增加本地Session缓存以减少I&#x2F;O开销，否则大量的doReadSession()调用会造成I&#x2F;O甚至网络压力（单机环境下能省一点是一点嘛，集群就没办法省了）；</li><li>如果是在集群环境下做Session共享，千万不要继承EnterpriseCacheSessionDAO，会产生服务器间的本地Session缓存不同步问题，直接继承AbstractSessionDAO即可；</li></ul><h4 id="失效"><a href="#失效" class="headerlink" title="失效"></a>失效</h4><p> <strong><code>AbstractShiroFilter</code></strong> <code> #doFilterInternal</code>过滤器每一次会触发更新Session的操作<code>updateSessionLastAccessTime</code>, 最终会触发<code>SessionDao.update()</code>, 将更新后的session存入缓存</p><p>Shiro默认会采用定时线程检测session是否失效, 具体可查看定时器类 <strong><code>ExecutorServiceSessionValidationScheduler</code></strong> 与失效session管理类 <strong><code>AbstractValidatingSessionManager</code></strong> </p><p>研发人员可实现这两个类, 自己实现相关session失效后的业务逻辑</p><h3 id="认证拦截"><a href="#认证拦截" class="headerlink" title="认证拦截"></a>认证拦截</h3><p>从统一入口 <strong><code>OncePerRequestFilter</code></strong> 儿子类 <strong><code>AdviceFilter</code></strong> <code>#doFilterInternal</code>进入, 如果状态为true, 则调用<code>executeChain</code>做后续filter责任链处理, 并可以自定义<code>postHandle</code>方法</p><p>再交由孙子类 <strong><code>PathMatchingFilte</code></strong> <code>#preHandle #isFilterChainContinued </code></p><p>接着孙孙子类 <strong><code>AccessControlFilter</code></strong> <code>#onPreHandle</code> 进行权限认证鉴权</p><p>当访问非anon拦截时, 会交由UserFilter处理认证逻辑, 若认证失败则转到登录页面.</p><p>主要是在<code>filterChainDefinitionMap.put(&quot;/**&quot;, &quot;user,kickout,onlineSession,syncOnlineSession&quot;)</code>配置</p><h2 id="鉴权"><a href="#鉴权" class="headerlink" title="鉴权"></a>鉴权</h2><p>当我们访问带有Shiro权限注释的方法时, 会被<code>AnnotationsAuthorizingMethodInterceptor</code>拦截到, 其内部会通过循环对多个权限注释的handler处理类进行鉴权处理, 如果权限不对, 则报错</p><p>多个handler最终还是会交由<code>AuthorizingSecurityManager</code>来做精细化的权限处理.</p><p>而在更内部则会调用 <strong><code>AuthorizingRealm</code></strong> <code>#getAuthorizationInfo</code>方法, 该方法内部先从Cache获取用户实体, 如果获取不到, 则调用自定义方法从数据库拿</p><h3 id="缓存-1"><a href="#缓存-1" class="headerlink" title="缓存"></a>缓存</h3><p>在鉴权的时候, <strong><code>AuthorizingRealm</code></strong><code>#getAuthorizationInfo</code>会经过缓存</p>]]></content>
    
    
    <categories>
      
      <category>Spring Cloud</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Spring Security Oauth</title>
    <link href="/2022/03/28/Spring/Spring%20Security%20Oauth/"/>
    <url>/2022/03/28/Spring/Spring%20Security%20Oauth/</url>
    
    <content type="html"><![CDATA[<p><a href="/2022/03/28/Spring/Spring%20Security/">Spring Security</a> 是一个强大的可高度定制的认证和授权框架，对于Spring应用来说它是一套Web安全标准。SpringSecurity注重于为Java应用提供认证和授权功能，像所有的Spring项目一样，它对自定义需求具有强大的扩展性。</p><p>如果要做一个认证登录模块, 那么我们就无法绕过JWT的概念. <strong>JWT</strong> 是将用户登录信息存储在了用户电脑中, 而不再是服务器里. 如果项目中用户量庞大. 并且分为电脑端和移动端. 那么 JWT 是必不可少的.</p><p>但是在企业级项目中，我们更倾向于<a href="/2022/03/28/Distributed%20System/Oauth2/">Oauth2</a>的使用。他保证了我们内部系统的登陆认证，也保证了外部系统的访问控制。</p><h2 id="授权模式"><a href="#授权模式" class="headerlink" title="授权模式"></a><strong>授权模式</strong></h2><h3 id="Authorization-Mode"><a href="#Authorization-Mode" class="headerlink" title="Authorization Mode"></a>Authorization Mode</h3><hr><ul><li><strong>Authorization Code</strong><a href="/2022/03/28/Distributed%20System/Oauth2/#授权码">授权码</a>：正宗的OAuth2的授权模式，客户端先将用户导向认证服务器，登录后获取授权码，然后进行授权，最后根据授权码获取访问令牌；</li><li>Implicit (隐式授权模式) ：适用于无应用服务器的项目，和授权码模式相比，取消了获取授权码的过程，直接获取访问令牌；</li><li>**Resource Owner Password Credentials<a href="/2022/03/28/Distributed%20System/Oauth2/#密码式">密码式</a>：客户端直接向用户获取用户名和密码，之后向认证服务器获取访问令牌；</li><li>Client Credentials (客户端模式) ：客户端直接通过客户端认证 (比如client_id和client_secret) 从认证服务器获取访问令牌。</li></ul><h2 id="授权服务配置适配器"><a href="#授权服务配置适配器" class="headerlink" title="授权服务配置适配器"></a><strong>授权服务配置适配器</strong></h2><h3 id="AuthorizationServerConfigurerAdapter"><a href="#AuthorizationServerConfigurerAdapter" class="headerlink" title="AuthorizationServerConfigurerAdapter"></a>AuthorizationServerConfigurerAdapter</h3><hr><ul><li>configure(ClientDetailsServiceConfigurer clients): 配置客户端的授权模式 , 客户端ID , 权限范围 , 权限类型 , token有效期等.</li><li>configure(AuthorizationServerEndpointsConfigurer endpoints): 配置具体的授权模式规则 , 如JWT 密码模式</li></ul><h2 id="过滤器链"><a href="#过滤器链" class="headerlink" title="过滤器链"></a><strong>过滤器链</strong></h2><h3 id="WebSecurityConfigurerAdapter-ResourceServerConfigurerAdapter"><a href="#WebSecurityConfigurerAdapter-ResourceServerConfigurerAdapter" class="headerlink" title="WebSecurityConfigurerAdapter(ResourceServerConfigurerAdapter)"></a>WebSecurityConfigurerAdapter(ResourceServerConfigurerAdapter)</h3><hr><ul><li>WebSecurityConfigurerAdapter 是 Spring security默认情况下的http配置，而 ResourceServerConfigurerAdapter 是Spring security oauth2 默认情况下的http配置。ResourceServerConfigurerAdapter 的优先级更高一些</li><li><strong>同样的资源地址，只会在优先级最高的 ResourceServerConfigurerAdapter 中生效，如果 WebSecurityConfigurerAdapter 也配置了这个资源地址，则不会生效</strong><ul><li>configure(HttpSecurity httpSecurity)：用于配置需要拦截的url路径、jwt过滤器及出异常后的处理器；</li><li>configure(AuthenticationManagerBuilder auth)：用于配置UserDetailsService及PasswordEncoder；</li><li>RestfulAccessDeniedHandler ：当用户没有访问权限时的处理器，用于返回JSON格式的处理结果</li><li>RestAuthenticationEntryPoint ：当未登录或token失效时，返回JSON格式的结果</li><li>UserDetailsService:SpringSecurity定义的核心接口，用于根据用户名获取用户信息，需要自行实现；</li><li>UserDetails：SpringSecurity定义用于封装用户信息的类（主要是用户信息和权限），需要自行实现；</li><li>PasswordEncoder：SpringSecurity定义的用于对密码进行编码及比对的接口，目前使用的是BCryptPasswordEncoder；</li><li>JwtAuthenticationTokenFilter：在用户名和密码校验前添加的过滤器，如果有jwt的token，会自行根据token信息进行登录。</li></ul></li></ul><h2 id="过滤链"><a href="#过滤链" class="headerlink" title="过滤链"></a><strong>过滤链</strong></h2><h3 id="SecurityWebFilterChain"><a href="#SecurityWebFilterChain" class="headerlink" title="SecurityWebFilterChain"></a>SecurityWebFilterChain</h3><hr><ul><li>SpringSecurityFilterChain 作为 SpringSecurity 的核心过滤器链在整个认证授权过程中起着举足轻重的地位，每个请求到来，都会经过该过滤器链</li><li>如果你想自己实现每一个自定义的未授权 , 未认证 , 白名单等策略 , 可以定制该过滤器链</li></ul><h2 id="授权管理器"><a href="#授权管理器" class="headerlink" title="授权管理器"></a><strong>授权管理器</strong></h2><h3 id="ReactiveAuthorizationManager"><a href="#ReactiveAuthorizationManager" class="headerlink" title="ReactiveAuthorizationManager"></a>ReactiveAuthorizationManager</h3><hr><ul><li>WebFlux授权管理器 , 可以当成是拦截器的一种 , 重写方法对授权做自定义处理 , 比如白名单 , 跨域等.</li><li><strong>因为Spring Cloud Gateway使用是基于WebFlux与Netty开发的，所以与传统的Servlet方式不同</strong></li></ul><h2 id="密码式登陆"><a href="#密码式登陆" class="headerlink" title="密码式登陆"></a>密码式登陆</h2><p>Token相关的接口都应该采用Basic base64的请求头，业务相关的接口都应该采用Bearer token的请求头</p><h3 id="认证逻辑"><a href="#认证逻辑" class="headerlink" title="认证逻辑"></a><strong>认证逻辑</strong></h3><figure class="highlight java"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></div></td><td class="code"><pre><code class="hljs Java">**# 在实际的开发中，我们不一定需要Basic的方式来对client进行解密验证方式，这只是pig自己的方式。但是的确蛮好用**<br>**# 请求头是Authorization=Basic base64.encode(client_id:client_secret) **<br><br><span class="hljs-comment">// 用户填写账户密码，发送登录请求，后台登录 API 主动发起获取/oauth/token的请求。</span><br><br><span class="hljs-comment">// 我们可以在中间加入网关拦截，验证base64的解密后格式是否正确</span><br>ValidateCodeGatewayFilter.apply()<br><br><span class="hljs-comment">/**</span><br><span class="hljs-comment">* 过滤器拦住Basic请求</span><br><span class="hljs-comment">* Spring让他默认拦截/oauth/token</span><br><span class="hljs-comment">*/</span><br>BasicAuthenticationFilter&#123;<br>  <span class="hljs-keyword">void</span> <span class="hljs-title function_">doFilterInternal</span><span class="hljs-params">()</span>&#123;<br>    <span class="hljs-comment">// 所以再进入BasicAuthenticationFilter过滤器中，将client_id与client_secret解析，变成UsernamePasswordAuthenticationToken对象</span><br>    <span class="hljs-type">UsernamePasswordAuthenticationToken</span> <span class="hljs-variable">authRequest</span> <span class="hljs-operator">=</span> <span class="hljs-built_in">this</span>.authenticationConverter.convert(request);<br>    <br>    <span class="hljs-comment">// 再通过一系列调用去找数据库存的客户端信息和传入的客户端信息比较，如果client_id或client_secret是错的，就报错。</span><br>    <span class="hljs-type">Authentication</span> <span class="hljs-variable">authResult</span> <span class="hljs-operator">=</span> <span class="hljs-built_in">this</span>.authenticationManager.authenticate(authRequest);<br>    <br>    ProviderManager.authenticate()<br>    →AbstractUserDetailsAuthenticationProvider.authenticate()<br>    →AbstractUserDetailsAuthenticationProvider.retrieveUser()<br>    →DaoAuthenticationProvider.retrieveUser()<br>    →ClientDetailsUserDetailsService.loadUserByUsername()<br>    →配置的PigClientDetailsService.loadClientByClientId()<br>  &#125;<br>&#125;<br><br><span class="hljs-comment">/**</span><br><span class="hljs-comment">* 专门拦截/oauth/token请求</span><br><span class="hljs-comment">*/</span><br>ClientCredentialsTokenEndpointFilter <span class="hljs-keyword">extends</span> <span class="hljs-title class_">AbstractAuthenticationProcessingFilter</span>&#123;<br>  <br>  Authentication <span class="hljs-title function_">attemptAuthentication</span><span class="hljs-params">()</span>&#123;<br>    <span class="hljs-comment">// 根据clientId和clientSecret最终会去查询client信息</span><br>    <span class="hljs-built_in">this</span>.getAuthenticationManager().authenticate(authRequest);<br>    -&gt; DaoAuthenticationProvider.retrieveUser()<br>    -&gt; ClientDetailsUserDetailsService.loadUserByUsername();<br>  &#125;<br>&#125;<br><br><span class="hljs-comment">/**</span><br><span class="hljs-comment">* oauth2.0 token请求接口</span><br><span class="hljs-comment">*/</span><br>TokenEndPoint&#123;<br>  ResponseEntity&lt;OAuth2AccessToken&gt; <span class="hljs-title function_">postAccessToken</span><span class="hljs-params">()</span>&#123;<br>    <span class="hljs-comment">// 获取client信息，验证请求，授权码和密码式都会进来</span><br>    <br>    <span class="hljs-comment">// 做一些验证操作，内部会开始创建OAuth2AccessToken对象</span><br>    <span class="hljs-type">OAuth2AccessToken</span> <span class="hljs-variable">token</span> <span class="hljs-operator">=</span> getTokenGranter().grant(tokenRequest.getGrantType(), tokenRequest);<br>    <br>    AbstractTokenGranter&#123;<br>      OAuth2AccessToken <span class="hljs-title function_">grant</span><span class="hljs-params">()</span>&#123;<br>        <span class="hljs-comment">// 通过 DefaultTokenServices.createAccessToken() 从tokenStore缓存实现PigCustomTokenServices类中创建OAuth2AccessToken对象，还可以用增强器tokenEnhancer加入附加信息，比如用户对象。</span><br>        <span class="hljs-comment">// 存入缓存，返回对象</span><br>        tokenServices.createAccessToken(getOAuth2Authentication(client, tokenRequest))<br>      &#125;<br>    &#125;<br>    <span class="hljs-comment">// 一系列操作结束后，返回给请求方token对象</span><br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="正常访问"><a href="#正常访问" class="headerlink" title="正常访问"></a><strong>正常访问</strong></h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs Java">**# 请求头需要加入Authorization=Bearer token的模式供服务端验证**<br><br>*<span class="hljs-comment">// 网关不做鉴权拦截，只转发，具体的鉴权操作交由对应的业务微服务处理。只要引入Security依赖，并读取Redis中的Token即可*</span><br><br>*<span class="hljs-comment">// 区别于Auth微服务的AuthorizationServerTokenServices(PigCustomTokenServices)</span><br><span class="hljs-comment">// 我们需要一个通用的ResourceServerTokenServices（PigLocalResourceServerTokenServices）来处理当前业务微服务的令牌认证问题*</span><br><br><span class="hljs-comment">/**</span><br><span class="hljs-comment">* 请求被拦截，开始校验并转换成认证对象，给调用链使用</span><br><span class="hljs-comment">* feign调用也进来这，所以我们需要在feign调用的时候，把请求头带上</span><br><span class="hljs-comment">*/</span><br>OAuth2AuthenticationProcessingFilter&#123;<br>  <span class="hljs-keyword">void</span> <span class="hljs-title function_">doFilter</span><span class="hljs-params">()</span>&#123;<br>    <span class="hljs-comment">// 从当前线程中抽取请求头的Token值</span><br>    <span class="hljs-comment">// 这一步在feign调用的时候很正常，用于token传递</span><br>    <span class="hljs-type">Authentication</span> <span class="hljs-variable">authentication</span> <span class="hljs-operator">=</span> tokenExtractor.extract(request);<br>    <span class="hljs-keyword">if</span> (authentication == <span class="hljs-literal">null</span>) &#123;<br>      <span class="hljs-comment">// 输出点日志</span><br>    &#125;<span class="hljs-keyword">else</span> &#123;<br>      <span class="hljs-comment">// 很长的调用，主要是通过token获取认证对象</span><br>      <span class="hljs-type">Authentication</span> <span class="hljs-variable">authResult</span> <span class="hljs-operator">=</span> authenticationManager.authenticate(authentication);<br>      -&gt; OAuth2AuthenticationManager.authenticate(authentication)<br>      -&gt; ResourceServerTokenServices.loadAuthentication(accessToken)<br>      -&gt; PigLocalResourceServerTokenServices(自定义).loadAuthentication(accessToken)<br>      <br>      <span class="hljs-comment">// 存入线程</span><br>      SecurityContextHolder.getContext().setAuthentication(authResult);<br>    &#125;<br>  &#125;<br>&#125;<br><br><span class="hljs-comment">/**</span><br><span class="hljs-comment">* 权限拦截器,方法前拦截</span><br><span class="hljs-comment">*/</span><br>FilterSecurityInterceptor <span class="hljs-keyword">extends</span> <span class="hljs-title class_">AbstractSecurityInterceptor</span>&#123;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="Token续期"><a href="#Token续期" class="headerlink" title="Token续期"></a>Token续期</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs Java">**# 前端可以定时调用/oauth/check_token端点检测Token是否失效过期**<br><br>CheckTokenEndpoint&#123;<br>  checkToken(<span class="hljs-meta">@RequestParam(&quot;token&quot;)</span> String value) &#123;<br>    resourceServerTokenServices.loadAuthentication(token.getValue());<br>  &#125;<br>&#125;<br><br>**# 若即将失效，则刷新令牌/oauth/token?grant_type=refresh_token**<br>**# 如果想要用户请求时对令牌续期，需要在tokenServices#loadAuthentication中进行重写**<br>TokenEndPoint&#123;<br>  ResponseEntity&lt;OAuth2AccessToken&gt; <span class="hljs-title function_">postAccessToken</span><span class="hljs-params">()</span>&#123;<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure><hr><h2 id="授权码登陆"><a href="#授权码登陆" class="headerlink" title="授权码登陆"></a>授权码登陆</h2><h3 id="认证逻辑-1"><a href="#认证逻辑-1" class="headerlink" title="认证逻辑"></a><strong>认证逻辑</strong></h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><code class="hljs Java">**# 如果是内部平台做Oauth2的逻辑，那就先登陆，再跳转到authorize接口**<br><br><span class="hljs-comment">/**</span><br><span class="hljs-comment">* 授权码模式专用授权请求</span><br><span class="hljs-comment">* oauth/authorize?</span><br><span class="hljs-comment">* response_type=code&amp;</span><br><span class="hljs-comment">* client_id=CLIENT_ID&amp;</span><br><span class="hljs-comment">* redirect_uri=CALLBACK_URL&amp;</span><br><span class="hljs-comment">* scope=read</span><br><span class="hljs-comment">*/</span><br><br><span class="hljs-meta">@SessionAttributes</span><br>AuthorizationEndpoint&#123;<br>  <span class="hljs-comment">// 最终返回confirm页面，供用于确认授权</span><br>  <span class="hljs-comment">// 可以自定义该页面</span><br>  ModelAndView <span class="hljs-title function_">authorize</span><span class="hljs-params">(Principal principal)</span>&#123;<br>    <span class="hljs-comment">// 因为类加入了Session注解，所以将model内容存储在了Session中</span><br>    <span class="hljs-comment">// 后续confirm页面提交时，也会拿到这次的内容</span><br>    <span class="hljs-comment">// 如果redis已经存在该clientId+userName的key，则省略confirm确认，直接返回重定向</span><br>  &#125;<br>&#125;<br><br>**# 如果是第三方调用的话，会在访问authorize接口的时候，因未登录被拦截器重定向到登陆页面，先登陆，然后再返回到authorize接口**<br><br><span class="hljs-comment">/**</span><br><span class="hljs-comment">* confirm页面请求通过，并携带了**user_oauth_approval**参数</span><br><span class="hljs-comment">*/</span><br>AuthorizationEndpoint&#123;<br>  <span class="hljs-comment">// 最终返回重定向地址，并拼接code参数传回</span><br>  View <span class="hljs-title function_">approveOrDeny</span><span class="hljs-params">(<span class="hljs-meta">@RequestParam</span> Map&lt;String, String&gt; approvalParameters, Map&lt;String, ?&gt; model, Principal principal)</span>&#123;<br>    <span class="hljs-comment">// 获取从authorize方法存储进session的内容</span><br>    <span class="hljs-comment">// 进行一系列验证后，返回重定向地址+code</span><br>    <span class="hljs-comment">// code默认放进ConcurrentHashMap里面，只要不用，就会一直存在</span><br>  &#125;<br>&#125;<br><br><span class="hljs-comment">/**</span><br><span class="hljs-comment">* 专门拦截/oauth/token请求</span><br><span class="hljs-comment">*/</span><br>ClientCredentialsTokenEndpointFilter <span class="hljs-keyword">extends</span> <span class="hljs-title class_">AbstractAuthenticationProcessingFilter</span>&#123;<br>  <br>  Authentication <span class="hljs-title function_">attemptAuthentication</span><span class="hljs-params">()</span>&#123;<br>    <span class="hljs-comment">// 根据clientId和clientSecret最终会去查询client信息</span><br>    <span class="hljs-built_in">this</span>.getAuthenticationManager().authenticate(authRequest);<br>    -&gt; DaoAuthenticationProvider.retrieveUser()<br>    -&gt; ClientDetailsUserDetailsService.loadUserByUsername(username);<br>    -&gt; ClientDetailsService.loadClientByClientId(username);<br>  &#125;<br>&#125;<br><br><span class="hljs-comment">/**</span><br><span class="hljs-comment">* oauth/token?</span><br><span class="hljs-comment">* client_id=CLIENT_ID&amp;</span><br><span class="hljs-comment">* client_secret=CLIENT_SECRET&amp;</span><br><span class="hljs-comment">* grant_type=authorization_code&amp;</span><br><span class="hljs-comment">* code=AUTHORIZATION_CODE&amp;</span><br><span class="hljs-comment">* redirect_uri=CALLBACK_URL</span><br><span class="hljs-comment">*/</span><br>TokenEndPoint&#123;<br><br>  ResponseEntity&lt;OAuth2AccessToken&gt; <span class="hljs-title function_">postAccessToken</span><span class="hljs-params">()</span>&#123;<br>    <span class="hljs-type">OAuth2AccessToken</span> <span class="hljs-variable">token</span> <span class="hljs-operator">=</span> getTokenGranter().grant(tokenRequest.getGrantType(), tokenRequest);<br>    -&gt; AuthorizationServerEndpointsConfigurer.grant()<br>    -&gt; CompositeTokenGranter.grant()<br>    <span class="hljs-comment">// 删除之前的code并返回对应的认证对象，与token值绑定</span><br>    -&gt; AuthorizationCodeTokenGranter.grant().getOAuth2Authentication(client, tokenRequest)<br>    <span class="hljs-comment">// 令牌增强器也在这</span><br>    -&gt; PigCustomTokenServices.createAccessToken(oAuth2Authentication)<br>    <span class="hljs-comment">// 一系列操作结束后，返回给请求方token对象</span><br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="正常访问-1"><a href="#正常访问-1" class="headerlink" title="正常访问"></a>正常访问</h3><p>与密码式相同</p><h3 id="Token失效"><a href="#Token失效" class="headerlink" title="Token失效"></a>Token失效</h3><p>与密码式相同</p><hr><h2 id="SSO"><a href="#SSO" class="headerlink" title="SSO"></a>SSO</h2><p><a href="/2022/03/28/Distributed%20System/SSO%E5%8D%95%E7%82%B9%E7%99%BB%E5%BD%95/">SSO单点登录</a></p><p>以Pig项目为例，Auth服务配置了「Spring Security」「Spring Security Oauth2密码模式」「Spring Security Oauth2授权码模式」三种认证方式。</p><p>简单的Spring Security配置是为了在SSO单点登录时与Session结合，让Oauth2授权码模式能够记住登录状态。</p><p>Spring Security Oauth2密码模式是为了给项目内微服务认证使用。</p><hr><h2 id="拓展相关🌟🌟"><a href="#拓展相关🌟🌟" class="headerlink" title="拓展相关🌟🌟"></a>拓展相关🌟🌟</h2><h3 id="BearerTokenExtractor"><a href="#BearerTokenExtractor" class="headerlink" title="BearerTokenExtractor"></a>BearerTokenExtractor</h3><p>该类是通过<code>OAuth2AuthenticationProcessingFilter</code>过滤器默认调用，专门处理用户访问请求，剥离Header中的<code>access_token</code>来确认用户令牌。我们可以实现该类，采用别的名称来替换<code>access_token</code>。比如掘金的就是<code>X-Legacy-Token</code>而非必须是 <code>Authorization</code></p><p>也可以参考pig项目，增加注解AOP实现，对部分接口实现白名单策略，分别解决外部访问以及feign调用的问题。</p><p>Inner注解的使用 <a href="https://www.yuque.com/pig4cloud/pig/hz5ppn">https://www.yuque.com/pig4cloud/pig/hz5ppn</a></p><h3 id="OAuth2FeignRequestInterceptor"><a href="#OAuth2FeignRequestInterceptor" class="headerlink" title="OAuth2FeignRequestInterceptor"></a>OAuth2FeignRequestInterceptor</h3><p>是为了解决Spring服务中Feign调用时，无法将Token通过Header传递给下游服务的问题。</p><p>该类需要程序员实现子类，在Feign调用前从线程中获取authentication对象并传递给父类做内部持有。主要方法是<code>accessTokenContextRelay.copyToken()</code>。</p><p>然后<code>OAuth2FeignRequestInterceptor</code>会根据内部持有的对象对下游服务发起携带Header的请求。下游服务可以从Header中获取Token值，并转换为authentication对象。</p><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p>Oauth2.0的数据库说明 <a href="https://andaily.com/spring-oauth-server/db_table_description.html">https://andaily.com/spring-oauth-server/db_table_description.html</a></p><p>Spring Oauth流程说明 <a href="https://www.yuque.com/pig4cloud/pig/dqnyuc">https://www.yuque.com/pig4cloud/pig/dqnyuc</a></p><p>分布式系统下的认证与授权 <a href="https://www.bmpi.dev/dev/authentication-and-authorization-in-a-distributed-system/">https://www.bmpi.dev/dev/authentication-and-authorization-in-a-distributed-system/</a></p><hr>]]></content>
    
    
    <categories>
      
      <category>Spring Cloud</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Spring Security</title>
    <link href="/2022/03/28/Spring/Spring%20Security/"/>
    <url>/2022/03/28/Spring/Spring%20Security/</url>
    
    <content type="html"><![CDATA[<h2 id="Session"><a href="#Session" class="headerlink" title="Session"></a>Session</h2><h3 id="创建"><a href="#创建" class="headerlink" title="创建"></a>创建</h3><p>Spring Security没有像Shiro一样，创建一个自己掌控的Session出来， 而是默认交由Tomcat处理。虽然Security没有自己创建，但是给了我们可以实现的<code>SessionRegistry</code>，以及用于管理用户和Session的<code>SessionInformation</code></p><p><code>SessionManagementFilter</code>是专门用于管理Session状态的，如检测用户并发Session，失效Session的逻辑处理等</p><ul><li>expiredUrl：是用户并发会话过多，被挤下线后的重定向地址。</li><li>invalidSessionUrl：Session超时的重定向地址</li></ul><h3 id="缓存"><a href="#缓存" class="headerlink" title="缓存"></a>缓存</h3><p>spring-session-data-redis依赖, 将Session进行分布式缓存</p><h3 id="失效"><a href="#失效" class="headerlink" title="失效"></a>失效</h3><p>Spring Security采用了事件广播在Session失效时，删除了对应的<code>SessionInformation</code>，我们可以在**<code>SessionRegistryImpl</code>**<code>#onApplicationEvent</code>进行深入的研究</p><h3 id="登陆认证"><a href="#登陆认证" class="headerlink" title="登陆认证"></a>登陆认证</h3><figure class="highlight java"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></div></td><td class="code"><pre><code class="hljs Java"><span class="hljs-comment">/**</span><br><span class="hljs-comment">* 用户登录后, 交由 AbstractAuthenticationProcessingFilter 过滤器检测是否为登录地址</span><br><span class="hljs-comment">*/</span><br>AbstractAuthenticationProcessingFilter&#123;<br>  <span class="hljs-keyword">void</span> <span class="hljs-title function_">doFilter</span><span class="hljs-params">(ServletRequest req, ServletResponse res, FilterChain chain)</span> <span class="hljs-keyword">throws</span> IOException, ServletException &#123;<br>    <span class="hljs-comment">// 判断是否是配置好的验证登录请求</span><br>    <span class="hljs-keyword">if</span> (!<span class="hljs-built_in">this</span>.requiresAuthentication(request, response)) &#123;<br>      chain.doFilter(request, response);<br>    &#125; <span class="hljs-keyword">else</span> &#123;<br>      <span class="hljs-comment">// 尝试身份验证</span><br>      authResult = <span class="hljs-built_in">this</span>.attemptAuthentication(request, response);<br>    &#125;<br>  &#125;<br>  <br>&#125;<br><br><span class="hljs-comment">/**</span><br><span class="hljs-comment">* 确定后默认再由 UsernamePasswordAuthenticationFilter进行用户获取认证</span><br><span class="hljs-comment">*/</span><br>UsernamePasswordAuthenticationFilter&#123;<br>  Authentication <span class="hljs-title function_">attemptAuthentication</span><span class="hljs-params">(HttpServletRequest request, HttpServletResponse response)</span> <span class="hljs-keyword">throws</span> AuthenticationException &#123;<br>    <span class="hljs-keyword">return</span> <span class="hljs-built_in">this</span>.getAuthenticationManager().authenticate(authRequest);<br>  &#125;<br>  <br>  <span class="hljs-comment">// 然后 AbstractUserDetailsAuthenticationProvider#authenticate </span><br>  <span class="hljs-comment">// 会通过username和生成的Authentication对象生成一个UserDetails对象，并检查用户是否存在</span><br>  Authentication <span class="hljs-title function_">authenticate</span><span class="hljs-params">(Authentication authentication)</span> <span class="hljs-keyword">throws</span> AuthenticationException &#123;<br>    <span class="hljs-type">String</span> <span class="hljs-variable">username</span> <span class="hljs-operator">=</span> authentication.getPrincipal() == <span class="hljs-literal">null</span> ? <span class="hljs-string">&quot;NONE_PROVIDED&quot;</span> : authentication.getName();<br>    <span class="hljs-comment">// 去找缓存, 可以通过ehcache实现该类, 默认是NullUserCache空实现</span><br>    <span class="hljs-type">UserDetails</span> <span class="hljs-variable">user</span> <span class="hljs-operator">=</span> <span class="hljs-built_in">this</span>.userCache.getUserFromCache(username);<br>    <span class="hljs-keyword">if</span>(user == <span class="hljs-literal">null</span>)&#123;<br>      <span class="hljs-comment">// 没有缓存, 则通过DetailService的实现类去数据库查询, 也可以从缓存走</span><br>      user = <span class="hljs-built_in">this</span>.retrieveUser(username, (UsernamePasswordAuthenticationToken)authentication)&#123;<br>        <span class="hljs-type">UserDetails</span> <span class="hljs-variable">loadedUser</span> <span class="hljs-operator">=</span> <span class="hljs-built_in">this</span>.getUserDetailsService().loadUserByUsername(username);<br>        <span class="hljs-keyword">return</span> loadedUser;<br>      &#125;<br>    &#125;<br>  &#125;<br>&#125;<br><br></code></pre></td></tr></table></figure><h3 id="正常访问"><a href="#正常访问" class="headerlink" title="正常访问"></a>正常访问</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><code class="hljs Java"><span class="hljs-comment">/**</span><br><span class="hljs-comment">* 过滤器链的第二位</span><br><span class="hljs-comment">*/</span><br>SecurityContextPersistenceFilter&#123;<br><br>  <span class="hljs-keyword">void</span> <span class="hljs-title function_">doFilter</span><span class="hljs-params">()</span>&#123;<br>    <span class="hljs-comment">// 获取session中的用户信息</span><br>    <span class="hljs-type">HttpSession</span> <span class="hljs-variable">session</span> <span class="hljs-operator">=</span> request.getSession();<br>    <span class="hljs-type">HttpRequestResponseHolder</span> <span class="hljs-variable">holder</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">HttpRequestResponseHolder</span>(request, response);<br>    <span class="hljs-type">SecurityContext</span> <span class="hljs-variable">contextBeforeChainExecution</span> <span class="hljs-operator">=</span> <span class="hljs-built_in">this</span>.repo.loadContext(holder);<br>    <span class="hljs-comment">// 存入当前线程</span><br>    SecurityContextHolder.setContext(contextBeforeChainExecution);<br>  &#125;<br>&#125;<br><br><span class="hljs-comment">/**</span><br><span class="hljs-comment">* 异常过滤器</span><br><span class="hljs-comment">*/</span><br>ExceptionTranslationFilter&#123;<br>  <span class="hljs-keyword">void</span> <span class="hljs-title function_">doFilter</span><span class="hljs-params">()</span>&#123;<br>    <span class="hljs-comment">// 后置过滤器，最终会走到FilterSecurityInterceptor</span><br>    <span class="hljs-keyword">try</span> &#123;<br>      chain.doFilter(request, response);<br>    &#125;<br>    <span class="hljs-keyword">catch</span> (Exception ex) &#123;<br>      <span class="hljs-comment">// 执行exceptionEntrypoint</span><br>      handleSpringSecurityException(request, response, chain, securityException);<br>    &#125;<br>  &#125;<br>&#125;<br><br><span class="hljs-comment">/**</span><br><span class="hljs-comment">* 权限拦截器,方法前拦截</span><br><span class="hljs-comment">*/</span><br>FilterSecurityInterceptor <span class="hljs-keyword">extends</span> <span class="hljs-title class_">AbstractSecurityInterceptor</span>&#123;<br>  <br>  <span class="hljs-keyword">void</span> <span class="hljs-title function_">invoke</span><span class="hljs-params">()</span>&#123;<br>    <span class="hljs-comment">// 前置, 检测访问请求是否是白名单，获取线程内认证对象并做权限校验，如@PreAuthorize</span><br>    <span class="hljs-built_in">super</span>.beforeInvocation(filterInvocation);<br>    <span class="hljs-keyword">try</span> &#123;<br>      <span class="hljs-comment">// </span><br>      filterInvocation.getChain().doFilter(filterInvocation.getRequest(), filterInvocation.getResponse());<br>    &#125;<br>    <span class="hljs-keyword">finally</span> &#123;<br>      <span class="hljs-comment">// 后置</span><br>      <span class="hljs-built_in">super</span>.finallyInvocation(token);<br>    &#125;<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="用户缓存"><a href="#用户缓存" class="headerlink" title="用户缓存"></a>用户缓存</h3><p><code>UserCache</code> 允许配置Ehcache缓存, 用于缓存 <code>UserDetails</code> 对象 , 在  CachingUserDetailsService 类中获取用户实体</p><p>感觉没啥用, 敲了断点发现只有登录的时候能用上该缓存.</p><h2 id="鉴权管理"><a href="#鉴权管理" class="headerlink" title="鉴权管理"></a>鉴权管理</h2><hr><p>spring security的认证与鉴权过滤器都在<code>AbstractSecurityInterceptor</code>拦截器中. 其中鉴权部分交由<code>AbstractAccessDecisionManager</code>实现, 采用了投票机制进行鉴权.默认有三个实现类</p><ul><li><strong>AffirmativeBased(默认)</strong> : 只要任一 AccessDecisionVoter 返回肯定的结果，便授予访问权限</li><li>UnanimousBased : 只要任一 AccessDecisionVoter 返回失败的结果，便全体失败</li><li>ConsensusBased : 少数服从多数授权访问决策方案</li></ul><h2 id="常用配置"><a href="#常用配置" class="headerlink" title="常用配置"></a>常用配置</h2><hr><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><code class="hljs Java">http<br>  <span class="hljs-comment">// 跨域</span><br>  .cors(AbstractHttpConfigurer::disable)<br>  <span class="hljs-comment">// csrf攻击</span><br>  .csrf(AbstractHttpConfigurer::disable)<br>  <span class="hljs-comment">// 完全放开frame页面</span><br>  .headers(h -&gt; h.frameOptions().disable())<br>  <span class="hljs-comment">// 异常处理配置 ExceptionTranslationFilter</span><br>  <span class="hljs-comment">// 在过滤器</span><br>  .exceptionHandling(<br>          <span class="hljs-comment">// 用来解决匿名用户访问无权限资源时的异常</span><br>          e-&gt;e.authenticationEntryPoint(customAuthenticationEntryPoint)<br>          <span class="hljs-comment">// 用来解决认证过的用户访问无权限资源时的异常</span><br>                  .accessDeniedHandler(customAccessDeniedHandler)<br>  <span class="hljs-comment">// session管理器</span><br>  ).sessionManagement(<br>  <span class="hljs-comment">// 同一用户最大允许同时存在几个</span><br>  s-&gt;s.maximumSessions(<span class="hljs-number">10</span>)<br>          <span class="hljs-comment">// 管理所有用户登录的session</span><br>          .sessionRegistry(sessionRegistry())<br>          <span class="hljs-comment">// session失效处理</span><br>          .expiredSessionStrategy(ssoSessionInformationExpiredStrategy)<br>  <span class="hljs-comment">// 认证请求拦截策略, 以下都不拦截处理，但是会走过滤器</span><br>  <span class="hljs-comment">// web.ignore的不拦截处理，是不走过滤器的，一般用于静态资源文件</span><br>).authorizeRequests(<br>  a-&gt; a.antMatchers(<span class="hljs-string">&quot;/sso/*&quot;</span>,<span class="hljs-string">&quot;/logout&quot;</span>)<br>          .permitAll().anyRequest().authenticated()<br>  <span class="hljs-comment">// 登陆失败的处理</span><br>).failureHandler(authenticationFailureHandler())<br>  <span class="hljs-comment">// 退出登陆成功处理</span><br>.logoutSuccessHandler(logoutSuccessHandler())<br>  <span class="hljs-comment">// 登录页面地址</span><br>.formLogin(<br>  f-&gt;f.loginPage(accessTokenUri)<br>        <span class="hljs-comment">// 可以不配置,表示登录提交的地址,用于校验后端登录的url</span><br>        .loginProcessingUrl(<span class="hljs-string">&quot;/login&quot;</span>)<br>          <span class="hljs-comment">// 登录成功后回调</span><br>          .successHandler(customAuthenticationSuccessHandler)<br><span class="hljs-comment">// 在userfilter前执行validateFilter</span><br>).addFilterBefore(validateCodeFilter, UsernamePasswordAuthenticationFilter.class)<br><span class="hljs-comment">// 在validateFilter前执行decryptFilter</span><br>.addFilterBefore(decryptParameterFilter, ValidateCodeFilter.class)<br>.apply(ssoAuthenticationSecurityConfig);<br><br><span class="hljs-comment">//禁用session管理</span><br>http.sessionManagement().sessionCreationPolicy(SessionCreationPolicy.STATELESS);<br><br><span class="hljs-comment">/**</span><br><span class="hljs-comment">* ssoAuthenticationSecurityConfig extends SecurityConfigurerAdapter</span><br><span class="hljs-comment">* 可以在CAS中配置业务认证逻辑</span><br><span class="hljs-comment">*/</span><br><br># **基于配置好的路径来进行认证的过滤器 AbstractAuthenticationProcessingFilter**<br><span class="hljs-comment">// 子类实现attemptAuthentication()来做逻辑处理</span><br><span class="hljs-comment">// 交由下面的AuthenticationManager来做认证处理</span><br><br><span class="hljs-comment">// 但是该抽象类中doFilter方法里有this.requiresAuthentication的调用, 里面是AntPathRequestMatcher类</span><br><span class="hljs-comment">// 该类默认记载了/login的url, 表示只有当用户请求地址与之相同时, 才会走下面的认证逻辑, 否则都会交由其他过滤器解决.</span><br><span class="hljs-comment">// 所以我们可以在子类构造中, 重写该地址, 将登陆后的请求地址放进去.*</span><br>AbstractAuthenticationProcessingFilter filter<br><br><span class="hljs-comment">// 用于处理身份验证的核心逻辑, 在CAS中可以根据authentication参数判断有没有被CAS中心认证过</span><br><span class="hljs-comment">// 最终需要返回认证对象</span><br>filter.setAuthenticationManager(providerManager);<br><span class="hljs-comment">// 认证成功后,Security会发布消息,用户可以订阅实现记录成功信息</span><br>providerManager.setAuthenticationEventPublisher();<br><span class="hljs-comment">// 业务模块认证通过后,可以根据savedRequest做跳转之类的</span><br>filter.setAuthenticationSuccessHandler(customAuthenticationSuccessHandler)<br></code></pre></td></tr></table></figure><h2 id="JWT无状态"><a href="#JWT无状态" class="headerlink" title="JWT无状态"></a>JWT无状态</h2><p>在认证的过程中，Spring Security会运行一个过滤器<code>SecurityContextPersistenceFilter</code>来存储请求的Security Context，这个上下文的存储是一个策略模式，但默认的是保存在HTTP Session中的<code>HttpSessionSecurityContextRepository</code>。现在我们设置了 create-session&#x3D;”stateless”，就会保存在<code>NullSecurityContextRepository</code>，里面没有任何session在上下文中保持。</p><p>既然没有为何还要调用这个空的filter？因为需要调用这个filter来保证每次请求完了<code>SecurityContextHolder</code>被清空了，下一次请求必须<strong>re-authentication</strong>。</p><h3 id="登录认证"><a href="#登录认证" class="headerlink" title="登录认证"></a>登录认证</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs Java"><span class="hljs-number">1.</span> 可以继承UsernamePasswordAuthenticationFilter类，去通过UserDetailService获取用户。<br><br><span class="hljs-number">2.</span> 登录校验成功后由配置好的 http.successHandler(JwtLoginSuccessHandler)来返回Token给前端。<br></code></pre></td></tr></table></figure><h3 id="正常访问-1"><a href="#正常访问-1" class="headerlink" title="正常访问"></a>正常访问</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs Java"><br><span class="hljs-comment">// 禁用session管理</span><br><span class="hljs-comment">// 跳过 HttpSessionSecurityContextRepository, SessionManagementFilter, RequestCacheFilter. </span><br>http.sessionManagement().sessionCreationPolicy(SessionCreationPolicy.STATELESS);<br><span class="hljs-comment">// 百度方法一般是继承该类</span><br><span class="hljs-comment">// 也有继承OncePerRequestFilter类的</span><br>JwtAuthorizationFilter <span class="hljs-keyword">extends</span> <span class="hljs-title class_">BasicAuthenticationFilter</span><br><span class="hljs-comment">// 然后通过配置加入该过滤器</span><br>http.addFilter(<span class="hljs-keyword">new</span> <span class="hljs-title class_">JwtAuthorizationFilter</span>(authenticationManager()));<br><br></code></pre></td></tr></table></figure><h2 id="认证入口点AuthenticationEntryPoint"><a href="#认证入口点AuthenticationEntryPoint" class="headerlink" title="认证入口点AuthenticationEntryPoint"></a>认证入口点AuthenticationEntryPoint</h2><hr><ul><li>它在用户请求处理过程中遇到认证异常时，被<code>ExceptionTranslationFilter</code>或者<code>AuthenticationFailureHandler</code>用于开启特定认证方案的认证流程。<ul><li><code>Http403ForbiddenEntryPoint</code>: 设置响应状态字为403,并非触发一个真正的认证流程。通常在一个预验证(pre-authenticated authentication)已经得出结论需要拒绝用户请求的情况被用于拒绝用户请求。</li><li><code>HttpStatusEntryPoint</code>: 设置特定的响应状态字，并非触发一个真正的认证流程。</li><li><code>LoginUrlAuthenticationEntryPoint</code>: 根据配置计算出登录页面url,将用户重定向到该登录页面从而开始一个认证流程。</li><li><code>BasicAuthenticationEntryPoint</code>: 对应标准Http Basic认证流程的触发动作，向响应写入状态字401和头部WWW-Authenticate:”Basic realm&#x3D;”xxx”触发标准Http Basic认证流程。</li><li><code>DigestAuthenticationEntryPoint</code>: 对应标准Http Digest认证流程的触发动作，向响应写入状态字401和头部WWW-Authenticate:”Digest realm&#x3D;”xxx”触发标准Http Digest认证流程。</li><li><code>DelegatingAuthenticationEntryPoint</code>: 这是一个代理，将认证任务委托给所代理的多个AuthenticationEntryPoint对象，其中一个被标记为缺省AuthenticationEntryPoint。</li></ul></li></ul><h2 id="用户实体UserDetailService"><a href="#用户实体UserDetailService" class="headerlink" title="用户实体UserDetailService"></a><strong>用户实体UserDetailService</strong></h2><hr><ul><li>Spring Security中进行身份验证的是 AuthenticationManager 接口，ProviderManager 是它的一个默认实现，但它并不用来处理身份认证，而是委托给配置好的 AuthenticationProvider ，每个 AuthenticationProvider 会轮流检查身份认证。检查后或者返回 Authentication 对象或者抛出异常。</li><li>loadUserByUsername：通过用户名获取一个真实用户，返回一个 UserDetails 的实现类</li><li>密码验证由 AuthenticationProvider 的 DaoAuthenticationProvider#additionalAuthenticationChecks 处理，也可以自己定义</li><li>UserDetail目前发现仅在登录时与Authentication做比较操作, 除此以外无他用</li></ul>]]></content>
    
    
    <categories>
      
      <category>Spring Cloud</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Zipkin Sleuth</title>
    <link href="/2022/03/28/Spring/Zipkin%20Sleuth/"/>
    <url>/2022/03/28/Spring/Zipkin%20Sleuth/</url>
    
    <content type="html"><![CDATA[<blockquote><p>Spring Cloud Sleuth 是分布式系统中跟踪服务间调用的工具，它可以直观地展示出一次请求的调用过程，本文将对其用法进行详细介绍。</p></blockquote><h3 id="Zipkin"><a href="#Zipkin" class="headerlink" title="Zipkin"></a>Zipkin</h3><p>Zipkin是Twitter的一个开源项目，可以用来获取和分析Spring Cloud Sleuth 中产生的请求链路跟踪日志，它提供了Web界面来帮助我们直观地查看请求链路跟踪信息。</p><p>Zipkin是一个单独的服务，Spring项目引入依赖后，再下载Zipkin的jar后启动。</p><p>Zipkin默认记录只是存储在内存中，Zipkin关闭则全部丢失。</p><ul><li>在user-service和ribbon-service中添加相关依赖：</li></ul><figure class="highlight xml"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></div></td><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.springframework.cloud<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>spring-cloud-starter-zipkin<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br></code></pre></td></tr></table></figure><ul><li>修改application.yml文件，配置收集日志的zipkin-server访问地址：</li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">spring:</span><br>  <span class="hljs-attr">zipkin:</span><br>    <span class="hljs-attr">base-url:</span> <span class="hljs-string">http://localhost:9411</span><br>  <span class="hljs-attr">sleuth:</span><br>    <span class="hljs-attr">sampler:</span><br>      <span class="hljs-attr">probability:</span> <span class="hljs-number">0.1</span> <span class="hljs-comment">#设置Sleuth的抽样收集概率</span><br></code></pre></td></tr></table></figure><h3 id="ElasticSearch存储"><a href="#ElasticSearch存储" class="headerlink" title="ElasticSearch存储"></a>ElasticSearch存储</h3><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs PowerShell"><span class="hljs-comment"># STORAGE_TYPE：表示存储类型 ES_HOSTS：表示ES的访问地址</span><br>java <span class="hljs-literal">-jar</span> zipkin<span class="hljs-literal">-server-2</span>.<span class="hljs-number">12.9</span><span class="hljs-literal">-exec</span>.jar <span class="hljs-literal">--STORAGE_TYPE</span>=elasticsearch <span class="hljs-literal">--ES_HOSTS</span>=localhost:<span class="hljs-number">9200</span> <br></code></pre></td></tr></table></figure><h3 id="Used-Config"><a href="#Used-Config" class="headerlink" title="Used Config"></a>Used Config</h3><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs CSS"><span class="hljs-number">1</span>、使用rabbitmq+elasticsearch的启动方式<br><br>java -jar zipkin<span class="hljs-selector-class">.jar</span> <span class="hljs-attr">--zipkin</span><span class="hljs-selector-class">.collector</span><span class="hljs-selector-class">.rabbitmq</span><span class="hljs-selector-class">.addresses</span>=<span class="hljs-number">62.234</span>.<span class="hljs-number">66.186</span> <span class="hljs-attr">--zipkin</span><span class="hljs-selector-class">.collector</span><span class="hljs-selector-class">.rabbitmq</span><span class="hljs-selector-class">.username</span>=root <span class="hljs-attr">--zipkin</span><span class="hljs-selector-class">.collector</span><span class="hljs-selector-class">.rabbitmq</span><span class="hljs-selector-class">.password</span>=<span class="hljs-number">123456</span> <span class="hljs-attr">--zipkin</span><span class="hljs-selector-class">.storage</span><span class="hljs-selector-class">.type</span>=elasticsearch <span class="hljs-attr">--zipkin</span><span class="hljs-selector-class">.storage</span><span class="hljs-selector-class">.elasticsearch</span><span class="hljs-selector-class">.host</span>=http://<span class="hljs-number">62.234</span>.<span class="hljs-number">66.186</span>:<span class="hljs-number">9200</span> --zipkin.storage.elasticsearch.http-logging=BASIC<br><br><span class="hljs-number">2</span>、使用rabbitmq+mysql启动方式<br><br>java -jar zipkin.jar --zipkin.collector.rabbitmq.addresses=<span class="hljs-number">62.234</span>.<span class="hljs-number">66.186</span> --zipkin.collector.rabbitmq.username=root --zipkin.collector.rabbitmq.password=<span class="hljs-number">123456</span> --zipkin.storage.type=mysql --zipkin.storage.mysql.host=<span class="hljs-number">62.234</span>.<span class="hljs-number">66.186</span> --zipkin.storage.mysql.port=<span class="hljs-number">3306</span> --zipkin.storage.mysql.username=root --zipkin.storage.mysql.password=root --zipkin.storage.mysql.db=psych<br><br><span class="hljs-number">3</span>、使用activemq+mysql启动方式<br><br>java -jar zipkin.jar --zipkin.collector.activemq.url=tcp://<span class="hljs-number">62.234</span>.<span class="hljs-number">66.186</span>:<span class="hljs-number">61616</span> --zipkin.collector.activemq.username=admin --zipkin.collector.activemq.password=admin --zipkin.storage.type=mysql --zipkin.storage.mysql.host=<span class="hljs-number">62.234</span>.<span class="hljs-number">66.186</span> --zipkin.storage.mysql.port=<span class="hljs-number">3306</span> --zipkin.storage.mysql.username=root --zipkin.storage.mysql.password=root --zipkin.storage.mysql.db=psych<br><br><span class="hljs-number">4</span>、使用activemq+elasticsearch方式雷同，只需要将数据源改为elasticsearch即可<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Spring Cloud</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/2022/03/28/hello-world/"/>
    <url>/2022/03/28/hello-world/</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><pre><code class="hljs bash">$ hexo new <span class="hljs-string">&quot;My New Post&quot;</span><br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo server<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo generate<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo deploy<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>MapReduce</title>
    <link href="/2022/03/27/Paper/MapReduce/"/>
    <url>/2022/03/27/Paper/MapReduce/</url>
    
    <content type="html"><![CDATA[<p>MapReduce: Simplified Data Processing on Large Clusters</p><span id="more"></span><p><a href="https://www.cnblogs.com/YaoDD/p/6017397.html">原始翻译版本网址：《MapReduce: Simplified Data Processing on Large Cluster 2004》翻译</a></p><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>MapReduce 是一种编程模型和一种用来处理和产生大数据集的相关实现。用户定义 map 函数（map function）来处理 key&#x2F;value 键值对来产生一系列的中间的 key&#x2F;value 键值对。还要定义一个 reduce 函数(reduce function)用来合并有着相同中间 key 值的中间 value。许多现实世界中的任务都可以用这种模型来表达，就像下文所展示的那样。</p><p>用这个风格（函数式）编写的程序可以自动并行地在大规模集群上工作。运行时系统会自动处理例如切割输入数据，在机器之间调度程序的执行，处理机器故障以及管理必要的机器间通信等细节问题。这可以让那些对于并行分布式系统<strong>没有任何经验</strong>的程序员也能<strong>很简单</strong>地利用起一个大的分布式系统的资源。</p><p>我们的 MapReduce 的实现运行在一个由大的商业机构成的集群当中并且是高度可扩展的：一个典型的 MapReduce 计算要在上千台机器中处理 TB 数量级的数据。程序员会觉得这个系统非常好用：已经有成千上万的 MapReduce 程序被实现出来并且每天有上千个 MapReduce 任务运行在 Google 的集群上。</p><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>在过去五年中，作者和许多 Google 的其他人已经实现了成百上千个用于特殊目的的计算程序用于处理大量的 raw data（如抓取文件，Web 请求日志等），用于计算产生各种各样的 derived data（如倒排索引、Web 文件结构的图片展示、每个 host 抓取的文件数量总结、指定日期最频繁的访问请求等）。许多这种计算程序在概念上都是非常直接的。然而输入的数据量往往很大，并且计算需要分布在成百上千台机器中为了在一个可接受的时间内完成任务。但是除了简单的计算模型以外，我们需要大量复杂的代码用来处理例如如何并行化计算、分发数据、处理故障等等问题。</p><p>为了解决这样的复杂性，我们设计了一种新的抽象，它让我们只需要表示出我们想要执行的计算模型，而将背后复杂的并行化，容错，数据分发，负载平衡等等技术的实现细节隐藏在了库中。我们这种新的抽象是受 Lisp 以及其他一些函数式编程语言中的 map 和 reduce 原语影响而来的。我们意识到为了计算出一系列的中间键值对，许多的计算都需要对于输入中的每个逻辑“记录”进行 map 操作。然后还需要对所有共享同一个 key 的 value 进行 reduce 操作，从而能够对派生的数据进行适当的组合。我们这种让用户自定义 map 和 reduce 操作的编程模型能够让我们简单地对大量数据实现并行化，并且使用重新执行（re-execution）作为主要的容错机制。</p><p>我们这项工作的主要共享是提供了一个简单并且强大的接口能够让我们实现自动的并行化并且分布处理大规模的计算，同时该接口的实现能在大型的商用 PC 集群上获得非常高的性能。</p><p>Section 2 描述了基本的编程模型以及一些简单的例子。Section 3 描述了为我们的基于集群的计算环境量身定做的 MapReduce 接口。Section 4 描述了一些我们认为有用的对于编程模型的改进。Section 5 是对我们的实现在不同任务下的性能测试。Section 6 包含了 MapReduce 在 Google 内的使用情况，包括我们以它为基础重写我们的产品索引系统的经验。Section 7 讨论了相关的工作以及未来的发展。</p><h2 id="Programming-Model"><a href="#Programming-Model" class="headerlink" title="Programming Model"></a>Programming Model</h2><p>计算模型以一系列的键值对作为输入并产生一系列的键值对作为输出。MapReduce 库的用户以“Map”和”Reduce”两个函数来表达计算。</p><p><strong>Map</strong>，是由用户编写的，取一个输入对，并且产生一系列中间的键值对。MapReduce 库将那些具有相同的中间键I的中间值聚集在一起，然后将它们传递给 Reduce 函数。</p><p><strong>Reduce</strong>，同样是由用户编写的，接收一个中间键I和该键对应的一系列的中间值。Reduce 函数通过将这些值合并来组成一个可能更小的集合（值的集合）。通常每个 Reduce 函数只产生 0 个或 1 个输出值。Reduce 函数一般通过一个迭代器（via an iterator）来获取中间值，从而在中间值的数目远远大于内存容量时，我们也能够处理。</p><h3 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h3><p>下面来考虑这样一个问题：统计大量文档中每一个单词出现的次数。对此，用户需要编写类似于如下的伪代码：</p><figure class="highlight c"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></div></td><td class="code"><pre><code class="hljs c"><span class="hljs-built_in">map</span>(String key, String value):<br>　　　　<span class="hljs-comment">// key: document name</span><br>　　　　<span class="hljs-comment">// value: document contents</span><br>　　　　<span class="hljs-keyword">for</span> each word w in value:<br>　　　　　　EmitIntermediate(w, <span class="hljs-string">&quot;1&quot;</span>);<br><br>　　reduce(String key, Iterator values):<br>　　　　<span class="hljs-comment">// key: a word</span><br>　　　　<span class="hljs-comment">// values: a list of counts</span><br>　　　　<span class="hljs-type">int</span> result = <span class="hljs-number">0</span>;<br>　　　　<span class="hljs-keyword">for</span> each v in values:<br>　　　　　　result += ParseInt(v);<br>　　　　Emit(AsString(result));<br></code></pre></td></tr></table></figure><p>Map 函数为在每一个单词出现的时候，为它加上一个计数（在这个简单的例子中就是加 1）。Reduce 函数对每个单词（作为中间键值对的键）的所有计数进行叠加。</p><p>另外，用户需要用输入输出文件的名字，以及一个可选的 tuning paramete 去 fill in 一个叫 mapreduce specification 的对象。之后，用户调用 MapReduce 函数，将上述定义的对象传递进去。用户的代码将和 MapReduce 库相连（由 C++实现）。Appendix A 中有这个例子所有的代码文档。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-built_in">map</span>     (k1,v1)  -&gt;  <span class="hljs-built_in">list</span>(k2,v2)<br>reduce  (k2,<span class="hljs-built_in">list</span>(v2)) -&gt; <span class="hljs-built_in">list</span>(v2)<br></code></pre></td></tr></table></figure><p>需要注意的是，输入的 key 和 value 与输出的 key 和 value 是不同的类型，而中间的 key 和 value 与输出的 key 和 value 是相同的类型（用 k1 和 k2 表示）。我们的 C++实现都是以字符串的形式和用户代码进行交互的，至于将字符串类型转换成相应合适的类型的工作则由用户代码来完成了。</p><h3 id="More-Example"><a href="#More-Example" class="headerlink" title="More Example"></a>More Example</h3><p>接下来是一些能够简单地用 MapReduce 计算模型进行表达的例子</p><p>Distributed Grep（分布式查找）：Map 函数获取匹配提供的模式的行，Reduce 函数只是简单地将这些中间数据拷贝到输出。</p><p>Count of URL Access Frequency（计算 URL 访问频率）：Map 函数处理 web 请求的日志，并且输出。Reduce 函数将拥有相同 URL 的 value 相加，得到对</p><p>Reverse Web-Link Graph：Map 函数输出对，其中 source 所在的 page 都有连向 target 这个 URL 的链接。Reduce 函数将给定 target 的所有的 source URL 连接起来，输出对</p><p>Term-Vector per Host：一个 term vector 表示一系列的键值对，word 表示一篇或者一系列文章中出现的比较重要的单词，frequency 表示它们出现的次数。Map 函数对于每篇输入的文章输出键值对（其中 hostname 是从文章所在的 URL 中抽取出来的）Reduce 函数获取给定 host 的 term vectors。它将这些 term vectors 累加起来，丢弃非频繁出现的 term，并产生一个最终的对。</p><p>Inverted Index：Map 函数对每篇文章进行处理，并输出一系列的对。Reduce 函数接收给定 word 的所有键值对，对相应的 document ID 进行排序并且输出&gt;对。所有输出对的集合构成了一个简单的倒排索引。用了 MapReduce 模型，对单词位置的追踪就变得非常简单了。</p><p>Distributed Sort：Map 函数从每个 record 中抽取出 key，产生键值对。Reduce 函数只是简单地将所有对输出。这个计算模型依赖于 Section 4.1 中描述的划分技巧以及 Section 4.2 中描述的排序特性。</p><p>（上述可以全部理解了）</p><h2 id="Implementation"><a href="#Implementation" class="headerlink" title="Implementation"></a>Implementation</h2><p>对于 MapReduce 的接口，各种各样不同的实现都是可能的。所有正确的选择都是基于当下环境的。比如，一种实现可能适合于小的共享内存的机器，另一种可能适合于大型的 NUMA 多处理器机器，甚至有的是为更大的互联的机器集群设计的。</p><p>本节中描述的实现基于的是 Google 中最常用的计算环境：一个由大量商用 PC 机通过交换以太网互联的集群。在我们的环境中：</p><ol><li>机器通常都是 x86 的双核处理器，其上运行 Linux，每台机器拥有 2-4G 的内存</li><li>商用网络硬件—-通常是 100 M&#x2F;s 或者 1 G&#x2F;s，但是综合起来要小于平均带宽</li><li>一个集群由成千上万台机器组成，因此机器故障是常有的事</li><li>存储由便宜的 IDE 磁盘提供，它们都与独立的机器直接相连。一个内部研发的文件系统用于管理所有存储于这些硬盘上的文件。该文件系统通过 Replication 在不可靠的硬件上提供了可用性和可靠性</li><li>用户提交 jobs 给调度系统。每个 job 由一系列的 task 组成，并且由调度器分配到集群中一系列可用的机器上</li></ol><h3 id="Execution-Overview"><a href="#Execution-Overview" class="headerlink" title="Execution Overview"></a>Execution Overview</h3><p>通过将输入数据自动分割成 M 份，Map 函数得以在多台机器上分布式执行。每一个输入块都能并行地在不同的机器上执行。通过划分函数(例如，hash(key) mod R)将中间键划分为 R 份，Reduce 函数也能被分布式地调用。其中划分的数目 R 和划分函数都是由用户指定的。</p><p><img src="/image/MapReduce/OS_3_1-20220327162940686.png" alt="OS_3_1"></p><p>上图 1 展示了在我们的实现中 MapReduce 全部的流程。当用户程序调用 MapReduce 函数时，接下来的动作将按序发生（图 1 中标记的数字与下面的数字是一一对应的）：</p><ol><li>用户程序中的 MapReduce 库首先将输入文件划分为M片，每片大小一般在 16MB 到 64MB 之间（由用户通过一个可选的参数指定）。之后，它在集群的很多台机器上都启动了相同的程序拷贝。</li><li>其中有一个拷贝程序是特别的——master。剩下的都是 worker，它们接收 master 分配的任务。其中有 M 个 Map 任务和 R 个 Reduce 任务要分配。master 挑选一个空闲的 worker 并且给它分配一个 map 任务或者 reduce 任务。</li><li>被分配到 Map 任务的 worker 会去读取相应的输入块的内容。它从输入文件中解析出键值对并且将每个键值对传送给用户定义的 Map 函数。而由 Map 函数产生的中间键值对缓存在内存中。</li><li>被缓存的键值对会阶段性地写回本地磁盘，并且被划分函数分割成 R 份。这些缓存对在磁盘上的位置会被回传给 master，master 再负责将这些位置转发给 Reduce worker。</li><li>当 Reduce worker 从 master 那里接收到这些位置信息时，它会使用远程过程调用从 Map worker 的本地磁盘中获取缓存的数据。当 Reduce worker 读入全部的中间数据之后，它会根据中间键对它们进行排序，这样所有具有相同键的键值对就都聚集在一起了。排序是必须的，因为会有许多不同的键被映射到同一个 reduce task 中。如果中间数据的数量太大，以至于不能够装入内存的话，还需要另外的排序。</li><li>Reduce worker 遍历已经排完序的中间数据。每当遇到一个新的中间键，它会将 key 和相应的中间值传递给用户定义的 Reduce 函数。Reduce 函数的输出会被添加到这个 Reduce 部分的输出文件中。</li><li>当所有的 Map tasks 和 Reduce tasks 都已经完成的时候，master 将唤醒用户程序。到此为止，用户代码中的 MapReduce 调用返回。</li></ol><p>当成功执行完之后，MapReduce 的执行结果被存放在 R 个输出文件中（每个 Reduce task 对应一个，文件名由用户指定）。通常用户并不需要将 R 个输出文件归并成一个。因为它们通常将这些文件作为另一个 MapReduce 调用的输入，或者将它们用于另外一个能够以多个文件作为输入的分布式应用。</p><p>（个人理解：module R 将中间键值对分为 R 份一方面是为了执行 Reduce work 的处理器进行分布式并行计算，另一方面，产生的分布式数据也可以接着用于其他能以多文件为输入的分布式应用。）</p><h3 id="Master-Data-Structures"><a href="#Master-Data-Structures" class="headerlink" title="Master Data Structures"></a>Master Data Structures</h3><p>在 master 中保存了许多的数据结构。对于每个 Map task 和 Reduce task，master 都保存了它们的状态（idle，in-progress 或者是 completed）以及 worker 所在机器的标识（对于非 idle 空转状态的 tasks 而言）。</p><p>master 相当于是一个管道，通过它 Map task 所产生的中间文件被传递给了 Reduce task。因此，对于每一个已经完成的 Map task，master 会存储由它产生的 R 个中间文件的位置和大小（分配给 R 个 Reduce task 执行，需要远程读取这些数据，所以要记录位置和大小）。当 Map task 完成的时候，master 就会收到位置和大小的更新信息。而这些信息接下来就会逐渐被推送到处于 in-progress 状态的 Reduce task 中。</p><h3 id="Fault-Tolerance"><a href="#Fault-Tolerance" class="headerlink" title="Fault Tolerance"></a>Fault Tolerance</h3><p>容错处理</p><p>因为 MapReduce 库的设计初衷是用成千上万的机器去处理大量的数据，所以它就必须能用优雅的方式对机器故障进行处理。</p><h4 id="Worker-Failure"><a href="#Worker-Failure" class="headerlink" title="Worker Failure"></a>Worker Failure</h4><p>master 会周期性地 ping 每一个 worker。如果经过了一个特定的时间还未从某一个 worker 上获得响应，那么 master 会将 worker 标记为 failed。所有由该 worker 完成的 Map task 都被回退为 idle 状态，因此能够被重新调度到其他的 worker 上。同样的，所有 failed worker 正在执行的 Map task 或者 Reduce task 也会被回退为 idle 状态，并且被重新调度。</p><p><strong>发生故障的机器上已经完成的 Map task 需要重新执行的原因是，它们的输入是保存在本地磁盘的，因此发生故障之后就不能获取了。而已经完成的 Reduce task 并不需要被重新执行，因为它们的输出是存放在全局的文件系统中的。</strong></p><p>当一个 Map task 开始由 worker A 执行，后来又由 worker B 执行（因为 A 故障了）。所有执行 Reduce task 的 worker 都会收到这个重新执行的通知。那些还未从 worker A 中读取数据的 Reduce task 将会从 worker B 中读取数据。</p><p>MapReduce 对于大面积的机器故障是非常具有弹性的。例如，在一次 MapReduce 操作中，网络维护造成了集群中八十台机器在几分钟的时间内处于不可达的状态。MapReduce 的 master 只是简单地将不可达的 worker 机器上的工作重新执行了一遍，接着再继续往下执行，最终完成了 MapReduce 的操作。</p><h4 id="Master-Failure"><a href="#Master-Failure" class="headerlink" title="Master Failure"></a>Master Failure</h4><p>对于 master，我们可以简单地对上文所述的 master 数据结构做周期性的快照。如果一个 master task 死了，我们可以很快地根据最新的快照来重新启动一个 master task。但是，因为我们只有一个 master，因此故障的概率比较低。所以，在我们的实现中如果 master 出现了故障就只是简单地停止 MapReduce 操作。用户可以检测到这种情况，并且如果他们需要的话可以重新开始一次 MapReduce 操作。</p><h4 id="Semantics-in-the-Presence-of-Failures"><a href="#Semantics-in-the-Presence-of-Failures" class="headerlink" title="Semantics in the Presence of Failures"></a>Semantics in the Presence of Failures</h4><p>如果用户提供的 Map 和 Reduce 操作是关于输入值的确定性函数，那么我们分布式的实现将会产生同样的输出，在整个程序经过没有出现故障的顺序执行之后。</p><p>我们依赖 Map task 和 Reduce task 原子性地提交输出来实现上述特性。每一个正在执行的 task 都会将它的输出写到一个私有的临时文件中。一个 Reduce task 产生一个这样的文件，而一个 Map task 产生 R 个这样的文件（每个 Reduce work 一个）。当一个 Map task 完成的时候，worker 就会给 master 发送一个信息，，其中包含了 R 个临时文件的名字。如果 master 收到了一个来自于已经完成了的 Map task 的完成信息，那么它就将它自动忽略。否则，将 R 个文件的名称记录到一个 master 数据结构中。</p><p>当一个 Reduce task 完成的时候，Reduce worker 会自动将临时输出文件命名为最终输出文件。如果同一个 Reduce task 在多台机器上运行，那么多个重命名操作产生的最终输出文件名将会产生冲突。对此，我们依赖底层文件系统提供的原子重命名操作来保证最终文件系统中的数据来自一个 Reduce task。</p><p>大多数的 Map 和 Reduce 操作都是确定性的，事实上，我们的语义等同于顺序执行。因此这让程序员非常容易地能够解释他们程序的行为。当 Map 和 Reduce 操作是非确定性的时候，我们提供较弱，但仍然合理的语义。在非确定性的操作中，对于一个特定的 Reduce task $R_1$ 的输出是对应非确定性程序顺序执行产生的一个结果。然而，对于另一个 Reduce task $R_2$，它的输出对应于非确定性程序另一个顺序执行的结果。</p><p>下面考虑 Map task $M$和 Reduce task $R_1$和$R_2$。让$e(R_i)$表示$R_i$的执行结果。更弱的语义意味着，$e(R_1)$可能从 M 的一次执行结果中读取输入，而$e(R_2)$可能从 M 的另一次执行中读取输入。</p><h3 id="Locality"><a href="#Locality" class="headerlink" title="Locality"></a>Locality</h3><p>网络带宽在我们的计算环境中是相对稀缺的资源。我们通过将输入数据（由 GFS 管理）存储在集群中每台机器的本地磁盘的方法来节省带宽。GFS 将输入文件切分成 64MB 大小的块，并且将每个块的多份拷贝（通常为 3 份）存储在不同的机器上。MapReduce 的 master 获取所有输入文件的位置信息，然后将 Map task 调度到有相应输入文件副本的机器上。当发生故障时，再将 Map task 调度到邻近的具有该 task 输入文件副本的机器（即在同一台交换机内具有相同数据的机器）。当在一个集群的大量机器上做 MapReduce 操作时，大多数的输入数据都是从本地读取的，而不用消耗带宽。</p><h3 id="Task-Granularity-粒度"><a href="#Task-Granularity-粒度" class="headerlink" title="Task Granularity 粒度"></a>Task Granularity 粒度</h3><p>如上所述，我们将 Map 操作分成 M 份，Reduce 操作分成 R 份。在理想的情况下，M 和 R 的值应该要比集群中 worker machine 的数量多得多。让一个 worker 同时进行许多不同的 task 有利于提高动态的负载均衡，同时在一个 worker 故障的时候能尽快恢复。许多已经完成的 Map task 也能尽快地传播到其他所有的 worker machine 上。</p><p>在我们的实现中，M 和 R 的大小是有一个实用范围的。因为我们的 master 需要做$O(M+R)$个调度决定，并且还要在内存中保存$O(M * R)$个状态（源自前面所说：<strong>对于每一个已经完成的 Map task，master 会存储由它产生的 R 个中间文件的位置和大小。</strong>）。（但是内存使用的常数还是比较小的，$O(M*R)$个 Map task&#x2F;Reduce task 状态对，每个的大小大概在一个字节）</p><p>另外，R通常受限于用户，因为每个 Reduce task 的输出都分散在不同的输出文件中。事实上，我们会选择M，使得每个输入文件大概 16MB 到 64MB 的输入文件（因此上文所述的局部性优化会达到最优，减少带宽负担，尽量利用本地存储数据进行 Map task）。而我们会让 R 成为 worker machine 数量的一个较小的倍数。因此，我们通常在进行 MapReduce 操作时，$M&#x3D;200000，R&#x3D;5000$，使用 2000 个 worker machine。</p><h3 id="Backup-Tasks"><a href="#Backup-Tasks" class="headerlink" title="Backup Tasks"></a>Backup Tasks</h3><p>“straggler”（落伍的士兵）的存在是拖慢整个 MapReduce 操作的通常的原因之一。所谓的”straggler”是指一台机器用了过长的时间去完成整个计算任务中最后几个 Map task 或者 Reduce task。Straggler 出现的原因有很多。比如一台机器上硬盘坏了，它就会经历大量的可纠正错误，从而让它的性能从 30MB&#x2F;s 下降到 1MB&#x2F;s。集群的调度系统可能将其他 task 调度到该机器上，导致它执行 MapReduce 代码的速度变慢很多，因为 CPU，内存，本地磁盘，网络带宽的竞争加剧。我们最近遇到的一个问题是一台机器的初始化代码有点问题，它会导致处理器的缓存被禁用，在这些受影响的机器上进行的计算速度会下降到原来的百分之一。（ping 得到不判定为故障机，但是自身速度过慢会拖累整体，出现短板效应）</p><p>对此，我们有一个通用的机制用来缓解 straggler 的问题。当 MapReduce 操作接近结束的时候，master 会将那些仍在执行的 task 的备份进行调度执行。无论是原来的还是备份执行完成，该 task 都将被标记为已完成。我们通过调整将该操作导致的计算资源消耗仅仅提高了几个百分点（只在即将结束的时候进行备份竞争执行）。但是在完成大型的 MapReduce 操作时，却让整个执行时间下降了好多。例如，Section 5.3 中所描述的排序算法在备份机制关闭的情况下，需要多消耗 44%的时间。</p><h2 id="Refinements-优化"><a href="#Refinements-优化" class="headerlink" title="Refinements 优化"></a>Refinements 优化</h2><p>虽然对于大多数需求由 Map 和 Reduce 函数提供的功能已经足够了，但是我们还是发现了一些有用的扩展。对它们的描述如下。</p><h3 id="Partitioning-Function"><a href="#Partitioning-Function" class="headerlink" title="Partitioning Function"></a>Partitioning Function</h3><p>MapReduce 用户决定他们的 Reduce task 或者输出文件的数目 R。通过一个划分函数，根据中间键值将各个 task 的数据进行划分。默认的划分函数是通过哈希（比如，hash(key) mod R）。这通常会产生非常好的较为均衡的划分。但是在其他一些情况下，通过键值的其他函数来划分要更好一些。例如，有的时候输出键值是一些 URL，我们希望同一个 host 的内容能放在同一个输出文件中。为了支持这种情况，MapReduce 库的用户可以提供一个特殊的划分函数。例如，使用“hash(Hostname(urlKey)) mod R”作为划分函数，从而让所有来自于同一个 host 的 URL 的内容都输出到同一个输出文件。</p><p>（个人理解，hash 之前可以根据需求（key 的相似性、urlhost 相同）对 key 提前进行一次分组）</p><h3 id="Ordering-Guarantees"><a href="#Ordering-Guarantees" class="headerlink" title="Ordering Guarantees"></a>Ordering Guarantees</h3><p>我们确保在一个给定的划分中，中间键值对都按照键值的升序进行处理。这样的处理顺序确保了每一个划分产生一个排好序的输出文件。这样的话，如果输出文件格式需要支持根据 key 进行有效的随机查找会比较方便。同时，输出文件（应用）的用户也会觉得已经排好序的数据使用起来特别方便。</p><h3 id="Combiner-Function"><a href="#Combiner-Function" class="headerlink" title="Combiner Function"></a>Combiner Function</h3><p>在有些情况下，每个 Map task 都会产生大量的中间键的重复而用户指定的 Reduce 函数是交互和关联的。Section 2.1 中的单词统计就是一个很好的例子。因为单词的出现频率服从于 Zipf 分布，每个 Map Task 都会产生成百上千个这样的记录。所有这些记录都会通过网络被送到一个 Reduce task 中，并且由 Reduce 函数加在一起去产生一个数。我们允许用户使用了可选的 Cominer 函数，用于在网络传输之前部分地进行归并操作。</p><p>Combiner 函数在每个执行 Map task 的机器上执行。通常 Combiner 和 Reduce 函数使用的是相同的代码。Reduce 函数和 Combiner 函数<strong>唯一的不同</strong>是 MapReduce 库<strong>如何处理函数的输出</strong>。Reduce 函数的输出写到最终的输出文件中。而 Combiner 函数的输出会被写到一个最终将被送给 Reduce task 的中间文件中（合并后替代原有的中间键值对集合传递给 Reduce Task 机器，这样减少了带宽的占用）。</p><p>部分的合并操作能极大地加速某类特定的 MapReduce 操作。Appendix A 包含了一个使用 Combiner 的例子。</p><h3 id="Input-and-Output-Types"><a href="#Input-and-Output-Types" class="headerlink" title="Input and Output Types"></a>Input and Output Types</h3><p>MapReduce 库提供了对读入数据文件多种的格式支持。例如，”text”格式的输入将每一行作为键值对：key 是文件内的偏移，value 是该行的内容。另外一种比较常用的格式存储一系列按照键进行排序的键值对。每一个输出格式的实现都知道如何将自己进行合理的划分从而能让不同的 Map task 进行处理（例如，text 模式就知道将区域划分到以行为边界）。用户可以通过简单地定义一个 reader 接口来提供一个新的输入类型的实现。事实上，大多数用户只使用了预定义输入类型的很小一部分。</p><p>reader 并不一定要从文件中读取数据。例如，我们可以很容易地定义一个从数据库，或者内存中映射的数据结构中读取记录的 reader。</p><p>同理，我们也支持产生不同格式的输出数据，用户也能编写新的输出数据格式。</p><h3 id="Side-effects"><a href="#Side-effects" class="headerlink" title="Side-effects"></a>Side-effects</h3><p>在有些情况下，MapReduce 的用户会很容易发现 Map 或者 Reduce 操作会产生一些辅助文件作为额外的输出文件。我们依赖应用的编写者去保证这些副作用是原子和幂等的。一般来说，应用会写到一个临时文件中，并且在它完全产生之后，通过一个原子操作将它重命名。</p><p>对于一个单一的 task 产生的多个输出文件，我们不提供原子性的两相提交支持。因此，产生多个输出文件并且有跨文件一致性要求的 task 需要是确定性的。但是这样的限制在实践过程中并不是什么问题。</p><h3 id="Skipping-Bad-Records"><a href="#Skipping-Bad-Records" class="headerlink" title="Skipping Bad Records"></a>Skipping Bad Records</h3><p>有时候，如果用户的代码中有 bug 的话，会导致 Map 或者 Reduce 操作在某些记录上崩溃。这些 bug 会导致 MapReduce 操作的正常完成。对于这种情况，通常就是去修 bug。不过有时候这是不可行的，也许 bug 是第三方库造成的，而我们并不能得到它的源代码。而且，有时候我们允许忽略掉一些记录，例如在对一个大数据集做分析的时候。因此我们提供了一种可选的执行模式，当 MapReduce 库检测到一些记录会造成崩溃时，就会主动跳过它们，从而保证正常地运行。</p><p>每一个 worker 进程都安装了一个 signal handler 用于捕捉段错误和 bug。在调用用户的 Map 和 Reduce 操作之前，MapReduce 库会将参数的序号保存在一个全局变量中。如果用户代码产生了一个信号，signal handler 就会传输一个参数含有序号的”last gasp”UDP 包给 MapReduce 的 master。当 master 在一个特定的记录中发现了不知一次的错误，这表示在下一次执行相应的 Map 或者 Reduce 操作的时候一个将它跳过。</p><h3 id="Local-Execution"><a href="#Local-Execution" class="headerlink" title="Local Execution"></a>Local Execution</h3><p>Map 或者 Reduce 函数的调试问题是非常 tricky 的。因为实际的计算发生在分布式的系统中，通常由成百上千台机器组成，并且工作的分配由 master 动态执行。为了帮助调试，分析，以及小规模的测试，我们开发了另外一个 MapReduce 库的实现，它能够在本地机器上顺序执行一个 MapReduce 操作的所有工作。它的控制交给用户，因此计算可以被限定到制定的 Map task 中执行。用户利用指定的 flag 启动程序，然后就能非常简单地使用任何它们觉得有用的调试或者测试工具了。</p><h3 id="Status-Information"><a href="#Status-Information" class="headerlink" title="Status Information"></a>Status Information</h3><p>master 运行了一个内置的 HTTP server 并且输出了一系列供人们使用的状态页。状态页会显示程序的计算过程，例如已经完成了多少个 task，还有多少个 task 正在执行，输入的字节数，中间数据的字节数，输出的字节数，以及处理速度等等。该页还包含了指向各个 task 的标准错误和标准输出链接。用户可以利用这些数据来判断计算会持续多长时间，以及计算是否需要添加更多的资源。这些页面还能用来发现什么时候处理速度比预期地下降好多。</p><p>另外，顶层的状态页显示了那些 worker 出错了，以及在它们出错时正在执行哪些 Map 和 Reduce task。这些信息在诊断用户代码出现的 bug 时是非常有用的。</p><p>MapReduce 库提供了一个叫 counter 的设施用于统计各种不同事件出现的次数。例如，用户可能想要统计已经处理过的单词的数目或者德国文件的索引数量。</p><p>为了使用这一特性，用户代码创建一个命名的 counter 对象，并且在 Map 以及 Reduce 函数中对 counter 进行增加。例如：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs c">Counter* uppercase;<br>uppercase = GetCounter(<span class="hljs-string">&quot;uppercase&quot;</span>);<br><br><span class="hljs-built_in">map</span>(String name, String contents):<br>　　<span class="hljs-keyword">for</span> each word w in contents:<br>　　　　<span class="hljs-keyword">if</span>(IsCapitalized(w)):<br>　　　　　　uppercase-&gt;Increment();<br>　　　　EmitIntermediate(w, <span class="hljs-string">&quot;1&quot;</span>);<br></code></pre></td></tr></table></figure><p>每个 worker 机器上 counter 的值会定期传给 master（捎带在给 master 的 ping 回复中）。master 将来自成功执行的 Map 和 Reduce task 的 counter 值聚集起来。然后在 MapReduce 操作完成之后返回给用户代码。当前的 counter 值也会显示在 master 的状态页上（前述的 state pages），所以用户能从实时观看计算的进行。在聚集 counter 的值的时候，master 会消除 Map 或者 Reduce task 的重复执行造成的重复计算。（重复执行可能由 backup tasks 或者因为错误重新执行的 task 引起）。</p><p>有些 counter 的值是由 MapReduce 库自动维护的，例如已经处理的输入键值对数目以及已经产生的输出键值对数目。</p><p>用户发现 counter 特性对于检查 MapReduce 操作的执行是非常有用的。例如，在有些 MapReduce 操作中，用户代码想要确保产生的输出对的数目和已经处理的输入对的数目是恰好相等的（比如检查满射），或者处理的德语文件的数目占总处理文件数目的比重在一个可容忍的范围内。</p><h2 id="Performance"><a href="#Performance" class="headerlink" title="Performance"></a>Performance</h2><p>在这个 section 中，我们通过运行在一个集群上的两个 computation 来测试 MapReduce 的性能。一个 Computation 搜索一个 T 的数据，从中获取一个特定的模式。另一个 computation 对一个 T 的数据进行排序。</p><p>这两个程序代表了由用户实际编写的 MapReduce 程序的一个子集———一类程序用于将数据从一种表示方法切换到另一种表示方法。另一类程序则从大数据集中抽取出一小部分有趣的数据。</p><h3 id="Cluster-Configuration"><a href="#Cluster-Configuration" class="headerlink" title="Cluster Configuration"></a>Cluster Configuration</h3><p>所有程序都运行在一个由 1800 台机器组成的机器上。每一台机器都有两个 2GHz 的 Intel Xeon 处理器，并且允许 Hper-Threading（超线程）， 4GB 内存，两个 160GB 的 IDE 磁盘，以及一个 G 比特的以太网链路。这些机器被安排在一个两层树状的交换网络中，根节点的带宽大概在 100-200Gbps。因为所有机器都在同一个托管设备中，因此任意两台机器间的 RTT 少于 1ms。</p><p>其中 4GB 中的 1-1.5G 是为集群中运行的其他任务预留的。程序在一个周末的下午运行，此时 CPU，磁盘，网络基本都处于空闲状态。</p><h3 id="Grep"><a href="#Grep" class="headerlink" title="Grep"></a>Grep</h3><p>grep 程序需要扫描 10 的十次方条 100-byte 的记录，搜索一个相对罕见的三字符模式（出现了 92337 次）。输入被分成大概 64MB 份（M &#x3D; 15000），所有的输出文件都存放在一个文件中（R &#x3D; 1）。</p><p>Figure 2 显示了 Computation 随着时间的变化过程。Y 轴代表了输入数据的扫描速度。随着机器逐渐加入 MapReduce 的计算当中，速度越来越快，当有 1764 个 worker 加入时，达到峰值 30GB&#x2F;s。随着 Map task 的结束，速度开始下降并且在 80s 的时候到达 0,。整个 Computation 从开始到结束总共花费了大概 150s。这其中还包括了 1 分钟的启动开销。开销主要来源于将程序分发到 worker machine 中，和 GFS 交互并打开 1000 个输入文件，以及获取局部性优化所需的信息的延时。</p><h3 id="Sort"><a href="#Sort" class="headerlink" title="Sort"></a>Sort</h3><p>排序程序用于对 10 的十次方条记录（大概 1T 的数据）进行排序。程序以 TeraSort benchmark 为模型。</p><p>排序程序由不超过 50 行用户代码组成，一个三行的 Map function 从 text 的一行中提取一个 10-byte 的排序 key，与原始的 text line 组合成一个中间 key&#x2F;value pair。我们使用内置的 Identity 函数作为 Reduce 的运算符。这一函数将中间键值对传递出作为输出对。最终的排序输出是一个二路复制的 GFS 文件。</p><p>输入被分成 64MB 份（M &#x3D; 15000），而将输出分为 4000 份（R &#x3D; 4000）。分割成许根据初始的 key 将其分割到 R 份中的一个。</p><p><img src="/image/MapReduce/OS_3_2-20220327170521059.png" alt="OS_3_2"></p><p>图 3（a）展示了排序程序的正常执行，左上方的图表示读入的速率，在达到峰值 13GB&#x2F;s 后迅速滑落因为所有的 map tasks 在 200 秒内就已经完成。值得注意的是，输入的速率慢于 grep 操作（对于相同的 M 划分），这是因为对于 sort 操作，花费了一半的事件以及 I&#x2F;O 带宽用于将中间键值对结果写入本地磁盘，而 grep 操作对应的输出则可以小到忽略不计。</p><p>中间左边的图表示经历 map tasks 后通过网络向 reduce tasks 传输数据的速率。这一混排在首个完成的 map task 后启动。第一个突起表示所有 reduce tasks 运行的第一个批次（R &#x3D; 1700 nearly all），开始计算后 300 秒左右，第一批次的部分 reduce tasks 完成，我们开始向完成的机器进一步递送剩余 reduce tasks 的数据。</p><p>左下的图表示排序好的数据向最终文件写出的速率。从第一批次 reduce tasks 完成到开始写数据有一段时间间隔，这是因为机器忙于对中间数据进行排序。</p><p>关于速度的比较，输入数据高于 shuffle 速率和输出速率，这是因为输入是基于本地存储，而又因为网络带宽的限制，以及输出要求两份 replica 的要求，shuffle 速率高于输出速率。我们写成两个副本，因为这是我们的底层文件系统提供的可靠性和可用性机制要求。 如果底层文件系统使用擦除编码（erasure coding）而不是复制（replication），则可以减少写入数据的网络带宽要求。</p><p>（GFS 介绍的论文里应该会解释为什么需要两份 replica）。</p><h3 id="Effect-of-Backup-Tasks"><a href="#Effect-of-Backup-Tasks" class="headerlink" title="Effect of Backup Tasks"></a>Effect of Backup Tasks</h3><p>在图 3（b）中，我们展示了禁止 backup tasks 情况下执行排序操作的结果。流程与图 3（a）很相似，但存在一个相当长的且看不出有明显活动的尾部。960 秒后，除了剩余的 5 个，其余 reduce tasks 均已完成，然而剩余的 stragglers 直到 300 秒后才完成任务，着导致整体耗时 1283 秒，比具备 backup tasks（最终备份处理任务）情况下多耗时 44%。</p><h3 id="Machine-Failures"><a href="#Machine-Failures" class="headerlink" title="Machine Failures"></a>Machine Failures</h3><p>在图 3（c）中，我们展示了将 1746 台工作机器中的 200 台机器故意宕机几分钟以模拟机器故障情况下排序操作的执行结果，底层的集群立刻重启新的工作进程（因为仅仅是 kill 进程，实际上机器功能良好）。</p><p>worker 的 deaths 通过图表中负值输入速率来表示，因为先前一些已完成的 map work 丢失而需要被重新执行（根据先前分析，由于 map task 得到的中间结果存储在本地，宕机后无法正确访问，使得之前的任务需要被重新执行 re-execute）。重执行开始得十分迅速，整体耗时仅仅比正常情况多耗时 5%。</p><h2 id="Experience"><a href="#Experience" class="headerlink" title="Experience"></a>Experience</h2><p>我们得 MapReduce 库首个版本于 2003 年 2 月写成，并在 2003 年 8 月进行了重要加强，包括引入局部优化，worker 执行任务间动态负载均衡等等。从那时起，我们非常欣喜得看到 MapReduce 在解决各类问题上的广泛应用。现在，它已 Google 用于以下广泛领域的研究。</p><ul><li>大规模机器学习问题</li><li>Google News 和 Froogle products（Google 购物）的聚类问题</li><li>提取用于生成热门查询报告的数据（如 Google Zeitgeiest）</li><li>提取网页上进行的试验或产品性能</li><li>大规模图形计算</li></ul><h2 id="Large-Scale-Indexing"><a href="#Large-Scale-Indexing" class="headerlink" title="Large-Scale Indexing"></a>Large-Scale Indexing</h2><p>目前为止，我们最重要的 MapReduce 应用之一是重写一个产生谷歌搜索引擎需要的数据结构的复杂系统。索引系统以被抓取系统检索到的文件（GFS 文件形式储存）为输入，raw content 大小约 20T，索引进程进行约 10 次 MapReduce 组成的序列操作。相较于先前 ad-hoc 分布式索引系统，现在应用 MapReduce 后，系统具备以下优点：</p><ul><li>因为与容错、分布式、并行化相关内容隐藏在库重，索引代码更加简单、精巧、易于理解。比如，计算的一个阶段从原有 3800 行 C++代码削减至 700 行。</li><li>概念上可与计算分开，从而使改动变得简单。</li><li>内部对一些机器故障的解决使得整个过程更容易成功执行。进一步的，也更容易向系统中加入新的机器。</li></ul><h2 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h2><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>现在 MapReduce 已成功被 Google 应用于各种目的，我们将这种成功归功于以下原因。</p><ul><li>甚至对于并行和分布式系统缺乏相关经验的编程人员，由于相关细节隐藏在库中，模型仍具备易用性。</li><li>大量问题易于以 MapReduce 地方式解决。</li><li>我们将其实现在大规模集群上，因而适于很多大型问题。</li></ul><p>在这项工作中我们学习到很多，</p><ul><li>重新定义编程范式使得并行&#x2F;分布式运算易于实现，也获得了相当的容错性能。</li><li>网络带宽作为稀缺资源，使得我们的很多优化都意在减少通过网络传输的数据。</li><li>冗余的任务执行（backup tasks）可以用于减少缓慢机器的影响，以及解决机器故障和数据丢失。</li></ul>]]></content>
    
    
    <categories>
      
      <category>Paper</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>hexo多端同步</title>
    <link href="/2022/03/26/git/hexo%E5%A4%9A%E7%AB%AF%E5%90%8C%E6%AD%A5/"/>
    <url>/2022/03/26/git/hexo%E5%A4%9A%E7%AB%AF%E5%90%8C%E6%AD%A5/</url>
    
    <content type="html"><![CDATA[<h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>这是一篇关于Hexo博客框架如何在git中多端同步的学习记录</p><h2 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h2><h3 id="文件同步"><a href="#文件同步" class="headerlink" title="文件同步"></a>文件同步</h3><figure class="highlight bash"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></div></td><td class="code"><pre><code class="hljs bash">git init  //初始化本地仓库<br>git remote add origin git@github.com:yourname/yourname.github.io.git  //将本地与Github项目对接<br>git checkout -b hexo  //新建并切换到hexo分支上<br>git add . //将必要的文件依次添加<br>git commit -m <span class="hljs-string">&quot;Blog Source Hexo&quot;</span><br>git push origin hexo  //push到Github项目的hexo分支上<br></code></pre></td></tr></table></figure><h3 id="图片同步"><a href="#图片同步" class="headerlink" title="图片同步"></a>图片同步</h3><p>当我想要在博客与Typora软件中都想要看到文章内引用的本地图片时，发生了渲染错误。博客的服务器端不支持Typora的本地路径引用方式。</p><p>为此我查看了一下Hexo的文档，发现官方默认指定了图片存放路径 <code>source/image</code> 下。</p><p>既然官方要求了，那我便只好更改Typora插入图片时的相关规则</p><ol><li><p>Typora -&gt; 偏好设置 -&gt; 图像 -&gt; 插入图片时 (复制到指定路径) <code>~/hexo/blog/source/image/$&#123;filename&#125;</code> 并勾选下方的所有子项</p></li><li><p>格式 -&gt; 图像 -&gt; 设置图片根目录 -&gt; 选中 <code>~/hexo/blog/source</code> 路径，这一步是保证了博客与Typora都能预览到图片内容</p><p>这一步等同于在文章头部添加 <code>typora-root-url: ../../</code> 配置项，注意要选到blog文件夹中</p></li></ol><h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>学习时在最终的 <code>git push origin hero</code>命令中遇到了 <font color='red'>Permission denied</font> 相关问题，发现需要生成新的ssh key，来添加给git。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">ssh-keygen -t rsa -C <span class="hljs-string">&#x27;github注册时的邮箱&#x27;</span><br><span class="hljs-comment"># 一路回车，最后会在～/.ssh目录中生成密钥文件</span><br><span class="hljs-comment"># 将id_rsa.pub公钥添加到git中</span><br><span class="hljs-comment"># 再执行 git push origin hexo 即可</span><br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>git</category>
      
    </categories>
    
    
    <tags>
      
      <tag>hexo</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
